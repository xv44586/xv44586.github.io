<!DOCTYPE html><html lang="zh-cn"><head><meta name="generator" content="Hexo 3.9.0"><meta charset="utf-8"><title>GPT-4 yes!! but | 小蛋子</title><meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no"><meta name="format-detection" content="telephone=no"><meta name="author" content="[object Object]"><meta name="designer" content="minfive"><meta name="keywords" content="NLP, 机器学习, 深度学习, Python, Backend"><meta name="description" content="NLP | Machine Learning | Developer"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black"><meta name="format-detection" content="telephone=yes"><meta name="mobile-web-app-capable" content="yes"><meta name="robots" content="all"><link rel="canonical" href="https://xv44586.github.io/2023/03/25/gpt4/index.html"><link rel="icon" type="image/png" href="/img/favicon.ico" sizes="32x32"><meta name="google-site-verification" content="tbK2z0UTHcAWdqNCgEwykaDA9vvvXnN4ZSp_LFbAbDc"><meta name="baidu-site-verification" content="NBO0j1DAOy"><meta name="baidu-site-verification" content="ulZR80nUkv"><link rel="stylesheet" href="/scss/base/index.css"><link rel="alternate" href="/atom.xml" title="小蛋子"><script>var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?b1d2a1d2b250300950a8ffb5caa20818";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><link rel="stylesheet" href="/scss/views/page/post.css"><link rel="alternate" href="/atom.xml" title="小蛋子" type="application/atom+xml"></head><body ontouchstart><div id="page-loading" class="page page-loading" style="background-image:url(/other/loading.gif)"></div><div id="page" class="page js-hidden"><header class="page__small-header page__header--small"><nav class="page__navbar"><div class="page__container navbar-container"><a class="page__logo" href="/" title="小蛋子" alt="小蛋子"><img src="/img/lg.png" alt="小蛋子"></a><nav class="page__nav"><ul class="nav__list clearfix"><li class="nav__item"><a href="/" alt="首页" title="首页">首页</a></li><li class="nav__item"><a href="/archives" alt="归档" title="归档">归档</a></li><li class="nav__item"><a href="/about" alt="关于" title="关于">关于</a></li></ul></nav><button class="page__menu-btn" type="button"><i class="iconfont icon-menu"></i></button></div></nav></header><main class="page__container page__main"><div class="page__content"><article class="page__post"><div class="post__cover"><img src="/2023/03/25/gpt4/bg.jpeg" alt="GPT-4 yes!! but"></div><header class="post__info"><h1 class="post__title">GPT-4 yes!! but</h1><div class="post__mark"><div class="mark__block"><i class="mark__icon iconfont icon-write"></i><ul class="mark__list clearfix"><li class="mark__item"><a href="https://github.com/xv44586">小蛋子</a></li></ul></div><div class="mark__block"><i class="mark__icon iconfont icon-time"></i><ul class="mark__list clearfix"><li class="mark__item"><span>2023-03-25</span></li></ul></div><div class="mark__block"><i class="mark__icon iconfont icon-tab"></i><ul class="mark__list clearfix"><li class="mark__item"><a href="/tags/LLM/">LLM</a></li><li class="mark__item"><a href="/tags/GPT-4/">GPT-4</a></li></ul></div><div class="mark__block"><i class="mark__icon iconfont icon-eye"></i><ul class="mark__list clearfix"><li id="busuanzi_container_page_pv" class="mark__item"><span id="busuanzi_value_page_pv"></span>次</li></ul></div></div></header><div class="post__content"><div class="toc"><ul><li><a href="#gpt-4-yes">GPT-4 yes</a></li><li><a href="#gpt-4-cun-zai-de-wen-ti">GPT-4存在的问题</a><ul><li><a href="#bu-kai-yuan">不开源</a></li><li><a href="#shu-ju-an-quan">数据安全</a></li><li><a href="#zi-yuan-xiao-hao-da">资源消耗大</a></li></ul></li><li><a href="#nlp-ke-zuo-de-fang-xiang">NLP可做的方向</a><ul><li><a href="#hallucination">hallucination</a></li><li><a href="#fu-xian-gpt-4-chatgpt-gpt-3-5-instructgpt">复现GPT-4/ChatGPT/GPT-3.5/InstructGPT</a></li><li><a href="#ru-he-ping-gu-llm">如何评估LLM</a></li><li><a href="#zhi-chi-chang-wen-ben">支持长文本</a></li><li><a href="#bian-xiao-bian-kuai">变小变快</a></li><li><a href="#di-cheng-ben-inference">低成本inference</a></li><li><a href="#di-cheng-ben-you-hua">低成本优化</a></li><li><a href="#you-hua-qi">优化器</a></li><li><a href="#geng-ke-kong">更可控</a></li><li><a href="#shi-bie-aigc">识别AIGC</a></li><li><a href="#dan-yi-ren-wu-ling-yu-shua-bang">单一任务/领域刷榜</a></li></ul></li><li><a href="#he-qu-he-cong">何去何从</a><ul><li><a href="#pu-tong-gong-cheng-shi">普通工程师</a></li><li><a href="#pu-tong-yong-hu">普通用户</a></li></ul></li><li><a href="#fan-wai">番外</a><ul><li><a href="#tong-guo-prompt-gou-jian-ji-zhu-bi-lei-shen-qing-prompt-zhuan-li">通过prompt 构建技术壁垒/申请prompt 专利</a></li><li><a href="#hui-bu-hui-shi-ye">会不会失业</a></li></ul></li><li><a href="#guan-yu-tou-tu">关于头图</a></li><li><a href="#buy-me-a-coffee">Buy me a coffee</a></li></ul></div><p>这篇博客简单讨论下在GPT-4 如此强大的技术冲击下，我们NLPer该何去何从。<br>首先说下我的结论：GPT-4 非常强大，但是还没有到完全取代我们工作的地步，我们依然有很多能做的方向。</p><h1><span id="gpt-4-yes">GPT-4 yes</span><a href="#gpt-4-yes" class="header-anchor"></a></h1><ol><li>更可靠了（胡说八道进一步降低）</li><li>性能更好：比GPT-3.5 又提升了一大截</li><li>reverse inverse scaling prize:一些随着模型变大性能下降的任务在GPT-4上不再出现类似现象（曾经没法通过增大模型规模提升性能的任务现在也解决了）</li><li>能够用图像做prompt：增加图像信息能进一步提升性能（看图说话，类似BLIP2，这个对盲人太友好了）</li><li>进一步closeAI</li></ol><h1><span id="gpt-4-cun-zai-de-wen-ti">GPT-4存在的问题</span><a href="#gpt-4-cun-zai-de-wen-ti" class="header-anchor"></a></h1><h2><span id="bu-kai-yuan">不开源</span><a href="#bu-kai-yuan" class="header-anchor"></a></h2><p>由于GPT-4 完全不公布任何技术细节，所以他为什么有如此强大的能力，我们只能猜，想要研究它变得困难重重。</p><h2><span id="shu-ju-an-quan">数据安全</span><a href="#shu-ju-an-quan" class="header-anchor"></a></h2><p>ChatGPT 的火爆让大家突然忘了曾经非常看重的数据安全问题，preview 版是有可能会参与下次迭代的；而商用api 即使强调不会用于模型训练，敏感业务数据你敢用吗？</p><h2><span id="zi-yuan-xiao-hao-da">资源消耗大</span><a href="#zi-yuan-xiao-hao-da" class="header-anchor"></a></h2><p>即使是GPT-3 也有175B 参数，训练/推理都是极其消耗资源的，从GPT-4 的价格上涨了50% 来看，GPT-4 的推理消耗资源也上升了50% 左右。</p><h1><span id="nlp-ke-zuo-de-fang-xiang">NLP可做的方向</span><a href="#nlp-ke-zuo-de-fang-xiang" class="header-anchor"></a></h1><p>这也是最近讨论比较热烈的一个问题，回答这个问题前，不妨先思考一下理想的NLP 模型应该具有哪些特征。我认为比较理想的模型是：安全可靠/支持长文本/小/快/私有化部署。所以我仅从个人出发，给出一些我比较关注的方向。</p><h2><span id="hallucination">hallucination</span><a href="#hallucination" class="header-anchor"></a></h2><p>目前LLM 最大的问题就是hallucination(一本正经的胡说八道)。目前主流两种思路：alignment/多模态。</p><ul><li>alignment<br>至于如何做alignment ，学术界主要是instruction-tuning为主，OpenAI 的路线是RLHF，然而普通玩家我是完全不推荐做RL的，只要仔细阅读InstructGPT/GPT-4 paper中关于reward model 部分就能劝退了。所以对于我们普通玩家，是否有别的路径？</li><li>多模态<br>GPT4 的paper 上看效果是不错的，我没做过，不多说了。</li></ul><h2><span id="fu-xian-gpt-4-chatgpt-gpt-3-5-instructgpt">复现GPT-4/ChatGPT/GPT-3.5/InstructGPT</span><a href="#fu-xian-gpt-4-chatgpt-gpt-3-5-instructgpt" class="header-anchor"></a></h2><p>不开源只能复现，目前主要有<a href="https://github.com/facebookresearch/llama" target="_blank" rel="noopener">facebookresearch/llama</a>/<a href="https://huggingface.co/bigscience/bloom" target="_blank" rel="noopener">bigscience/bloom</a>,此外还有不开源但是可以使用API 访问的百度文心一言/ChatGLM 等。</p><h2><span id="ru-he-ping-gu-llm">如何评估LLM</span><a href="#ru-he-ping-gu-llm" class="header-anchor"></a></h2><p>我们说百度文心一言性能不行时，到底如何不行？这里就牵扯到如何量化的评估LLM 的性能。曾经自动化的方案及benchmark 的参考意义随着LLM 的能力提升显得越来越弱，现在急需新的数据集/评估方案。目前的工作有<a href="https://github.com/openai/evals" target="_blank" rel="noopener">openai/evals</a>/<a href="https://github.com/stanford-crfm/helm" target="_blank" rel="noopener">stanford-crfm/HELM</a></p><h2><span id="zhi-chi-chang-wen-ben">支持长文本</span><a href="#zhi-chi-chang-wen-ben" class="header-anchor"></a></h2><p>更长的输入对某些任务是有利的，如何让模型支持更长的输入呢？主要的思路有两个：</p><ul><li>训练时使用较短文本，推理时外推更长的位置信息，使模型获得处理长文本的能力，如bloom 中使用的<a href="https://arxiv.org/pdf/2108.12409.pdf" target="_blank" rel="noopener">ALiBI</a></li><li>调整模型结构，如最近的工作：<a href="https://arxiv.org/pdf/2303.09752.pdf" target="_blank" rel="noopener">CoLT5:Faster Long-Range Transformers with Conditional Computation</a><br>PS: GPT-4 的输入从GPT-3.5 的4K(or 8K?) 提升到了30K，如何做的呢？</li></ul><h2><span id="bian-xiao-bian-kuai">变小变快</span><a href="#bian-xiao-bian-kuai" class="header-anchor"></a></h2><p>相同架构的模型通常变小就会变快，让模型变小的方法主要是蒸馏/量化/train 小模型，这个方向目前工作有<a href="https://github.com/tatsu-lab/stanford_alpaca" target="_blank" rel="noopener">stanford_alpaca</a>/<a href="https://github.com/TimDettmers/bitsandbytes" target="_blank" rel="noopener">bitsandbytes</a>，中文上也有<a href="https://github.com/THUDM/ChatGLM-6B" target="_blank" rel="noopener">ChatGLM-6B</a>/<a href="https://github.com/LianjiaTech/BELLE" target="_blank" rel="noopener">BELLE</a>等。</p><h2><span id="di-cheng-ben-inference">低成本inference</span><a href="#di-cheng-ben-inference" class="header-anchor"></a></h2><p>如何在低成本设备上使用这些模型？如单张GPU 上跑大模型或普通CPU 上跑模型。这个方向的工作也有<a href="https://github.com/FMInference/FlexGen" target="_blank" rel="noopener">FlexGen</a>/<a href="https://github.com/ggerganov/llama.cpp" target="_blank" rel="noopener">llama.cpp</a> 等。</p><h2><span id="di-cheng-ben-you-hua">低成本优化</span><a href="#di-cheng-ben-you-hua" class="header-anchor"></a></h2><p>低成本fine-tuning 主要有两个方向：parameter-efficient / sample-efficient.</p><ul><li>parameter-efficient 的思路目前主要有prompt-tuning/prefix-tuning/LoRA/Adapter 等，参考<a href="https://github.com/huggingface/peft" target="_blank" rel="noopener">huggingcae/peft</a></li><li>sample-efficient 可以帮助我们如何更有效的构造训练集，最近的工作有<a href="http://arxiv.org/abs/2303.08114" target="_blank" rel="noopener">Simfluence: Modeling the Influence of Individual Training Examples by Simulating Training Runs</a></li></ul><h2><span id="you-hua-qi">优化器</span><a href="#you-hua-qi" class="header-anchor"></a></h2><p>优化器决定了我们训练时需要的资源。虽然我们通常使用Adam 优化器，但是其需要2倍额外显存，而google 好像用Adafactor 更多一点，最近他们又出了一个新工作<a href="https://arxiv.org/abs/2302.06675" target="_blank" rel="noopener">Lion</a>.</p><h2><span id="geng-ke-kong">更可控</span><a href="#geng-ke-kong" class="header-anchor"></a></h2><p>如从可控生成角度看，目前可控主要通过control token（prompt）来实现，有没有更好的办法来实现更“精细”的控制，就如controlnet 之于stable diffusion。</p><h2><span id="shi-bie-aigc">识别AIGC</span><a href="#shi-bie-aigc" class="header-anchor"></a></h2><p>如何判别内容是人写的还是模型生成的呢？随着模型的性能越来越强，识别AIGC 也越来越困难。目前的工作也有watermark/<a href="https://gptzero.me/" target="_blank" rel="noopener">GPTZero</a> 等。不过我感觉还没什么特别有效的方案目前。<br>对此我有个简单的思路：将AI 生成的与非AI 生成的看作是两种不同的语言，如code 与英语一样，虽然都是相同符合构成，但是对应不同语言。使用大量的AI 生成的内容（或人机交互数据）pretrain 一个”AI 语言模型“，再来进行识别。</p><h2><span id="dan-yi-ren-wu-ling-yu-shua-bang">单一任务/领域刷榜</span><a href="#dan-yi-ren-wu-ling-yu-shua-bang" class="header-anchor"></a></h2><p>我认为在某个任务/领域上通过小模型挑战大模型依然有意义，LLM 虽然强大，但是依然有太多我们不知道的能力，通过小模型刷榜也许能提供一些思路，就像PET 本意是调战GPT-3，却打开了LLM 的新思路。</p><h1><span id="he-qu-he-cong">何去何从</span><a href="#he-qu-he-cong" class="header-anchor"></a></h1><h2><span id="pu-tong-gong-cheng-shi">普通工程师</span><a href="#pu-tong-gong-cheng-shi" class="header-anchor"></a></h2><p>这种新的革命性的技术我们普通工程师通常都不是第一线的，我第一次真正使用bert 也是在其出来两年后了。即使今天，也有很多场景/公司不使用bert这个技术。<br>换个角度，即使我们想参与，我想能参与训练/fine-tuning 一个10B 规模模型的工程师都相当少，更别提更大的了。所以到底是“左右逢源”还是“举步维艰”，让子弹飞一会儿吧。</p><h2><span id="pu-tong-yong-hu">普通用户</span><a href="#pu-tong-yong-hu" class="header-anchor"></a></h2><p>普通用户我觉得应该就是多读书，提高自己的鉴别能力了。”生活中不缺少美，而是缺少发现美的眼睛。”</p><h1><span id="fan-wai">番外</span><a href="#fan-wai" class="header-anchor"></a></h1><h2><span id="tong-guo-prompt-gou-jian-ji-zhu-bi-lei-shen-qing-prompt-zhuan-li">通过prompt 构建技术壁垒/申请prompt 专利</span><a href="#tong-guo-prompt-gou-jian-ji-zhu-bi-lei-shen-qing-prompt-zhuan-li" class="header-anchor"></a></h2><p>随着alignment 的进一步优化，LLM 通常越来越理解自然语言，所以我认为prompt-trick 越来越不重要，而清晰准备的用prompt 描述你的需求越来越重要。所谓技术壁垒也许就是如何更清晰有效的描述需求了，但也很难形成技术壁垒。<br>至于专利，软件著作权保护的是制作软件这个技术本身，而非你使用软件时的姿势，所以我想单独的prompt 应该也不会形成专利，但是作为你某个技术的一部分，还是有可能的。</p><h2><span id="hui-bu-hui-shi-ye">会不会失业</span><a href="#hui-bu-hui-shi-ye" class="header-anchor"></a></h2><p>我认为不会失业，但是会转变一部分人的工作方式。在计算这件事上，人类早已被计算机远远的甩在后面，而计算机的出现也带来了大量的新工作。尤其是LLM 现阶段的表现是“懂开车的人才能开车”，所以需要更多更懂某个业务，更熟练使用LLM 工具的人。</p><h1><span id="guan-yu-tou-tu">关于头图</span><a href="#guan-yu-tou-tu" class="header-anchor"></a></h1><p>放张动漫图，据说能缓解焦虑</p><h1><span id="buy-me-a-coffee">Buy me a coffee</span><a href="#buy-me-a-coffee" class="header-anchor"></a></h1><p>如果觉得这篇文章不错，对你有帮助，欢迎打赏一杯蜜雪冰城。</p><p><img src="/img/sponsor.JPG" alt="赞赏"></p><script src="https://giscus.app/client.js" data-repo="xv44586/giscus" data-repo-id="R_kgDOIC6Ipg" data-category="Announcements" data-category-id="DIC_kwDOIC6Ips4CRkmo" data-mapping="pathname" data-strict="0" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="bottom" data-theme="preferred_color_scheme" data-lang="zh-CN" crossorigin="anonymous" async></script><div class="content-footer-sponsor"><h1><span id="sponsor">Buy me a coffee</span></h1><p>如果觉得这篇文章不错，对你有帮助，欢迎打赏一杯蜜雪冰城。</p><img src="/img/sponsor.JPG" alt="logo" title="sponsor"></div><div class="post__prevs"><div class="post__prev"><a href="/2023/03/10/llm-inf/" title="LLM Inference串讲"><i class="iconfont icon-prev"></i>LLM Inference串讲</a></div><div class="post__prev post__prev--right"></div></div></div></article><script src="https://giscus.app/client.js" data-repo="xv44586/giscus" data-repo-id="R_kgDOIC6Ipg" data-category="Announcements" data-category-id="DIC_kwDOIC6Ips4CRkmo" data-mapping="pathname" data-strict="0" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="bottom" data-theme="light" data-lang="zh-CN" crossorigin="anonymous" async></script></div><aside class="page__sidebar"><form id="page-search-from" class="page__search-from" action="/search/"><label class="search-form__item"><input class="input" type="text" name="search" placeholder="Search..."> <i class="iconfont icon-search"></i></label></form><div class="sidebar__block"><h3 class="block__title">简介</h3><p class="block__text">NLP | Machine Learning | Developer</p></div><div class="sidebar__block"><h3 class="block__title">文章分类</h3><ul class="block-list"><li class="block-list-item"><a class="block-list-link" href="/categories/Programming/">Programming</a><span class="block-list-count">4</span></li><li class="block-list-item"><a class="block-list-link" href="/categories/NLP/">NLP</a><span class="block-list-count">33</span></li><li class="block-list-item"><a class="block-list-link" href="/categories/Math/">Math</a><span class="block-list-count">5</span></li><li class="block-list-item"><a class="block-list-link" href="/categories/MachineLearning/">MachineLearning</a><span class="block-list-count">8</span></li><li class="block-list-item"><a class="block-list-link" href="/categories/Life/">Life</a><span class="block-list-count">6</span></li></ul></div><div class="sidebar__block"><h3 class="block__title">最新文章</h3><ul class="block-list latest-post-list"><li class="latest-post-item"><a href="/2023/03/25/gpt4/" title="GPT-4 yes!! but"><div class="item__cover"><img src="/2023/03/25/gpt4/bg.jpeg" alt="GPT-4 yes!! but"></div><div class="item__info"><h3 class="item__title">GPT-4 yes!! but</h3><span class="item__text">2023-03-25</span></div></a></li><li class="latest-post-item"><a href="/2023/03/10/llm-inf/" title="LLM Inference串讲"><div class="item__cover"><img src="/2023/03/10/llm-inf/sd.PNG" alt="LLM Inference串讲"></div><div class="item__info"><h3 class="item__title">LLM Inference串讲</h3><span class="item__text">2023-03-10</span></div></a></li><li class="latest-post-item"><a href="/2023/02/01/fine-tuning-at-few-shot/" title="few-shot视角下的fine-tuning"><div class="item__cover"><img src="/2023/02/01/fine-tuning-at-few-shot/himalayas.JPG" alt="few-shot视角下的fine-tuning"></div><div class="item__info"><h3 class="item__title">few-shot视角下的fine-tuning</h3><span class="item__text">2023-02-01</span></div></a></li><li class="latest-post-item"><a href="/2023/01/09/zero-to-chatgpt/" title="From zero to ChatGPT"><div class="item__cover"><img src="/2023/01/09/zero-to-chatgpt/chatgpt-bg.jpeg" alt="From zero to ChatGPT"></div><div class="item__info"><h3 class="item__title">From zero to ChatGPT</h3><span class="item__text">2023-01-09</span></div></a></li></ul></div><div class="sidebar__block"><h3 class="block__title">文章标签</h3><ul class="block-list tag-list clearfix"><li class="tag-item"><a class="tag-link" href="/tags/BERT/">BERT</a></li><li class="tag-item"><a class="tag-link" href="/tags/BPE/">BPE</a></li><li class="tag-item"><a class="tag-link" href="/tags/Bagging/">Bagging</a></li><li class="tag-item"><a class="tag-link" href="/tags/Boosting/">Boosting</a></li><li class="tag-item"><a class="tag-link" href="/tags/CCF/">CCF</a></li><li class="tag-item"><a class="tag-link" href="/tags/CRF/">CRF</a></li><li class="tag-item"><a class="tag-link" href="/tags/CUDA/">CUDA</a></li><li class="tag-item"><a class="tag-link" href="/tags/ChatGPT/">ChatGPT</a></li><li class="tag-item"><a class="tag-link" href="/tags/Classification/">Classification</a></li><li class="tag-item"><a class="tag-link" href="/tags/Competition/">Competition</a></li><li class="tag-item"><a class="tag-link" href="/tags/Deep-Learning/">Deep Learning</a></li><li class="tag-item"><a class="tag-link" href="/tags/Distillation/">Distillation</a></li><li class="tag-item"><a class="tag-link" href="/tags/EDA/">EDA</a></li><li class="tag-item"><a class="tag-link" href="/tags/FastBERT/">FastBERT</a></li><li class="tag-item"><a class="tag-link" href="/tags/Few-shot/">Few-shot</a></li><li class="tag-item"><a class="tag-link" href="/tags/GPT-3/">GPT-3</a></li><li class="tag-item"><a class="tag-link" href="/tags/GPT-4/">GPT-4</a></li><li class="tag-item"><a class="tag-link" href="/tags/GPU/">GPU</a></li><li class="tag-item"><a class="tag-link" href="/tags/Game/">Game</a></li><li class="tag-item"><a class="tag-link" href="/tags/Glove/">Glove</a></li><li class="tag-item"><a class="tag-link" href="/tags/Hexo/">Hexo</a></li><li class="tag-item"><a class="tag-link" href="/tags/In-context-learning/">In-context learning</a></li><li class="tag-item"><a class="tag-link" href="/tags/Inference/">Inference</a></li><li class="tag-item"><a class="tag-link" href="/tags/LLM/">LLM</a></li><li class="tag-item"><a class="tag-link" href="/tags/LR/">LR</a></li><li class="tag-item"><a class="tag-link" href="/tags/Language-Model/">Language Model</a></li><li class="tag-item"><a class="tag-link" href="/tags/Loss/">Loss</a></li><li class="tag-item"><a class="tag-link" href="/tags/MarkDown/">MarkDown</a></li><li class="tag-item"><a class="tag-link" href="/tags/Math/">Math</a></li><li class="tag-item"><a class="tag-link" href="/tags/Matrix/">Matrix</a></li><li class="tag-item"><a class="tag-link" href="/tags/NLG/">NLG</a></li><li class="tag-item"><a class="tag-link" href="/tags/Optimizer/">Optimizer</a></li><li class="tag-item"><a class="tag-link" href="/tags/Python/">Python</a></li><li class="tag-item"><a class="tag-link" href="/tags/QA/">QA</a></li><li class="tag-item"><a class="tag-link" href="/tags/R-Drop/">R-Drop</a></li><li class="tag-item"><a class="tag-link" href="/tags/Random-Forest/">Random Forest</a></li><li class="tag-item"><a class="tag-link" href="/tags/Segmentation/">Segmentation</a></li><li class="tag-item"><a class="tag-link" href="/tags/SimCSE/">SimCSE</a></li><li class="tag-item"><a class="tag-link" href="/tags/Statistics/">Statistics</a></li><li class="tag-item"><a class="tag-link" href="/tags/Survey/">Survey</a></li><li class="tag-item"><a class="tag-link" href="/tags/T5/">T5</a></li><li class="tag-item"><a class="tag-link" href="/tags/UniLM/">UniLM</a></li><li class="tag-item"><a class="tag-link" href="/tags/Unigram/">Unigram</a></li><li class="tag-item"><a class="tag-link" href="/tags/WordPiece/">WordPiece</a></li><li class="tag-item"><a class="tag-link" href="/tags/Words-Distance/">Words Distance</a></li><li class="tag-item"><a class="tag-link" href="/tags/Xgboost/">Xgboost</a></li><li class="tag-item"><a class="tag-link" href="/tags/debug/">debug</a></li><li class="tag-item"><a class="tag-link" href="/tags/faster-decoder/">faster decoder</a></li><li class="tag-item"><a class="tag-link" href="/tags/fine-tuning/">fine-tuning</a></li><li class="tag-item"><a class="tag-link" href="/tags/horovod/">horovod</a></li><li class="tag-item"><a class="tag-link" href="/tags/multi-task/">multi-task</a></li><li class="tag-item"><a class="tag-link" href="/tags/nohup/">nohup</a></li><li class="tag-item"><a class="tag-link" href="/tags/npm/">npm</a></li><li class="tag-item"><a class="tag-link" href="/tags/simbert/">simbert</a></li><li class="tag-item"><a class="tag-link" href="/tags/skipgram/">skipgram</a></li><li class="tag-item"><a class="tag-link" href="/tags/speed-up/">speed-up</a></li><li class="tag-item"><a class="tag-link" href="/tags/swift/">swift</a></li><li class="tag-item"><a class="tag-link" href="/tags/tensorflow-gpu/">tensorflow-gpu</a></li><li class="tag-item"><a class="tag-link" href="/tags/word2vec/">word2vec</a></li><li class="tag-item"><a class="tag-link" href="/tags/信息熵/">信息熵</a></li><li class="tag-item"><a class="tag-link" href="/tags/新词发现/">新词发现</a></li><li class="tag-item"><a class="tag-link" href="/tags/样本不均衡/">样本不均衡</a></li><li class="tag-item"><a class="tag-link" href="/tags/装机/">装机</a></li><li class="tag-item"><a class="tag-link" href="/tags/领域词挖掘/">领域词挖掘</a></li></ul></div></aside></main><footer class="page__footer"><section class="footer__top"><div class="page__container footer__container"><div class="footer-top__item footer-top__item--2"><h3 class="item__title">关于</h3><div class="item__content"><p class="item__text">本站是基于 Hexo 搭建的静态资源博客，主要用于分享日常学习、生活及工作的一些心得总结。</p><ul class="footer__contact-info"><li class="contact-info__item"><i class="iconfont icon-address"></i> <span>Beijing, China</span></li><li class="contact-info__item"><i class="iconfont icon-email2"></i> <span>xv44586@gmail.com</span></li></ul></div></div><div class="footer-top__item"><h3 class="item__title">友情链接</h3><div class="item__content"><ul class="footer-top__list"><li class="list-item"><a href="http://www.matrix67.com/" title="Matrix67" target="_blank">Matrix67</a></li><li class="list-item"><a href="https://spaces.ac.cn/" title="Spaces" target="_blank">科学空间</a></li></ul></div></div></div></section><section class="footer__bottom"><div class="page__container footer__container"><p class="footer__copyright">© <a href="https://github.com/Mrminfive/hexo-theme-skapp" target="_blank">Skapp</a> 2017 powered by <a href="http://hexo.io/" target="_blank">Hexo</a>, made by <a href="https://github.com/Mrminfive" target="_blank">minfive</a>. modified by <a href="https://github.com/xv44586" target="_blank">小蛋子</a></p><ul class="footer__social-network clearfix"><li class="social-network__item"><a href="https://github.com/xv44586" target="_blank" title="github"><i class="iconfont icon-github"></i></a></li><li class="social-network__item"><a href="xv44586@gmail.com" target="_blank" title="email"><i class="iconfont icon-email"></i></a></li></ul></div></section></footer><div id="back-top" class="back-top back-top--hidden js-hidden"><i class="iconfont icon-top"></i></div></div><script src="/js/common.js"></script><script src="/js/page/post.js"></script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
            tex2jax: {
                inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
                processEscapes: true,
                skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
            }
            });</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
            var all = MathJax.Hub.getAllJax(), i;
                for (i=0; i < all.length; i += 1) {
                all[i].SourceElement().parentNode.className += ' has-jax';
                }
            });</script><script type="text/javascript" src="//cdn.jsdelivr.net/npm/mathjax@2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script></body></html>