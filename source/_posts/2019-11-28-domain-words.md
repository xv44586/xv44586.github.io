---
title: 带约束的领域词挖掘
author:
  nick: 小蛋子
  link: 'https://www.github.com/xv44586'
date: 2019-11-28 15:31:41
tags: 
    - 新词发现
    - 领域词挖掘
    - 信息熵
categories: NLP
cover: /2019/11/28/domain-words/cover.jpeg
---
<!-- toc -->

# 背景

分享一个最近做的项目方案，背景是当前的内容标签是最细粒度到一级大类，而产品希望出一些三级小类（当前最细分类）的标签，而且这些标签应该是有别于其他三级小类的。

# 方案

我将其看作是领域词挖掘任务，只是这个任务带有一些约束，及这些领域词是个性化的，与其他小类内的领域词是不同的。
所以，需要做的是抽词（新词发现）+领域词挖掘+个性化判断。
由于之前做过新词发现，主要参考[互联网时代的社会语言学：基于SNS的文本数据挖掘](http://www.matrix67.com/blog/archives/5044),
对应的java实现[dict_build](https://github.com/xv44586/dict_build)。
除了无监督抽词外，matrix67的博文后面半部分也很有意思：通过对两份语料进行抽词，然后对词进行词频统计，通过对比词在两份语料内的词频差异，来发现“热词”。
回到现在的任务，个性化的词，必定在当前小类内相对于其他小类更“热”，我们可以将当前小类内的词与非当前小类进行对比，就能得到当前小类的“热词”，
有了热词，我们在判断这些“热词”是不是领域词，即可得到想要的结果。而实际上，由于一级大类之间的词已经有很大差异，所以，我们在抽当前小类“热词”时，不必对全量非当前小类语料进行统计，只需要对其一级大类内非当前小类语料进行统计对比，即可得到“热词”。
而对于领域词判断，由于我们已经有了一级大类的标签，我们可以利用这部分信息来进行领域词判断。
所以，最终的方案是先抽词，然后对词进行领域词判断，对词进行是否是“热词”判断，对领域词与热词进行求交运算，得到个性化的领域词。

## 实验

实际处理时，由于我们挖掘的“词”其实更像是一个短语，其长度也比词稍长，而“词”的组合上限是${CharCount}^{WordLength}$，而字符大概有12000+， 词平均长度假如是7，这个量也是相当大的。
所以抽词对内存要求很高，而且非常耗时（10h+).在思考如何优化抽词程序时，看到了[分享一次专业领域词汇的无监督挖掘](https://kexue.fm/archives/6540)，作者的思路与我的思路一样，不过不同的是，
作者在抽词时，并没有沿用matrix67的博文中根据凝合度与信息熵来进行是否成词判断，而且用信息熵是否低于某个阈值，来判断是否切开，即为两个词，这个思路还是非常巧妙的，这样，不光计算量减小了很多，而且不在需要设置超参数中ngram的值，
挖掘出的词也更符号“语义完整性”；而领域词判断，作者采用的是通过语料训练词向量，再由种子词来扩展领域词，也不失为一个好思路。

## 实验结果

从结果上看，效果还是很不错的。
![热词结果](/2019/11/28/domain-words/words.png)
热词结果
![领域词结果](/2019/11/28/domain-words/keywords.png)
领域词结果
![最终结果](/2019/11/28/domain-words/result.png)
最终挖掘的个性化领域词

# 总结

## 优点
挖掘领域词任务中，首先是如何对"词"进行判断，然后才是"领域词"判断，所以影响最终结果好坏的主要因素也是"词"划分的质量与"领域词"判断的准确性。
上述方案中，通过用信息熵的最小阈值来判断相邻两个字是否属于同一个词内来进行分词，优点是速度快，能切分出高频的短语；
通过种子词在词向量空间来一层一层挖掘领域词，主要思路是近邻的近邻，虽然与你"直线距离"稍远，但通过你的近邻点跳转后"距离"近，这样来扩大召回，所以通过少量种子点即可召回出大量"近邻"词。

## 缺点
缺点也很明显，首先分词时，容易将常用搭配错误切分，如html容易切出 *h/tml,的xxx容易切分为一个词，所以需要写一些规则过滤掉明显错误切分的词；种子词在召回时，由于词向量用的是word2vec这种静态词向量，近邻容易跳出当前domain，如用"华为"做种子词，直接聚类出"小米"/"苹果"，而苹果的近邻就可能跳出手机品牌，
转向水果，如"西瓜"/"桃子"，所以需要控制扩散的层次深度。

## 分享
机器学习中最重要的一个思路就是寻找差异，找到合理的差异往往是解决问题的关键。本次分享了一个通过对比差异来进行领域词挖掘的例子，希望给做类似任务的同学一些思路。

# 关于头图
摄于奥森