<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>小蛋子</title>
  
  <subtitle>小蛋子</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://xv44586.github.io/"/>
  <updated>2020-11-08T04:45:02.602Z</updated>
  <id>https://xv44586.github.io/</id>
  
  <author>
    <name>[object Object]</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>ccf_qa</title>
    <link href="https://xv44586.github.io/2020/11/08/ccf-qa/"/>
    <id>https://xv44586.github.io/2020/11/08/ccf-qa/</id>
    <published>2020-11-08T02:44:15.000Z</published>
    <updated>2020-11-08T04:45:02.602Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><div class="toc"><!-- toc --><ul><li><a href="#bi-sai-shuo-ming">比赛说明</a></li><li><a href="#baseline">baseline</a><ul><li><a href="#qa-pair">qa pair</a></li><li><a href="#point">point</a></li><li><a href="#pet">pet</a></li></ul></li><li><a href="#dui-bi">对比</a></li><li><a href="#chang-shi">尝试</a><ul><li><a href="#post-training">Post-training</a></li><li><a href="#focal-loss">focal loss</a></li><li><a href="#dui-kang-xun-lian-yu-ti-du-cheng-fa">对抗训练与梯度惩罚</a></li><li><a href="#tricks">tricks</a></li></ul></li><li><a href="#zong-jie">总结</a></li><li><a href="#guan-yu-tou-tu">关于头图</a></li></ul><!-- tocstop --></div><p>这两周玩了一下ccf 2020 中的<a href="https://www.datafountain.cn/competitions/474" target="_blank" rel="noopener">房产聊天问答匹配</a>比赛，虽然还没完赛，但是先总结一下目前的收获。</p><h1><span id="bi-sai-shuo-ming">比赛说明</span><a href="#bi-sai-shuo-ming" class="header-anchor"></a></h1><p>首先，这个比赛的任务是在一系列回答中找到针对客户问题的回答。而客户提问前的对话及回答前的对话都是不可见的，即整个IM信息是不连续的，任务就是在不连续的回答中找到那些针对客户问题的答案。样本示例：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">query: 采荷一小是分校吧。</span><br><span class="line">reply:</span><br><span class="line">  是的  <span class="number">0</span></span><br><span class="line">  杭州市采荷第一小学钱江苑校区，杭州市钱江新城实验学校。  <span class="number">1</span></span><br><span class="line">  这是五楼  <span class="number">0</span></span><br></pre></td></tr></table></figure></p><p>可以看到，样本中所谓的针对问题的回答，不仅仅是直接回答问题的答案，而是更有针对性和说明的回答。</p><h1><span id="baseline">baseline</span><a href="#baseline" class="header-anchor"></a></h1><p>模型选择上，baseline全部使用bert，鉴于相对位置编码优于绝对位置编码，所以选择<a href="https://github.com/huawei-noah/Pretrained-Language-Model/tree/master/NEZHA-TensorFlow" target="_blank" rel="noopener">NEZHA</a>作为预训练权重。备选方案Roberta。</p><h2><span id="qa-pair">qa pair</span><a href="#qa-pair" class="header-anchor"></a></h2><p>由于回答是不连续的，所以可以将问题和答案一一对应，组成qa pair，然后分别判断是否是针对问题的回答。</p><p><img src="/2020/11/08/ccf-qa/pair.png" alt="pair"></p><h2><span id="point">point</span><a href="#point" class="header-anchor"></a></h2><p>虽然对话是不连续的，但是是同一个对话，所以不同的回答能相互支撑，提供部分信息，所以，第二种思路就是将同一个问题的所有回答都拼接在当前回答后面，然后同时对每一个回答进行判断。</p><p><img src="/2020/11/08/ccf-qa/point.png" alt="point"></p><h2><span id="pet">pet</span><a href="#pet" class="header-anchor"></a></h2><p>由于预训练模型使用的语料与当前任务所处领域有一定的gap，所以一个比较简单的想法是先在任务语料上进行Post-training，然后再进行fine-tuning。不过，上次我们介绍过<code>Pattern-Exploiting Training</code>,不了解的可以参考<a href="https://xv44586.github.io/2020/10/25/pet/">PET-文本分类的又一种妙解</a>。借鉴PET的方式，我们将posting-training与fine-tuning结合，即在label data上进行pattern exploiting training，在unlable data上进行mlm任务进行post-traing.</p><p><img src="/2020/11/08/ccf-qa/pet.png" alt="pet"></p><p>以上三种baseline的代码放在<a href="https://github.com/xv44586/ccf_2020_qa_match" target="_blank" rel="noopener">ccf_2020_qa_match</a>,感兴趣的可以查阅。</p><h1><span id="dui-bi">对比</span><a href="#dui-bi" class="header-anchor"></a></h1><p>第一种方案（pair-wise），由于缺少一定的上下文信息，加上很多回答都非常短，同时又可能会离提问”较远”，所以效果是最差的，不过线上提交单模型也有0.75左右了，所以bert确实强大！<br>第二种方案（point）中，将所有已知的上下文信息都整合到一起，所以相对上一种有所提升，不过由于这种上下文的可见性，所以也会带来一定的迷惑：即对某一个reply来说，假如其他的reply中有一个是针对性的回答，就有可能会干扰对当前reply的判断。<br>第三种方案（pet）中，通过mlm进行post-training，可以将领域间的gap缩小，同时，由于在训练时”看到”了测试数据，也在一定程度上减小了线上线下的差距，所以性能是最好的，单模型最好能达到0.765左右。</p><h1><span id="chang-shi">尝试</span><a href="#chang-shi" class="header-anchor"></a></h1><h2><span id="post-training">Post-training</span><a href="#post-training" class="header-anchor"></a></h2><p>第一个想法是尝试进行post-training，来提升所有方案的性能。由于问答之间是不连续的，所以在组织语料上进行了不同方式：</p><ol><li>query reply1 reply2 \n…</li><li>query \n  reply1 \n reply2 \n…</li><li>sentence_left \n sentence_right \n …</li></ol><p>第一种，将同一对话作为同一篇文档顺序排列；第二种，将问题作为单独文档，同一问题的所有回答作为单独文档，第三种，将问题和回答都作为单独文档，同时将其拆分为左右两个部分来做nsp任务。<br>在mask选择上，选择动态mask，即每个epoch都重新选择mask的token。<br>最终结果是以上三种都不能带来pair-wise方案的提升，反而会带来不小的降低，猜测原因可能与以上三种方式的nsp任务与当前任务的模式不同，所以反而会引起降低。</p><h2><span id="focal-loss">focal loss</span><a href="#focal-loss" class="header-anchor"></a></h2><p>由于针对性回答与非针对性回答在数量上有不小差距，大约3:1，所以也想到尝试在loss上进行调节。<br>最终结果是没有多少提升，最后将普通loss训练后的模型在train data上进行了predict，并借鉴之前<a href="https://xv44586.github.io/2020/10/14/focal-loss/">focal loss</a>中的方式分析了一下，发现其难样本并不多也不聚集，所以focal loss并不难带来提升。</p><h2><span id="dui-kang-xun-lian-yu-ti-du-cheng-fa">对抗训练与梯度惩罚</span><a href="#dui-kang-xun-lian-yu-ti-du-cheng-fa" class="header-anchor"></a></h2><p>对抗训练与梯度惩罚也是两种比较有效的提升模型泛化性能的方法。其中对抗采用的FGM。<br>最终实验后发现两者都能带来线上线下的提升，尤其是对抗，最高能提升三个点，不过相同参数下结果也会差二个点左右，所以每个模型都要少不了调参的过程，所以适合后期提高时使用。</p><h2><span id="tricks">tricks</span><a href="#tricks" class="header-anchor"></a></h2><p>由于也是第一次做比赛，所以走了不少弯路，也学到了一些trick：</p><ol><li>对样本进行kfold然后训练，得到k个模型再进行ensemble。其中k从5增加到10，也会有提升。这种方式的好处是可以让更多的数据参与到训练，同时多个模型进行投票，也会带来或多或少的提升。</li><li>对数据进行post-training，虽然我的尝试暂时没有起到提升，但是交流时有其他组的同学通过这个方法就达到单模型0.77以上。而我三种方案对比，pet的方式也是最好的，所以也在一定程度上说明这种方式的有效性。</li><li>bert后接新的层，如cnn,dgcnn等。虽然bert的特征提取能力强大，但是在bert后面接一些新的层，总能带来一定的提升，尤其是DGCNN。这种方式可以看作是两种模型的stacking，即利用bert做特征提取，后面的模型在其上做下游任务。</li><li>不同模型进行ensemble，如将上述三种方案进行ensemble，由于不同模型关注点不同，融合后会带来一定提升。</li><li>更大的模型，如bert-xxlarge等。虽然我的显卡没法实验这种方案，但是交流后发现很多同学都是使用的大模型，baseline就可以达到0.77以上了，所以有时候还是需要一些”钞能力”.</li><li>数据清洗与增强。交流中有人提到用外部数据做增强，所以如果有能力，先做清洗与增强，结果也会提升很多。</li></ol><h1><span id="zong-jie">总结</span><a href="#zong-jie" class="header-anchor"></a></h1><p>以上就是对当前比赛的一些思考与总结，现在单模型最好的成绩为线上<code>0.7779</code>, 虽然只排到61名，不过鉴于我使用的是base模型，同时也是单模型，没有任何其他后续处理，所以结果感觉还行。后续完赛后如果有新的收获再更新一篇吧。最后，附上暂时排名截图。</p><p><img src="/2020/11/08/ccf-qa/leadboard.png" alt></p><h1><span id="guan-yu-tou-tu">关于头图</span><a href="#guan-yu-tou-tu" class="header-anchor"></a></h1>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;/assets/css/APlayer.min.css&quot;&gt;&lt;script src=&quot;/assets/js/APlayer.min.js&quot; cla
      
    
    </summary>
    
    
      <category term="NLP" scheme="https://xv44586.github.io/categories/NLP/"/>
    
    
      <category term="QA" scheme="https://xv44586.github.io/tags/QA/"/>
    
      <category term="CCF" scheme="https://xv44586.github.io/tags/CCF/"/>
    
  </entry>
  
  <entry>
    <title>PET-文本分类的又一种妙解</title>
    <link href="https://xv44586.github.io/2020/10/25/pet/"/>
    <id>https://xv44586.github.io/2020/10/25/pet/</id>
    <published>2020-10-25T03:30:31.000Z</published>
    <updated>2020-10-27T13:11:56.892Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><div class="toc"><!-- toc --><ul><li><a href="#classification-to-nlg">Classification to NLG</a></li><li><a href="#mlm">MLM</a></li><li><a href="#ren-wu-zhuan-huan">任务转换</a></li><li><a href="#pattern-exploiting-training">Pattern-Exploiting Training</a></li><li><a href="#yu-nlg-chai-yi">与NLG差异</a></li><li><a href="#shi-yan">实验</a></li><li><a href="#zong-jie">总结</a></li><li><a href="#guan-yu-tou-tu">关于头图</a></li></ul><!-- tocstop --><p></div><br>之前的一篇<a href="https://xv44586.github.io/2020/09/13/classification-label-augment/">《模型增强-从label下手》</a>中，我们提到了通过转换label，将分类转换为NLG的方法，而由于性能没有得到增加，所以就没有继续往下做。今天看到两篇文章，思路略微相似，也让我眼前一亮，发现原来我与顶会思路这么近（误），所以总结对比一下。</p><h1><span id="classification-to-nlg">Classification to NLG</span><a href="#classification-to-nlg" class="header-anchor"></a></h1><p>对于分类任务，我们可以将其转换为一个生成任务。比如此时我们有一个样本：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"context：'「天天特价房」华庭仁和国际 3室2厅2卫仅售65万', label: '房产', label_id: 0"</span></span><br></pre></td></tr></table></figure></p><p>通常我们直接预测对应的label id，而由于其也有label，所以我们可以将其转换为一个NLG任务，即：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"context：['「天天特价房」华庭仁和国际 3室2厅2卫仅售65万', '房产']"</span></span><br></pre></td></tr></table></figure></p><p>即通过样本生成label对应的token。借助UniLM同时具有NLU与NLG的能力，只需要很小的改动就可以利用BERT做该任务了，对应的示意图如下：<br><img src="/2020/10/25/pet/unilm.png" alt></p><p>不过当时考虑到UniLM中提到seq2seq的训练<code>不能</code>提高NLU的能力，所以当时并没有选择使用MLM来尝试，最后得到的结论是：</p><p>1.<em> 将分类转为生成后，性能基本一致；</em><br>2.<em> 将分类与生成联合起来训练，性能与单个任务性能基本一致。</em></p><h1><span id="mlm">MLM</span><a href="#mlm" class="header-anchor"></a></h1><p>MLM,即Masked Language Model,中文翻译又叫“掩码语言模型”，即以自监督的方式，mask 掉一部分，然后通过剩余的部分来还原被mask 掉的部分，示意图如下：<br><img src="/2020/10/25/pet/mlm.png" alt></p><p>而mask的方式也有多种，如随机选择token进行mask；将token所在的整个词都mask（whole word mask）；或者将某个span内的token都mask掉（span mask）。<br>虽然mlm在预训练任务上已经被证明十分有效，但是通常认为mlm部分的参数是与mlm任务相关的，而通常在下游任务中我们是别的任务，所以会舍弃掉这部分参数，而只使用encoder部分。<br>但是论文<a href="http://arxiv.org/abs/2009.07118" target="_blank" rel="noopener">It’s Not Just Size That Matters: Small Language Models Are Also Few-Shot Learners</a>与<a href="http://arxiv.org/abs/2001.07676" target="_blank" rel="noopener">Exploiting Cloze Questions for Few Shot Text Classification and Natural Language Inference</a>却告诉我们，mlm不仅有用，在few-shot场景下，通过一下简单的融合手段，性能能超过当前的明星GPT-3.</p><h1><span id="ren-wu-zhuan-huan">任务转换</span><a href="#ren-wu-zhuan-huan" class="header-anchor"></a></h1><p>与之前的思路类似，我们针对分类任务，不再直接对label进行预测，而是预测其label description，即将其转换为完形填空形式的任务，来预测不同label description的概率。<br>而如何转换成完形填空呢？也很简单，我们添加一个简单的语义通顺的描述，然后将其中与分类有关的内容mask掉即可。举个例子：<br>假如我们现在的任务是短文本分类，一个样本为“context：’「天天特价房」华庭仁和国际 3室2厅2卫仅售65万’, label: ‘房产’”，我们添加一个统一的描述句，将其变为：<br>“下面是一则__相关新闻标题: 「天天特价房」华庭仁和国际 3室2厅2卫仅售65万”,其中的空格可选的内容是所有的label description，对应的真实值是”房产”两个字，这样，我们就将分类任务转换为一个完形填空的形式。<br>而添加的方式也可以分为前缀、后缀两种，完整的方式：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"以下是一则__相关新闻标题: 「天天特价房」华庭仁和国际 3室2厅2卫仅售65万"</span></span><br><span class="line"><span class="string">"「天天特价房」华庭仁和国际 3室2厅2卫仅售65万，以上是一则__相关新闻标题"</span></span><br></pre></td></tr></table></figure></p><h1><span id="pattern-exploiting-training">Pattern-Exploiting Training</span><a href="#pattern-exploiting-training" class="header-anchor"></a></h1><p>上面我们添加的前缀/后缀句子称为<code>Pattern</code>, 而label description可以有多种方式，比如，对于“房产”这个label，我们也可以用“地产”来表达，对于“娱乐”label，也可以用“八卦”来表达，所以需要一个token到label的映射，这个映射可以是多对一的，这个被称为<code>Verbalizer</code>,所以在预测时可以将多个token的概率结合起来判断其对应的label。<br>由于是few-shot，为了提高性能，作者采用了与Knowledge Distillation类似的思路，具体方案如下：</p><p>1.<em> 对每个Pattern利用多个pre-train model 进行fine-tuning，得到多个模型.其中$loss=L_{ce} + L_{mlm}$;</em><br>2.<em> 将多个模型的结果进行融合，得到一个融合模型Teacher Model；</em><br>3.<em> 利用Teacher Model在大量unlabed数据上进行预测，得到对应的soft labels；</em><br>4.<em> 利用soft labels数据，训练一个常规的分类模型（非MLM模型）。</em></p><p>以上就是论文<a href="http://arxiv.org/abs/2001.07676" target="_blank" rel="noopener">Exploiting Cloze Questions for Few Shot Text Classification and Natural Language Inference</a>中提到的PET。<br>此外，该论文中还提到了一个改进：iPET。其中的区别是：在ipet中，得到mlm的多个model后，增加一个迭代：每次会从训练mlm的model中抽取一个$m_i$，然后从剩余的model中选取一部分对unlabeled data进行预测，将其中预测结果确定（不是准确，此时意味着结果的熵很小）的部分打上一个fake label，让$m_i$进行训练。重复多次后，融合模型对unlabeled data进行预测，得到一个soft labels data，在此基础上训练一个常规分类器。</p><p>可以看到，PET的方式主要适用label description为有限空间，即选择题，此外，每个样本的label description需要长度相同，而且由于mask之间相互独立，所以长度也不能太长。</p><h1><span id="yu-nlg-chai-yi">与NLG差异</span><a href="#yu-nlg-chai-yi" class="header-anchor"></a></h1><p>在之前的脑洞中，我们将分类任务转变为NLG任务，即利用样本来生成对应的label description，而他与PET中的主要差别主要有几点：</p><p>1.<em> NLG中我们并没有没有限制label description的长度，且不同label对应description也可能是不同长度；</em><br>2.<em> NLG中我们每个token的生成是有依赖关系的，即后面的token会依赖之前的token，所以token长度可以比PET中稍微长一些；</em><br>3.<em> PET中对应的解码空间大大减小，只需要得到label对应token的概率即可;</em><br>4.<em> PET中的pattern可以放在前缀也可以放在后缀，NLG可以看作是后缀PET.</em><br>5.<em> PET 中由于pre-train是mlm任务，所以zero-show性能更好。</em></p><h1><span id="shi-yan">实验</span><a href="#shi-yan" class="header-anchor"></a></h1><p>针对这些差异尝试做了几组实验，验证一下想法。</p><ol><li>NLG中label长度同一且解码时利用PET的方式解码，在few-shot下准确率从$52.4%$上升到$52.9%$，所以生成的label越短，解码空间越小越准确；</li><li>PET前缀pattern下准确率为%53.7%$,所以前缀pattern比后缀性能更好，这也与苏剑林<a href="https://spaces.ac.cn/archives/7764" target="_blank" rel="noopener">《必须要GPT3吗？不，BERT的MLM模型也能小样本学习》</a>的结论一致。</li><li>zero-shot情况下，PET的准确率为$47.2%$, 而NLG只有$17.9%$，考虑到数据集全量下目前最好成绩才$60.7%$,说明PET的方式在zero-shot下效果相当惊人。</li></ol><p>主要实验代码在<a href="https://github.com/xv44586/toolkit4nlp/blob/master/examples/classification_pet_seq2seq.py" target="_blank" rel="noopener">classification_pet_seq2seq</a> 与 <a href="https://github.com/xv44586/toolkit4nlp/blob/master/examples/classification_tnews_pet.py" target="_blank" rel="noopener">classification_tnews_pet</a></p><h1><span id="zong-jie">总结</span><a href="#zong-jie" class="header-anchor"></a></h1><p>本文介绍了一种新的转变分类任务获得更好性能的方法：即将分类任务转化为mlm模型进行完形填空，同时与之前脑洞的将分类转变为生成任务进行对比，通过实验验证了两者的差异与有效性。同时也提醒自己，多想几步，也许就能有新的发现。</p><h1><span id="guan-yu-tou-tu">关于头图</span><a href="#guan-yu-tou-tu" class="header-anchor"></a></h1>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;/assets/css/APlayer.min.css&quot;&gt;&lt;script src=&quot;/assets/js/APlayer.min.js&quot; cla
      
    
    </summary>
    
    
      <category term="NLP" scheme="https://xv44586.github.io/categories/NLP/"/>
    
    
      <category term="Classification" scheme="https://xv44586.github.io/tags/Classification/"/>
    
      <category term="Few-shot" scheme="https://xv44586.github.io/tags/Few-shot/"/>
    
  </entry>
  
  <entry>
    <title>AdaBelief-更稳定的优化器</title>
    <link href="https://xv44586.github.io/2020/10/25/adabelief/"/>
    <id>https://xv44586.github.io/2020/10/25/adabelief/</id>
    <published>2020-10-25T02:26:54.000Z</published>
    <updated>2020-10-25T03:18:27.710Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><div class="toc"><!-- toc --><ul><li><a href="#warmup">warmup</a></li><li><a href="#xiu-gai-adam">修改Adam</a></li><li><a href="#you-dian">优点</a></li><li><a href="#zong-jie">总结</a></li><li><a href="#guan-yu-tou-tu">关于头图</a></li></ul><!-- tocstop --><p></div><br>对<code>Adam</code> 进行改进的算法有很多，今天介绍一篇改动很小改动小效果不错的-<code>AdaBelief</code>。</p><h1><span id="warmup">warmup</span><a href="#warmup" class="header-anchor"></a></h1><p>在bert中第一次见到warmup的使用，而warmup的作用是让训练更稳定，最后收敛的更好。而warmup有效的一个原因是减缓训练初期模型对mini-batch的提前过拟合，同时，在训练初期，由于loss较大，模型还没得到多少训练，不同step 之间的梯度方差较大，而此时如果使用较大的步长更新，则会朝错误的方向走一大步，而随后的模型不断得到训练，对应的梯度不断减小，同时一般我们会采用不断衰减的学习率，这些都导致随着模型的训练，更新的步长不断变小，而前期朝错误方向的一大步更新可能需要后期很多步的更新才能弥补，有时候可能甚至无法弥补，这就导致模型最后收敛在一个不怎么好的局部最优点，而如果在前期时抑制可能出现的大步更新，保持模型保持“小步走”，则可以避免模型在错误方向上的大步更新，而由模型的不断训练调整会正确的轨道。<br>所以一个重要的点是梯度更新方差大时（不同time step），我们需要谨慎行事，防止出现大错步，而方差小时，我们可以大胆一些，因为此时方向上基本一致，所以可以大踏步的往前走。</p><h1><span id="xiu-gai-adam">修改Adam</span><a href="#xiu-gai-adam" class="header-anchor"></a></h1><p>现在让我们来回顾一下Adam更新公式：</p><p>$$<br>\theta_t = \theta_{t-1} - \alpha \frac{m_t}{\sqrt{v_t}}<br>$$</p><p>其中$m_t$是对$g_t$的预测，$v_t$是对$g_t^2$的预测，对应的更新方向为$\frac{m_t}{\sqrt{v_t}}$.<br>$m_t$除了是对$g_t$的预测外，还可以看做是最近一段时间内（大概为$\frac{1}{1-\alpha}$）梯度的均值,而为了表征当前梯度$g_t$所处区域的方差，我们可以使用$belief = \left | g_t - m_t\right |$,即当前梯度距最近一段区域梯度均值的距离。在结合Adam的更新公式，我们可以用$s_t = (g_t - m_t) ^ 2$ 来代替$v_t$,即在方差大的区域更新时减小步长，而在方差小的区域，快步大走，最后的更新公式为：</p><p>$$<br>\theta_t = \theta_{t-1} - \alpha \frac{m_t}{\sqrt{s_t}}<br>$$</p><p>此时的更新方向为$\frac{m_t}{\sqrt{s_t}}$.<br>这就是<a href="https://arxiv.org/pdf/2010.07468.pdf" target="_blank" rel="noopener">AdaBelief Optimizer</a>的核心思想。具体的更新流程与Adam只需要修改一小部分即可：<br><img src="/2020/10/25/adabelief/opt.jpg" alt></p><h1><span id="you-dian">优点</span><a href="#you-dian" class="header-anchor"></a></h1><p>作者在论文中提到AdaBelief能媲美Adam的收敛速度，同时达到SGD的准确率。我做了几个实验，由于是在小数据集上fine-tuning，所以可能不如在大数据集上从头训练效果明显。不过依然可以得到：<br>1.<em>loss上相对Adam更平稳</em><br>2.<em>收敛上比Adam稍快</em><br>3.<em>性能上比Adam更好</em></p><p>loss 对比图<br><img src="/2020/10/25/adabelief/loss.png" alt></p><p>accuracy对比图<br><img src="/2020/10/25/adabelief/acc.png" alt></p><p>实验代码：<a href="https://github.com/xv44586/toolkit4nlp/blob/master/examples/classification_adabelief.py" target="_blank" rel="noopener">classification_adabelief</a></p><h1><span id="zong-jie">总结</span><a href="#zong-jie" class="header-anchor"></a></h1><p>本文介绍一个最新的优化器AdaBelief，并从与论文不同角度解释其主要作用，在实际工作中可以尝试使用AdaBelief，也许能得到比Adam收敛更快性能更好的结果。</p><h1><span id="guan-yu-tou-tu">关于头图</span><a href="#guan-yu-tou-tu" class="header-anchor"></a></h1><p>算法改进对比图</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;/assets/css/APlayer.min.css&quot;&gt;&lt;script src=&quot;/assets/js/APlayer.min.js&quot; cla
      
    
    </summary>
    
    
      <category term="MachineLearning" scheme="https://xv44586.github.io/categories/MachineLearning/"/>
    
    
      <category term="Optimizer" scheme="https://xv44586.github.io/tags/Optimizer/"/>
    
  </entry>
  
  <entry>
    <title>pet</title>
    <link href="https://xv44586.github.io/2020/10/22/pet/pet/"/>
    <id>https://xv44586.github.io/2020/10/22/pet/pet/</id>
    <published>2020-10-22T08:54:19.000Z</published>
    <updated>2020-10-26T14:15:48.266Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>之前的一篇<a href="https://xv44586.github.io/2020/09/13/classification-label-augment/">《模型增强-从label下手》</a>中，我们提到想通过转换label，增加一个任务，来尝试增强分类任务的性能。而其中的主要思路是想通过文本生成对应的label description ，将文本分类任务转换为NLG任务来做，不过当时考虑到UniLM中提到seq2seq的训练<code>不能</code>提高NLU的能力，所以当时并没有选择使用MLM来尝试，最后得到的结论是：</p><ol><li><ul><li>将分类转为生成后，性能基本一致；*</li></ul></li><li><ul><li>将分类与生成联合起来训练，性能与单个任务性能基本一致。*</li></ul></li></ol><p>最近看了两篇将分类任务转化为MLM的论文，也让我眼前一亮，发现原来我与顶会思路这么近（误）</p><h1><span id="mlm">mlm</span><a href="#mlm" class="header-anchor"></a></h1><p>mlm,即Masked Language Model,中文翻译又叫“掩码语言模型”，即以自监督的方式，mask 掉一部分，然后通过剩余的部分来还原被mask 掉的部分，示意图如下：<br><img src="pet/mlm.png" alt></p><p>而mask的方式也有多种，如随机mask选择token进行mask；将token所在的整个词都mask（whole word mask）；或者将某个span内的token都mask掉（span mask）。<br>虽然mlm在预训练任务上已经被证明十分有效，但是通常认为mlm部分的参数是与mlm任务相关的，而通常在下游任务中我们是别的任务，所以会舍弃掉这部分参数，而只使用encoder部分。<br>但是论文<a href="http://arxiv.org/abs/2009.07118" target="_blank" rel="noopener">It’s Not Just Size That Matters: Small Language Models Are Also Few-Shot Learners</a>与<a href="http://arxiv.org/abs/2001.07676" target="_blank" rel="noopener">Exploiting Cloze Questions for Few Shot Text Classification and Natural Language Inference</a>却告诉我们，mlm不仅有用，在few-shot场景下，通过一下简单的融合手段，性能能超过当前的明星GPT-3.</p><h1><span id="ren-wu-zhuan-huan">任务转换</span><a href="#ren-wu-zhuan-huan" class="header-anchor"></a></h1><p>与之前的思路类似，我们针对分类任务，不再直接对label进行预测，而是预测其label description，即将其转换为完形填空形式的任务，来预测不同label description的概率。<br>而如何转换成完形填空呢？也很简单，我们添加一个简单的语义通顺的描述，然后将其中与分类有关的内容mask掉即可。举个例子：<br>假如我们现在的任务是短文本分类，一个样本为“context：’「天天特价房」华庭仁和国际 3室2厅2卫仅售65万’, label: ‘房产’”，我们添加一个统一的描述句，将其变为：<br>“下面是一则__相关新闻标题: 「天天特价房」华庭仁和国际 3室2厅2卫仅售65万”,其中的空格可选的内容是所有的label description，对应的真实值是”房产”两个字，这样，我们就将分类任务转换为一个完形填空的形式。<br>而添加的方式也可以分为前缀、后缀两种，完整的方式：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"以下是一则__相关新闻标题: 「天天特价房」华庭仁和国际 3室2厅2卫仅售65万"</span></span><br><span class="line"><span class="string">"「天天特价房」华庭仁和国际 3室2厅2卫仅售65万，以上是一则__相关新闻标题"</span></span><br></pre></td></tr></table></figure></p><h1><span id="pattern-exploiting-training">Pattern-Exploiting Training</span><a href="#pattern-exploiting-training" class="header-anchor"></a></h1><p>上面我们添加的前缀/后缀句子称为<code>Pattern</code>, 而label description可以有多种方式，比如，对于“房产”这个label，我们也可以用“地产”来表达，对于“娱乐”label，也可以用“八卦”来表达，所以需要一个token到label的映射，这个映射可以是多对一的，这个被称为<code>Verbalizer</code></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;/assets/css/APlayer.min.css&quot;&gt;&lt;script src=&quot;/assets/js/APlayer.min.js&quot; cla
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>一切三段成三角形</title>
    <link href="https://xv44586.github.io/2020/10/19/triangle/"/>
    <id>https://xv44586.github.io/2020/10/19/triangle/</id>
    <published>2020-10-19T13:23:48.000Z</published>
    <updated>2020-10-20T15:11:24.993Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><div class="toc"><!-- toc --><ul><li><a href="#ti-mu">题目</a></li><li><a href="#jie-da">解答</a></li><li><a href="#guan-yu-tou-tu">关于头图</a></li></ul><!-- tocstop --></div><p>听到一个题目，还挺有意思，所以记录一下。</p><h1><span id="ti-mu">题目</span><a href="#ti-mu" class="header-anchor"></a></h1><p>问：一个绳子长<code>a</code>，任意剪两刀变成三段后，可以组成一个三角形的概率是多少？</p><h1><span id="jie-da">解答</span><a href="#jie-da" class="header-anchor"></a></h1><p>分析一下题目，一段长度固定的绳子，切割为三段，则：<br>1.<em> 任意一段绳子的长度大于0小于<code>a</code>；</em><br>2.<em> 任意两段绳子的长度大于0小于<code>a</code>。</em></p><p>而三段绳子可以组成一个三角形，而三角形中两边之和大于第三边，所以意味着：<br>1.<em>任意一段的长度小于<code>a/2</code>；</em><br>2.<em>任意两段的长度和大于<code>a/2</code>.</em></p><p>现在设其中两段的长度分别为 <code>x</code>, <code>y</code>，画出一个直角坐标系，如下图所示。<br><img src="/2020/10/19/triangle/triangle.png" alt></p><p>同时连接<code>(0, a), (a, 0)</code>两点，则切割绳子后其中两段的长度的所有可取的值对应由<code>(0, 0),(a, 0), (0, a)</code>组成的三角形区域。<br>简单证明如下：对于任意一点<code>B</code>,我们做其对<code>y</code>轴的垂线，相交与点<code>P</code>,而点<code>B</code>位于<code>(a, 0) (0, a)</code>的连线时，对应$\angle PAB  = 45^o$,此时<br>$PB=PA \Rightarrow  PB + PO = PA + PO = a$,而当<code>P</code>位于连线外侧，则$\angle PAB  &gt; 45^o$,对应$PO + PB &gt; PO + PA = a$,不满足约束。而$\Delta A O C$ 的面积为 $a^2 / 2$.</p><p>而对于能组成三角形时，首先任意一条长度小于$a/2$，对应<code>(0, a/2),(a/2,a/2)</code>连线与<code>(a/2,0)(a/2,a/2)</code>连线围城的矩形区域，而任意两边之和大于$a/2$,利用之前的方法可以证明是(0,a/2)(a/2, 0)连线右侧区域，两者的交即图中绿色三角形区域，其面积为$(a/2)^2/2 = a^2 / 8$</p><p>所以最后结论是组成三角形的概率为两个面积之比：<br>$$<br>pro = \frac{a^2/8}{a^2/2} = 1/4<br>$$</p><h1><span id="guan-yu-tou-tu">关于头图</span><a href="#guan-yu-tou-tu" class="header-anchor"></a></h1>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;/assets/css/APlayer.min.css&quot;&gt;&lt;script src=&quot;/assets/js/APlayer.min.js&quot; cla
      
    
    </summary>
    
    
      <category term="Math" scheme="https://xv44586.github.io/categories/Math/"/>
    
    
      <category term="Statistics" scheme="https://xv44586.github.io/tags/Statistics/"/>
    
  </entry>
  
  <entry>
    <title>样本不均衡之难易不均衡</title>
    <link href="https://xv44586.github.io/2020/10/14/focal-loss/"/>
    <id>https://xv44586.github.io/2020/10/14/focal-loss/</id>
    <published>2020-10-14T13:35:55.000Z</published>
    <updated>2020-10-25T02:55:33.075Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><div class="toc"><!-- toc --><ul><li><a href="#cross-entropy">Cross Entropy</a></li><li><a href="#yang-ben-lei-bie-bu-jun-heng">样本类别不均衡</a></li><li><a href="#focal-loss">Focal Loss</a><ul><li><a href="#ru-he-que-ding-alpha-yu-gamma">如何确定$\alpha$ 与 $\gamma$</a></li><li><a href="#shi-yan">实验</a></li></ul></li><li><a href="#ghm">GHM</a></li><li><a href="#zong-jie">总结</a></li><li><a href="#guan-yu-tou-tu">关于头图</a></li></ul><!-- tocstop --><p></div><br>上篇提到样本有难易，通过利用样本的这个特性，可以在推理上进行加速，除了在推理上可以利用，在训练时也可以利用，本篇就来说怎么在训练时更充分的利用样本有难易的特性。</p><h1><span id="cross-entropy">Cross Entropy</span><a href="#cross-entropy" class="header-anchor"></a></h1><p>对于分类问题，通常我们选择交叉熵作为损失。本文均针对二分类进行说明，多分类的情况可以横向扩展。对于二分类问题来说，其损失CE：</p><p>$$<br>CE = \left\{\begin{matrix}<br> -log(p)&amp; y\_true=1  \\<br> -log(1-p),&amp; y\_true=0<br>\end{matrix}\right.<br>$$</p><h1><span id="yang-ben-lei-bie-bu-jun-heng">样本类别不均衡</span><a href="#yang-ben-lei-bie-bu-jun-heng" class="header-anchor"></a></h1><p>当我们遇到一个正负样本不均衡的情况，如1:1000时，直接训练后效果往往不好，其倾向于将更多的样本预测为类别多的类，而产生的原因是：由于我们训练时使用的 CE:<br>$CE_W = CE_positive + CE_negative$, 其中CE_positive 与 CE_negative 分别代表正负样本的loss，而由于此时的样本不均衡，loss主要有类别多的样本贡献，主导了优化方向，所以模型会偏向数量多的方向，如当前全部预测为正样本，那解决这个问题最简单直接的办法就是在loss上增加一个权重α来均衡一下两方的loss，从而让模型更“公平”的对待不同类别样本,即：</p><p>$$<br>CE_W = \left\{\begin{matrix}<br> -\alpha log(p)&amp; y\_true=1  \\<br> -(1-\alpha)log(1-p),&amp; y\_true=0<br>\end{matrix}\right.<br>$$</p><h1><span id="focal-loss">Focal Loss</span><a href="#focal-loss" class="header-anchor"></a></h1><p>除了在类别上可能存在这种不均衡外，样本在难易程度上往往也会有难易之分。如当训练一个情感分类器时，“不喜欢xx”就比“谁不喜欢xx呢”要容易训练一些. 为了衡量这种“难易”特征，我们定义一个代表预测值与真实label 之间差距的参数$p_t$:</p><p>$$<br>p_t = \left\{\begin{matrix}<br> 1-p,&amp; y\_true=1  \\<br> p,&amp; y\_true=0<br>\end{matrix}\right.<br>$$</p><p>即</p><p>$$<br>p_t = \begin{vmatrix}<br>pred - y_{true}<br>\end{vmatrix}<br>$$</p><p>pt越大则说明预测值与其label 相差越大，也即样本越“难训练”，最后我们对整个样本的pt 统计往往得到一个U型分布，如下图所示：<br><img src="/2020/10/14/focal-loss/a1.png" alt><br>即“易训练”样本是“难训练”样本的指数级。虽然此时“易训练”样本由于得到了很好的训练，其loss 很小，当由于其数量庞大，任然可能主动整个训练。<br>所以为了解决难易不均衡的问题，我们采用与样本不均衡一样的方法：对不同样本添加一个权重来平衡，即此时的loss FL:</p><p>$$<br>FL = \left\{\begin{matrix}<br> -\alpha \beta(p\_t) log(p)&amp; y\_true=1  \\<br> -(1-\alpha)\beta(1-p\_t)log(1-p),&amp; y\_true=0<br>\end{matrix}\right.<br>$$</p><p>而前面我们说难易样本的loss 呈指数级差距，所以此时的$\beta(p_t)$ 我们也定义为指数函数，最终的 FL:</p><p>$$<br>FL = \left\{\begin{matrix}<br> -\alpha(1 - p)^{\gamma} log(p)&amp; y\_true=1  \\<br> -(1-\alpha)(p)^{\gamma}log(1-p),&amp; y\_true=0<br>\end{matrix}\right.<br>$$</p><p>此时，$\alpha$ 用来平衡样本不均衡，$(1-p)^{\gamma}$ 用来均衡难易样本。通过平衡难易样本对应损失，让模型更“关注”那些难分的样本。</p><p>以上就是<a href="https://arxiv.org/pdf/1708.02002.pdf" target="_blank" rel="noopener">focal loss</a> 的主要思想，虽然最后我们得到的loss形式上与focal loss一样，但其中参数的含义与focal loss中的内容却有一些不同，主要在于focal loss 中实验证明，由于对难易样本降权后正样本（量少的类）对应的loss反而更易主动优化方向，所以用 $\alpha$ 来降权，而我们上面提到的alpha 主要是用来均衡正负样本，这里读者可以自行判断理解。此外，苏剑林通过硬截断过渡到软阶段也得到了类似的loss，推荐大家也看看：<a href="https://spaces.ac.cn/archives/4733" target="_blank" rel="noopener">从loss的硬截断、软化到focal loss </a></p><h2><span id="ru-he-que-ding-alpha-yu-gamma">如何确定$\alpha$ 与 $\gamma$</span><a href="#ru-he-que-ding-alpha-yu-gamma" class="header-anchor"></a></h2><p>在focal loss论文内，作者是通过搜索一个范围来确定两个参数的最优解，最后给出的结果是 $\alpha = 0.25$, $\gamma=2.$，而通过上面我们提到的两个参数的含义，这里给出一个确定参数范围的方案：<br>1.首先，我们通过统计正负样本，来确定$\alpha$的大致范围；<br>2.通过CE_W我们可以训练一个基础的分类器，通过这个分类器，我们对训练集进行预测，生成对应的prob，然后通过统计$p_t$，我们认为$p_t&lt;=0.1$ 的为主要的“易分样本”，${p_t&gt;=0.9}$ 为主要“难分样本”，由于是指数衰减，所以两者的loss 差距为 $9^\gamma$, 即此时$9^\gamma=C_易/C_难$, 解出此时的$\gamma$ 即可得到其大致的范围。</p><h2><span id="shi-yan">实验</span><a href="#shi-yan" class="header-anchor"></a></h2><p>实验时，通过构造一个正负样本8:1的数据集进行实验，在通过权重平衡正负样本不均衡后，对应的pt分布如下图：<br><img src="/2020/10/14/focal-loss/a1.png" alt><br><img src="/2020/10/14/focal-loss/p1.png" alt><br><img src="/2020/10/14/focal-loss/n1.png" alt><br>而focal loss 训练后的pt 分布为：<br><img src="/2020/10/14/focal-loss/a2.png" alt><br><img src="/2020/10/14/focal-loss/p2.png" alt><br><img src="/2020/10/14/focal-loss/n2.png" alt><br>可以看到，在focal loss 下，右侧偏差大的样本基本都被移到了左侧，说明“难样本”大幅度减少变为了“易样本”。<br>实验代码地址：<a href="https://github.com/xv44586/toolkit4nlp/blob/master/examples/classification_focal_loss.py" target="_blank" rel="noopener">classification use focal loss</a></p><h1><span id="ghm">GHM</span><a href="#ghm" class="header-anchor"></a></h1><p>现在让我们来讨论一下focal loss存在的问题：</p><ol><li>首先，让模型过多的关注那些特别难分的样本没有什么问题，但是这个前提：样本紧凑。而当数据中存在离群点时，那此时就会发生：本来模型已经收敛了，但是由于这些离群点还是会误判，一直存在在pt的最右侧，而让模型再过多的去关注这些点，这明显是不合适的；</li><li>对于focal loss中的两个参数$\alpha$ 和$\gamma$ ，虽然我们能估算一个大致范围，但是由于两者是相互影响的，所以实际使用时还是需要通过实验去寻找最优解，这也为训练增加了一定的难度。</li></ol><p>现在再让我们回过头来重新审视一下我们的原始问题：样本有难易之分，所以训练时存在难易样本不均衡，而”易分”样本占比过高导致主导优化方向。那此时让我们往后再思考一步，当我们对易分样本降权后，对应的pt分布图中最左侧的柱子会降低，而由于模型得到了更好的优化方向，模型的性能提高，所以最右侧的柱子也会降低，两边减少的样本会同时向”中间”扩散，最后得到一个比原始pt分布曲线更”平滑”的分布曲线，正如上文中focal loss对应的pt分布图。<br>而focal loss 由于过度关注”难分样本”，导致存在离群点时不理想的问题。而离群点有一个特点就是：量相对正常样本非常少（否则就是一个”小群”了），利用这个特点，我们就能对focal loss 进行改进了。改进的思路就是利用离群点少的特点，从难易样本的量上来平衡难易样本的loss。<br>具体做法：我们将$p_t$ 按间隔$\varepsilon$均等的分为K个区间，然后统计不同区间内的样本数量$num_k$，然后针对每个区间内的loss 我们用参数$\beta(i)$ 来平滑：</p><p>$$<br>L_{GHN-C} = \sum_{1}^{N}\beta(i)L_{CE}(p_i,  \hat p_i)<br>$$</p><p>其中：<br>$\beta(i)$对应$pt_i$所属区间的样本$num_k$在整体样本 $N$ 中占比的倒数。<br>而在实现时，由于通常我们都是采取mini-batch 的方式训练，无法在每个batch内事先得到全局统计量进行$\beta(i)的计算，一种近似的办法是利用动量，逐步近似求。<br>以上就是<a href="http://arxiv.org/abs/1811.05181" target="_blank" rel="noopener">GHM</a> 在分类情况下的loss，原始论文中的pt 分布对比图中也能看到，利用GHM确实更平滑。<br><img src="/2020/10/14/focal-loss/gn.jpeg" alt> </p><h1><span id="zong-jie">总结</span><a href="#zong-jie" class="header-anchor"></a></h1><p>本文介绍了两种针对样本难易不均衡问题的loss：focal loss 与 GHM，并通过实验进一步验证了其有效性，在一些样本不均衡的场景下均可尝试使用。</p><h1><span id="guan-yu-tou-tu">关于头图</span><a href="#guan-yu-tou-tu" class="header-anchor"></a></h1><p><a href="https://arxiv.org/pdf/1811.05181.pdf" target="_blank" rel="noopener">Gradient Harmonized Single-stage Detector</a>中配图。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;/assets/css/APlayer.min.css&quot;&gt;&lt;script src=&quot;/assets/js/APlayer.min.js&quot; cla
      
    
    </summary>
    
    
      <category term="MachineLearning" scheme="https://xv44586.github.io/categories/MachineLearning/"/>
    
    
      <category term="样本不均衡" scheme="https://xv44586.github.io/tags/%E6%A0%B7%E6%9C%AC%E4%B8%8D%E5%9D%87%E8%A1%A1/"/>
    
      <category term="Loss" scheme="https://xv44586.github.io/tags/Loss/"/>
    
  </entry>
  
  <entry>
    <title>年轻人的第一个swift：ios 模拟定位打卡</title>
    <link href="https://xv44586.github.io/2020/09/30/location/"/>
    <id>https://xv44586.github.io/2020/09/30/location/</id>
    <published>2020-09-30T14:34:11.000Z</published>
    <updated>2020-09-30T15:10:14.932Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><div class="toc"><!-- toc --><ul><li><a href="#qi-yin">起因</a></li><li><a href="#mo-ni-ding-wei">模拟定位</a></li><li><a href="#fang-fa">方法</a></li><li><a href="#zong-jie">总结</a></li><li><a href="#guan-yu-tou-tu">关于头图</a></li></ul><!-- tocstop --></div><h1><span id="qi-yin">起因</span><a href="#qi-yin" class="header-anchor"></a></h1><p>由于最近马上过节了，而我也被这节日的气氛所支配，所以今天完成了未打卡三连成就。公司现在规定每个月只有两次未正常打卡的机会，超过了会有相应的惩罚机制。我感觉自己工作时长接近十个小时，但是因为忘记打卡被处罚的话心里多少有点不爽，所以就想是不是可以补救一下。- -！</p><h1><span id="mo-ni-ding-wei">模拟定位</span><a href="#mo-ni-ding-wei" class="header-anchor"></a></h1><p>很早之前就听说Xcode 提供了模拟定位，方便开发者调试，所以我想这个应该是个切入点，问了一个懂这个大佬，也得到了肯定的答案。<br>所以主体思路是通过Xcode 模拟定位，然后借助这个模拟定位功能，定位到公司附近，然后钉钉打卡。不过网上找到的方法大多数都不是swift 的，我自己摸索了一个小时找到了具体方案，其实非常的简单。</p><h1><span id="fang-fa">方法</span><a href="#fang-fa" class="header-anchor"></a></h1><ol><li><p>首先，通过<a href="https://lbs.amap.com/console/show/picker" target="_blank" rel="noopener">高德</a>/百度地图/腾讯地图获取公司附近经纬度，不过需要注意的是iOS原生坐标为<code>世界标准地理坐标(WGS-84)</code>, 百度地图的坐标为<code>BD-09</code>,高德为<code>中国国测局地理坐标（GCJ-02）</code>,需要将位置转换为iOS 坐标下的。<br>坐标转换有比较简单的方法，GitHub上找到一个<a href="https://github.com/wandergis/coordTransform_py" target="_blank" rel="noopener">coordTransform_py</a>(忽略我是一个GIS专业学生 - -！),对应转换：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> coordTransform_utils <span class="keyword">import</span>  *</span><br><span class="line">lon, lat = <span class="number">120.177239</span>,<span class="number">30.216698</span></span><br><span class="line">w_lon, w_lat = gcj02_to_wgs84(lon, lat)</span><br></pre></td></tr></table></figure></li><li><p>Xcode 新建一个项目，项目内新建一个gpx 文件，文件内容里添加对应的经纬度：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version="1.0"?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">gpx</span> <span class="attr">version</span>=<span class="string">"1.1"</span> <span class="attr">creator</span>=<span class="string">"Xcode"</span>&gt;</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">&lt;!--</span></span><br><span class="line"><span class="comment">     Provide one or more waypoints containing a latitude/longitude pair. If you provide one</span></span><br><span class="line"><span class="comment">     waypoint, Xcode will simulate that specific location. If you provide multiple waypoints,</span></span><br><span class="line"><span class="comment">     Xcode will simulate a route visiting each waypoint.</span></span><br><span class="line"><span class="comment">     --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">wpt</span> <span class="attr">lat</span>=<span class="string">"39.99200300843388"</span> <span class="attr">lon</span>=<span class="string">"116.46688673941635"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>Cupertino<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">&lt;!--</span></span><br><span class="line"><span class="comment">         Optionally provide a time element for each waypoint. Xcode will interpolate movement</span></span><br><span class="line"><span class="comment">         at a rate of speed based on the time elapsed between each waypoint. If you do not provide</span></span><br><span class="line"><span class="comment">         a time element, then Xcode will use a fixed rate of speed.</span></span><br><span class="line"><span class="comment">         </span></span><br><span class="line"><span class="comment">         Waypoints must be sorted by time in ascending order.</span></span><br><span class="line"><span class="comment">         --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">time</span>&gt;</span>2014-09-24T14:55:37Z<span class="tag">&lt;/<span class="name">time</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">wpt</span>&gt;</span></span><br><span class="line">    </span><br><span class="line"><span class="tag">&lt;/<span class="name">gpx</span>&gt;</span></span><br></pre></td></tr></table></figure></li><li><p>手机与电脑连接，然后让程序在手机上运行起来，同时保持手机定位打开状态，此时就可以通过模拟位置来修改手机的当前定位了。最终打卡成功。</p></li></ol><h1><span id="zong-jie">总结</span><a href="#zong-jie" class="header-anchor"></a></h1><p>本文是由于未正常打卡紧缺，我尝试补救的一次探索，由于是第一次接触Xcode ，感觉有点兴奋。不过希望看到这里的你不要用这个方法来做坏事。</p><h1><span id="guan-yu-tou-tu">关于头图</span><a href="#guan-yu-tou-tu" class="header-anchor"></a></h1><p>打卡成功</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;/assets/css/APlayer.min.css&quot;&gt;&lt;script src=&quot;/assets/js/APlayer.min.js&quot; cla
      
    
    </summary>
    
    
      <category term="Life" scheme="https://xv44586.github.io/categories/Life/"/>
    
    
      <category term="swift" scheme="https://xv44586.github.io/tags/swift/"/>
    
  </entry>
  
  <entry>
    <title>Knowledge Distillation (3) &amp;#58; 看样本下菜的FastBERT</title>
    <link href="https://xv44586.github.io/2020/09/25/fastbert/"/>
    <id>https://xv44586.github.io/2020/09/25/fastbert/</id>
    <published>2020-09-25T14:32:38.000Z</published>
    <updated>2020-10-25T02:55:33.030Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><div class="toc"><!-- toc --><ul><li><a href="#knowledge-distillation-mu-de">Knowledge Distillation 目的</a></li><li><a href="#zen-me-zuo">怎么做</a><ul><li><a href="#qu-fen-yang-ben">区分样本</a></li><li><a href="#mo-xing-can-shu-gong-xiang">模型参数共享</a></li><li><a href="#zheng-ti-jia-gou">整体架构</a></li></ul></li><li><a href="#fu-xian">复现</a></li><li><a href="#zong-jie">总结</a></li><li><a href="#guan-yu-tou-tu">关于头图</a></li></ul><!-- tocstop --></div><p>之前Knowledge Distillation 相关的两篇分别介绍了两种知识蒸馏的方式：<a href="https://xv44586.github.io/2020/08/09/bert-of-theseus/">模型替换之bert-of-theseus</a> 和<a href="https://xv44586.github.io/2020/08/31/bert-01/">知识迁移</a>,本篇介绍一种从样本入手的知识蒸馏方法。</p><h1><span id="knowledge-distillation-mu-de">Knowledge Distillation 目的</span><a href="#knowledge-distillation-mu-de" class="header-anchor"></a></h1><p>再来看看我们做knowledge distillation 的目的是什么：我们是想要模型即性能好又推理快，那要推理快，我们直接使用一个更小的模型，比如3层的bert就比12层的bert快，那为什么不这么做呢？这是因为直接用3层bert来fine-tuning的结果往往不那么“性能好”，所以他只能满足推理快这一半。<br>所以我们要通过一个teacher 来引导这个小模型，来把“性能好”这个特性补上。</p><h1><span id="zen-me-zuo">怎么做</span><a href="#zen-me-zuo" class="header-anchor"></a></h1><p>而一般做KD ，我们往往关注怎么去让student 更好的学习teacher，但是好像没人关注过student 直接fine-tuning 的时候到底有多差？拿文本分类来说，我们用bert-3 在IFLYTEK数据上进行fine-tuning，最终的accuracy 大概在57.9%，而bert-12 大概在60.7%((结果)[<a href="https://github.com/xv44586/toolkit4nlp/blob/master/examples/classification_ifytek_bert_of_theseus.py])，3层是不如12层，但是差距只有不到3个点，换句不严谨的话说，只有不到3%的数据需要12层的bert才能达到当前最优性能，而大部分样本在前3层就已经能确定了。" target="_blank" rel="noopener">https://github.com/xv44586/toolkit4nlp/blob/master/examples/classification_ifytek_bert_of_theseus.py])，3层是不如12层，但是差距只有不到3个点，换句不严谨的话说，只有不到3%的数据需要12层的bert才能达到当前最优性能，而大部分样本在前3层就已经能确定了。</a><br>换成一句我们都能理解的事实描述就是：样本有难易之分，有的样本容易区分，有的样本不容易区分。这时候，如果全部样本都当不容易区分看待，对这部分容易区分的样本来说就是“杀鸡用牛刀”了，那一个简单直观的办法就是，我们“杀鸡时用杀鸡刀，杀牛时用杀牛刀”，即我们按样本难易程度，分别为他们指定不同的模型来分类，简单的样本只需要用小模型，因为他就能得到与大模型一致的结果，而难的样本再用大模型，这样就能“性能好”的同时推理又快了，因为大部分模型只需要小模型推理即可。</p><h2><span id="qu-fen-yang-ben">区分样本</span><a href="#qu-fen-yang-ben" class="header-anchor"></a></h2><p>接下来的问题就是我们怎么区分样本是简单样本还是难样本了。这里我们将其换个思路：假如小模型对自己的结果非常有信心（确定），那我们就相信小模型的结果，反之，我们就将样本送进大模型，让大模型来进一步判断。注意，这里如果小模型非常“确定”的将样本给了错误结果，那这个结果也将认为是最终结果，即使这个结果送进大模型有被改正确的可能。那如何判断一个结果的不确定性呢？通常我们用熵来判断一个分布的不确定性，这里也一样。</p><h2><span id="mo-xing-can-shu-gong-xiang">模型参数共享</span><a href="#mo-xing-can-shu-gong-xiang" class="header-anchor"></a></h2><p>到了这一步，我们取得了“性能好”又“推理快”的目标了吗？其实还没有，因为此时我们会有多个模型，每个模型对应不同难易程度的样本，这样无疑是将推理从一次变成了多次，那怎么解决呢？我们可以利用上一个小模型的结果而不用再从头算，这样最终的模型就由一系列模型变为一个带有多个分支的大模型，只是每个分支的部分会进行一次判断，如果其结果的不确定性非常低，则直接返回结果而不再往后继续计算。而由于利用了上一层的结果，所以整体的时间上只增加了多个分类器与判断结果置信度的时间，而这个时间相对于其他计算要小的多。</p><h2><span id="zheng-ti-jia-gou">整体架构</span><a href="#zheng-ti-jia-gou" class="header-anchor"></a></h2><p>模型整体架构示意图：<br><img src="/2020/09/25/fastbert/fastbert.png" alt></p><p>以上就是fastbert 模型的整体思路了。对于fastbert 来说，越靠前的层的性能越好，其推理速度提升的就越大，所以有必要尽量提高前面层的性能。这里就是Knowledge Distillation 的任务了：由于fastbert 本身就是一个12层bert，所以将最后一个分类器作为Teacher Model，然后生成对应的soft labels，然后迁移到fastbert 的每一个分支model上。之前的<a href="https://xv44586.github.io/2020/08/31/bert-01/">实验</a>我们也提到过这种self-distillation 能提高性能，作者这里也是一样的思路。</p><h1><span id="fu-xian">复现</span><a href="#fu-xian" class="header-anchor"></a></h1><p>实验代码在<a href="https://github.com/xv44586/Knowledge-Distillation-NLP/blob/master/knowledge_distillation_fastbert.py" target="_blank" rel="noopener">fastbert</a>感兴趣的同学可以看看.不过由于我只会keras(tensorflow)，而tf 这种静态图不好实现这种分支结构，所以我的实验代码其实并没有真的提前终止计算返回结果，暂时没找到更好的实现方式，如果有知道的同学也欢迎告知。</p><h1><span id="zong-jie">总结</span><a href="#zong-jie" class="header-anchor"></a></h1><p>fastbert从思路上来说，通过对样本进行难易程度进行划分，对样本进行adaptive predict ，但是缺点也比较明显：1. 用确定性来代替难易，中间有不对等会导致较难样本在初期被错分后没有修正对机会；2.其基本假设是易分样本远多于难分样本，否则会使推理速度不降反增。</p><h1><span id="guan-yu-tou-tu">关于头图</span><a href="#guan-yu-tou-tu" class="header-anchor"></a></h1><p>芝麻街</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;/assets/css/APlayer.min.css&quot;&gt;&lt;script src=&quot;/assets/js/APlayer.min.js&quot; cla
      
    
    </summary>
    
    
      <category term="NLP" scheme="https://xv44586.github.io/categories/NLP/"/>
    
    
      <category term="Distillation" scheme="https://xv44586.github.io/tags/Distillation/"/>
    
      <category term="FastBERT" scheme="https://xv44586.github.io/tags/FastBERT/"/>
    
  </entry>
  
  <entry>
    <title>模型增强（2）&amp;#58; 从label下手</title>
    <link href="https://xv44586.github.io/2020/09/13/classification-label-augment/"/>
    <id>https://xv44586.github.io/2020/09/13/classification-label-augment/</id>
    <published>2020-09-12T16:09:24.000Z</published>
    <updated>2020-10-25T02:55:33.036Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><div class="toc"><!-- toc --><ul><li><a href="#gou-zao-xin-label">构造新label</a><ul><li><a href="#zi-jian-du">自监督</a></li><li><a href="#xiang-si-xing">相似性</a></li></ul></li><li><a href="#shi-yan-jie-guo">实验结果</a></li><li><a href="#zong-jie">总结</a></li><li><a href="#guan-yu-tou-tu">关于头图</a></li></ul><!-- tocstop --></div><p>上篇<a href="https://xv44586.github.io/2020/08/31/bert-01/">Knowledge Distillation (2): distilling knowledge of bert</a>中我们提到，模型压缩时一个很重要的知识是soft labels，<br>并且提出了一种简单的方式：自蒸馏（self-distillation），而从label 的角度来看，可以看作是一种label augmentation，即构造了一个新的label，为模型新增了一个任务，通过新任务的学习，来提高模型对原来任务的性能。本文就label augmentation 继续脑洞。</p><h1><span id="gou-zao-xin-label">构造新label</span><a href="#gou-zao-xin-label" class="header-anchor"></a></h1><p>构造新label，其实本质上是构造一个与当前任务相关的新的任务，而对应的label则是通过当前样本通过某种方式获得，获得的label至少要比随机好，否则只会帮倒忙。</p><h2><span id="zi-jian-du">自监督</span><a href="#zi-jian-du" class="header-anchor"></a></h2><p>构造新label，我们可以借鉴自监督的方式，如Mask Language Model，AutoRegressive，而BERT中已使用来MLM，UniLM中也告诉我们增加Seq2Seq的AR 任务对NLU任务提高不显著，不过今年的论文<a href="http://arxiv.org/abs/2004.10964" target="_blank" rel="noopener">Don’t Stop Pretraining: Adapt Language Models to Domains and Tasks</a> 实验证明了进一步预训练是能进一步提升下游任务的性能。而当前任务是文本分类，MLM也许不是很合适，所以Seq2Seq 的方式可以尝试。<br>具体的，我们让模型学习目标类别的同时，希望模型能同时生成样本的描述字段（或者人为给定的某种相关性短语），即利用类别对应描述字段构造一个seq2seq任务。</p><h2><span id="xiang-si-xing">相似性</span><a href="#xiang-si-xing" class="header-anchor"></a></h2><p>对于同一个类别的样本，他们必然有某种相似性，至少比与其他类别的样本更相似。而何如构造样本呢？<br>一种简单的方式是对每个样本都从类当中抽取一个样本与他组成一对，然后让每个<code>i</code>样本与<code>i+1</code>样本相似。这种方式由于每次样本都是shuffle 的，只要让batch size 小于label number，一个batch 内同时出现多个同一类别的样本概率就会很小。<br>既然在构造seq2seq任务时，我们使用来label对应的描述，此时我们也可以继续尝试使用：每个样本构造一个新的样本，新样本由label对应描述与label id组成。</p><h1><span id="shi-yan-jie-guo">实验结果</span><a href="#shi-yan-jie-guo" class="header-anchor"></a></h1><p>两组实验结果如下：</p><p>$$<br>\begin{array}{c|c|c}<br>\hline \\<br>\text{seq2seq} &amp; \text{similarity} \\<br>\hline \\<br>59.91\% &amp; 56.9\%<br>\end{array}<br>$$</p><p>可以看到，对于构造seq2seq 任务，其结果与直接fine-tuning 结果基本一致，这也符合预期。而构造相似性任务，其结果直接fine-tuning 结果相比反而更差了。原因可能是样本不均衡，所以同一batch 内有较高概率出现同一类别的样本，同时通过让样本与同一样本相似来间接相似，这种方式可能有些曲折了，不过最根本的原因应该还是batch 内同一类别样本的出现干扰了学习。<br>具体实验代码可以查阅<a href="https://github.com/xv44586/toolkit4nlp/blob/master/examples/classification_ifytek_auxiliary_seq2seq_task.py" target="_blank" rel="noopener">classification_ifytek_auxiliary_seq2seq_task</a> 和<a href="https://github.com/xv44586/toolkit4nlp/blob/master/examples/classification_ifytek_with_similarity.py" target="_blank" rel="noopener">classification_ifytek_with_similarity</a></p><h1><span id="zong-jie">总结</span><a href="#zong-jie" class="header-anchor"></a></h1><p>本文只是由于之前实验想到的尝试对label 做增强来实现模型增强的尝试，最后两组实验都没取得什么好的结果。</p><h1><span id="guan-yu-tou-tu">关于头图</span><a href="#guan-yu-tou-tu" class="header-anchor"></a></h1><p>摄于翠湖湿地</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;/assets/css/APlayer.min.css&quot;&gt;&lt;script src=&quot;/assets/js/APlayer.min.js&quot; cla
      
    
    </summary>
    
    
      <category term="NLP" scheme="https://xv44586.github.io/categories/NLP/"/>
    
    
      <category term="Classification" scheme="https://xv44586.github.io/tags/Classification/"/>
    
  </entry>
  
  <entry>
    <title>Knowledge Distillation (2) &amp;#58; 知识迁移</title>
    <link href="https://xv44586.github.io/2020/08/31/bert-01/"/>
    <id>https://xv44586.github.io/2020/08/31/bert-01/</id>
    <published>2020-08-31T15:14:55.000Z</published>
    <updated>2020-10-25T02:55:33.071Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><div class="toc"><!-- toc --><ul><li><a href="#distilling-knowledge">Distilling Knowledge</a><ul><li><a href="#distilling-the-knowledge-in-a-neural-network">Distilling the Knowledge in a Neural Network</a><ul><li><a href="#distilling">Distilling</a></li></ul></li><li><a href="#distill-bert">Distill BERT</a></li><li><a href="#tinybert">TinyBERT</a><ul><li><a href="#you-dian">优点</a></li><li><a href="#que-dian">缺点</a></li></ul></li><li><a href="#distilbert">DistilBERT</a><ul><li><a href="#you-dian-1">优点</a></li></ul></li><li><a href="#mobilebert">MobileBERT</a><ul><li><a href="#you-dian-2">优点</a></li><li><a href="#que-dian-1">缺点</a></li></ul></li></ul></li><li><a href="#lun-wen-zong-jie">论文总结</a></li><li><a href="#xiang-fa">想法</a></li><li><a href="#shi-yan">实验</a><ul><li><a href="#teacher-to-student">Teacher-to-Student</a></li><li><a href="#student-to-student">student-to-student</a></li><li><a href="#normal-noise-training">normal-noise-training</a></li></ul></li><li><a href="#shi-yan-jie-guo">实验结果</a></li><li><a href="#zong-jie">总结</a></li><li><a href="#guan-yu-tou-tu">关于头图</a></li></ul><!-- tocstop --></div><p>上篇讨论了<a href="https://xv44586.github.io/2020/08/31/bert-01/">bert-of-theseus</a>，算是一个开篇，本文继续讨论关于模型蒸馏（Distilling Knowledge）及关于BERT模型的知识蒸馏。<br>模型蒸馏的最重要的一个特点就是降低资源使用和加速模型推理速度，而小模型往往性能较低，本文总结一些如何通过蒸馏来使小模型具有更好的性能。</p><h1><span id="distilling-knowledge">Distilling Knowledge</span><a href="#distilling-knowledge" class="header-anchor"></a></h1><h2><span id="distilling-the-knowledge-in-a-neural-network">Distilling the Knowledge in a Neural Network</span><a href="#distilling-the-knowledge-in-a-neural-network" class="header-anchor"></a></h2><p>这篇是2015年Hinton发表的,也是我看到的最早提出Knowledge Distillation的<a href="http://arxiv.org/abs/1503.02531" target="_blank" rel="noopener">论文</a>。<br>在这篇论文中，Hinton指出one-hot 的label只指示了true label 的信息，但是没有给出negative label 之间、negative 与 true label之间<br>的相对关系，比如：比如现在的任务是给定一个词（比如：苹果），然后判断词对应的类别（电视/手机/水果/汽车），假如现在我们有两个样本：<br>（苹果，[0,0,1,0]）和 （小米，[0,1,0,0]), 而one-hot 形式的label并不能告诉我们，苹果中 label是水果的概率高出label是拖拉机的概率，<br>稍低于是手机的概率，而小米中label是电视的概率稍低于是手机的概率，但是同时要高于是汽车和水果的概率，这些相对关系在one-hot 形式的label中<br>是无法得到的，而这些信息非常重要，有了这些信息，我们可以更容易的学习任务。于是提出了Teacher-Student模式，<br>即用一个大的复杂的模型（也可以是ensemble后的）来先学习，然后得到label的相对关系（logits），然后将学习到的知识迁移到一个小模型（Student）。</p><h3><span id="distilling">Distilling</span><a href="#distilling" class="header-anchor"></a></h3><p>具体迁移过程是Student 在进行training 时，除了学习ground truth 外，还需要学习label 的probability（softmax output），但是不是直接学习<br>softmax output，而是学习<code>soften labels</code>，所谓soften labels 即经过<code>Temperature</code> 平滑后的 probability，具体形式：<br>$$<br>q_{i} = \frac{exp(z_{i}/T)}{\sum_{j}^{}exp(z_{j}/T)}<br>$$<br>其中T 越大，对应的probability 越平滑，如下图所示。而平滑probability 可以看作是对soften label的一种正则化手段。<br> <img src="/2020/08/31/bert-01/soften.png" alt></p><p>更直观的实验请查阅<a href="https://github.com/xv44586/Knowledge-Distillation-NLP/blob/master/Knowledge_Distillation_From_Scratch.ipynb" target="_blank" rel="noopener">Knowledge Distillation From Scratch</a></p><h2><span id="distill-bert">Distill BERT</span><a href="#distill-bert" class="header-anchor"></a></h2><p>看到的第一篇针对BERT 模型做蒸馏的是<a href="http://arxiv.org/abs/1903.12136" target="_blank" rel="noopener">Distilling Task-Specific Knowledge from BERT into Simple Neural Networks</a>,<br>在这篇论文中，作者延续Hinton 的思路在BERT 上做实验，首先用BERT-12 做Teacher，然后用一个单层Bi-LSTM 做Student，loss 上除了<br>ground truth 外，也选择了使用teacher 的logits，包括Temperature 平滑后的soften labels 的CrossEntropy和 logits 之间的MSE，<br>最后实验验证MSE效果优于CE。<br>此外，由于是从头开始训练Student，所以只用任务相关数据会严重样本不足，所以作者提出了三种NLP的任务无关的data augment策略：</p><ol><li><strong>mask：随机mask一部分token作为新样本，让teacher去生成对应logits ;</strong></li><li><strong>根据POS标签去替换，得到 ”What do pigs eat?” -&gt; “ How do pigs ear?”</strong></li><li><strong>n-gram采样：随机选取n-gram，n取[1-5]，丢弃其余部分。</strong></li></ol><p>在<a href="http://arxiv.org/abs/1503.02531" target="_blank" rel="noopener">Distilling the Knowledge in a Neural Network</a>中曾指出 logits 之间的CrossEntropy是可以看作<br>是MSE 的近似版本，不过这里作者的结论是MSE 更好，此外，由于Hinton 实验时是巨大数据量，所以不存在样本不足的情况，而普通实验时都会遇到<br>迁移时训练样本不足，需要做数据增强的问题。</p><h2><span id="tinybert">TinyBERT</span><a href="#tinybert" class="header-anchor"></a></h2><p>TinyBERT 出自<a href="http://arxiv.org/abs/1909.10351" target="_blank" rel="noopener">TinyBERT: Distilling BERT for Natural Language Understanding</a>,由于Transformer 结构<br>在NLP 任务中的强大能力，作者选择用与BERT 同结构的方式做Student，此外，为了提高KD后模型性能，做了更细致的工作：</p><ol><li><strong>Student选择一个更窄更浅的transformer;</strong></li><li><strong>将KD也分为两个阶段：pre-train 和 fine-tuning，并且在两个阶段上都进行KD;</strong></li><li><strong>使用了更多的loss：Embedding之间的MSE，Attention Matrix中的logits之间的MSE，Hidden state之间的MSE以及最后的分类层的CE;</strong></li><li><strong>为了提高下游任务fine-tuning后的性能，使用了近义词替换的策略进行数据增强.</strong></li></ol><h3><span id="you-dian">优点</span><a href="#you-dian" class="header-anchor"></a></h3><ol><li><strong>6层transformer基本达到了bert-12的性能，并且hidden size更小，实际是比bert-6更小的;</strong></li><li><strong>因为有pre-train KD，所以可以拿来当bert 一样直接在下游fine-tuning.</strong></li></ol><h3><span id="que-dian">缺点</span><a href="#que-dian" class="header-anchor"></a></h3><ol><li><strong>由于hidden size的不同，所以为了进行MSE，需要用一个参数矩阵W 来调节，这个参数只在训练时使用，训练完后丢弃，这个矩阵没有任何约束，觉得不优雅;</strong></li><li><strong>其次，student model的每一层都需要去学习teacher model的对应的block的输出，如何对不同的层如何设计更好的权重也是一个费力的事；</strong></li><li><strong>虽然student的结构也是transformer，但是由于hidden size 不同，没法使用teacher的预训练结果，但是我觉得这里其实可以用降维的方式用<br>teacher的预训练结果，可能不需要pretraining的阶段了也说不定。</strong></li></ol><h2><span id="distilbert">DistilBERT</span><a href="#distilbert" class="header-anchor"></a></h2><p>DistilBERT 出自<a href="http://arxiv.org/abs/1910.01108" target="_blank" rel="noopener">DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter</a>,<br>论文中作者通过调查发现BERT 中的hidden size 的对计算效率的改变比hidden layer nums 的影响小，说白了就是让模型变矮比让模型变瘦效率更高，<br>所以作者使用了一个更矮的BERT来做Student 来迁移BERT 中的知识。由于DistilBERT 是一个与BERT 同结构只是层数更小，所以DistilBERT 可以用<br>BERT 的预训练的权重进行初始化，此外，DistilBERT 是一个与任务无关的模型，即与BERT 一样，可以对很多下游任务进行fine-tuning。<br>由于DistilBERT 与 BERT 的前几层一致，所以loss 的选择上就更多一些，作者选择了triple loss：<br>MLM loss + embedding cosin loss + soften labels cross entropy .s</p><h3><span id="you-dian">优点</span><a href="#you-dian" class="header-anchor"></a></h3><p>DistilBERT 做到了与BERT 一样，完全与任务无关，不需要添加额外的Distillation 阶段（添加后结果会更好)。</p><h2><span id="mobilebert">MobileBERT</span><a href="#mobilebert" class="header-anchor"></a></h2><p>MobileBERT 出自<a href="http://arxiv.org/abs/2004.02984" target="_blank" rel="noopener">MobileBERT: a Compact Task-Agnostic BERT for Resource-Limited Devices</a>,<br>作者同样采用一个transformer 作为基本结构，但作者认为深度很重要，宽度较小对模型损坏较小，所以整体架构是保持模型深度不变，<br>通过一个矩阵来改变feature size，即bottleneck，在通过在block的前后插入两个bottleneck，来scale feature size。由于<br>MobileBERT太窄太深，所以不好训练，作者提出新的方式，通过一个同深但是更宽的同架构的模型来训练 作为teacher，然后用MobileBERT迁移。<br>loss 设计上主要包括三部分：feature map之间的MSE，Attention logits之间的KL，以及pre-training MLM + pre-training-NSP + pre-training-KD<br>训练策略上，有三种方式：</p><ol><li><strong>将KD作为附加预训练的附加任务，即一起训练；</strong></li><li><strong>分层训练，每次训练一层，同时冻结之前的层；</strong></li><li><strong>分开训练，首先训练迁移，然后单独进行pre-training.</strong></li></ol><p>此外，为了提高推理速度，将gelu 替换为更快的 relu ，LayerNormalization 替换为 更简单的NoNorm，也做了量化的实验。</p><h3><span id="you-dian">优点</span><a href="#you-dian" class="header-anchor"></a></h3><ol><li><strong>首先mobileBERT容量更小，推理更快，与任务无关，可以当bert来直接在下游fine-tuning，而之前的KD大多数时候需要与任务绑定并使用数据<br>增强，才能达到不错的性能；</strong></li><li><strong>论文实验非常详实，包括如何选择inter-block size, intra-block size, 不同训练策略如何影响等;</strong></li><li><strong>训练策略上，除了之前的一起训练完，实验了两种新的训练方式，而最终的一层一层的训练与skip connection 有异曲同工的作用：每层都学一小部分<br>内容，从而降低学习的难度；</strong></li><li><strong>替换了gelu 和 LayerNormalization,进一步提速.</strong></li></ol><h3><span id="que-dian">缺点</span><a href="#que-dian" class="header-anchor"></a></h3><ol><li>要训练一个IBBERT作为teacher，而这个模型容量与BERT-Large差不多，增加了训练难度.</li></ol><h1><span id="lun-wen-zong-jie">论文总结</span><a href="#lun-wen-zong-jie" class="header-anchor"></a></h1><p>以上论文的迁移过程其实可以总结为两类：</p><ol><li><strong>soft label迁移，即主要迁移Teacher 模型最后分类层的logits 及相应的soft label；</strong></li><li><strong>feature迁移，即除了最后分类层外，还迁移Teacher 模型中的output/attention/embedding等特征。</strong></li></ol><p>Student 的选择上，除了自定义外，还可以选择跟Teacher 同结构，而为了降低参数量，可以选择将模型变矮/变窄/减小hidden size 等方式。<br>而为了蒸馏后的模型能更加的general，适应更多的task，就需要迁移更多的信息，设计上也越复杂。</p><h1><span id="xiang-fa">想法</span><a href="#xiang-fa" class="header-anchor"></a></h1><p>实际工作上，大多数时候我们都是需要一个task 来做模型，而以上论文中告诉我们，迁移的信息越多，Student 的性能越好。而针对具体task ，我觉得<br>比较简洁有效的一种方式是采用更矮的Teacher 来作为Student ，这样可以直接将Teacher 中的前几层的信息完全迁移过来，然后在object 上，<br>加入迁移Teacher 在train data 上的logits ，这样就可以比较有效的进行蒸馏了。<br>除此之外，让我们换个角度看看为什么logits 能增强Student 模型的性能呢？除了迁移的角度外，其实logits 提供了label<br>更多的信息（不同类别的相对关系），而这个额外信息只要优于随机分布，就能对模型提供更多的约束信息，从而增强模型性能，即当前的模型可以看<br>作是分别拟合ground truth 和 logits的两个模型的<code>ensemble</code>，只不过是两个模型共享参数。<br>上面我们提到只要logits 优于随机，对Student 模型来说就会有所提升，那logits 由谁产生的其实并不重要。所以，我们除了可以用Teacher 产生的<br>logits来增强Student 模型外，我们还可以增强Teacher 模型，或者直接用Student 先学习一下，产生logits，再用Student 去迁移上次产生的logits。<br>想到这里，我不禁的有个大胆的想法：<code>既然我可以一边生成logits， 一边学习logits，那我不是可以持续这个过程，直到模型完全拟合train data，<br>生成的logits退化为one-hot，那此时的模型是不是能得到一个非常大的提升呢？</code></p><h1><span id="shi-yan">实验</span><a href="#shi-yan" class="header-anchor"></a></h1><p>实验的基本设置是用12层bert 作为Teacher model ，用3层bert 作为Student model 。soften labels 采用Temperature 平滑后的结果，此外，<br>Student model 除了学习 soften labels 的外，也需要学习ground truth。</p><h2><span id="teacher-to-student">Teacher-to-Student</span><a href="#teacher-to-student" class="header-anchor"></a></h2><p>Teacher model 在train data 上训练，然后在train data 上生成对应的soften labels，Student model 学习ground truth 和 soften labels。 </p><h2><span id="student-to-student">student-to-student</span><a href="#student-to-student" class="header-anchor"></a></h2><p>既然soften labels 是一种对labels 的一种平滑估计，那我们可以用任何方式去估计他，所以这里我们就用student 去做一个估计：<br>student model 在train data 上进行训练，然后在train data 上生成对应的soften labels ，将 student model 利用bert 预训练结果重新初始化，<br>然后去学习ground truth 和 soften labels.</p><h2><span id="normal-noise-training">normal-noise-training</span><a href="#normal-noise-training" class="header-anchor"></a></h2><p>既然是对labels 的一个估计，那假如给一个随机的估计，只要保证生成的logits 中true label 对应的值最大，就能对Student 模型进行一定程度的提升：<br>直接在train label 上添加一个normal noise ，然后重新进行平滑后归一，作为soften labels让student model 去学习。</p><h1><span id="shi-yan-jie-guo">实验结果</span><a href="#shi-yan-jie-guo" class="header-anchor"></a></h1><p>$$<br>\begin{array}{c|c|c}<br>\hline \\<br>\text{teacher standalone} &amp; \text{student standalone} &amp; \text{teacher-to-student} &amp; \text{teacher-to-teacher} &amp; \text{student-to-student} &amp; \text{normal-noise-student}\\<br>\hline \\<br>60.21\% &amp; 58.14\% &amp; 60.14\% &amp; 60.14\% &amp; 61.07\% &amp; 59.5\%<br>\end{array}<br>$$</p><p>从结果中可以看到：</p><ol><li><strong>优于随机的logits 对Student 模型有一定的提升，估计越准确，提升越高；</strong></li><li><strong>越大的模型性能越好;</strong><br>3.<strong>迭代进行logits 的生成与训练不能进一步提高模型性能，原因主要是新的logits 分布相比之前的对模型的提升非常小，此外这个分布也比较容易拟<br>合，所以无法进一步提升。</strong></li></ol><p>完整实验代码地址<a href="https://github.com/xv44586/toolkit4nlp/blob/master/examples/distilling_knowledge_bert.py" target="_blank" rel="noopener">distilling_knowledge_bert</a></p><h1><span id="zong-jie">总结</span><a href="#zong-jie" class="header-anchor"></a></h1><p>本文主要针对目前针对BERT 的知识蒸馏进行了总结，并提出了针对具体任务时可行的简洁方案，同时在新的视角下探讨了知识蒸馏有效的一些原因，<br>并通过实验进行了验证，发表顺序上上篇<a href="https://xv44586.github.io/2020/08/09/bert-of-theseus/">bert-of-theseus</a> 更晚一些，有兴趣的可以再去看一下上一篇。</p><h1><span id="guan-yu-tou-tu">关于头图</span><a href="#guan-yu-tou-tu" class="header-anchor"></a></h1><p>芝麻街</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;/assets/css/APlayer.min.css&quot;&gt;&lt;script src=&quot;/assets/js/APlayer.min.js&quot; cla
      
    
    </summary>
    
    
      <category term="NLP" scheme="https://xv44586.github.io/categories/NLP/"/>
    
    
      <category term="BERT" scheme="https://xv44586.github.io/tags/BERT/"/>
    
      <category term="Distillation" scheme="https://xv44586.github.io/tags/Distillation/"/>
    
  </entry>
  
  <entry>
    <title>模型增强（1）&amp;#58; 利用NLG 增强QA 任务性能</title>
    <link href="https://xv44586.github.io/2020/08/22/qa-augmentation/"/>
    <id>https://xv44586.github.io/2020/08/22/qa-augmentation/</id>
    <published>2020-08-22T01:38:13.000Z</published>
    <updated>2020-10-25T02:55:33.062Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><div class="toc"><!-- toc --><ul><li><a href="#bei-jing">背景</a></li><li><a href="#unilm">UniLM</a></li><li><a href="#shu-ju-zeng-qiang">数据增强</a></li><li><a href="#shi-yan">实验</a><ul><li><a href="#wen-ti-sheng-cheng">问题生成</a></li><li><a href="#wen-ti-da-an-dui-sheng-cheng">问题答案对生成</a></li></ul></li><li><a href="#zong-jie">总结</a></li><li><a href="#guan-yu-tou-tu">关于头图</a></li></ul><!-- tocstop --></div><h1><span id="bei-jing">背景</span><a href="#bei-jing" class="header-anchor"></a></h1><p>上周打算把UniLM在<a href="https://github.com/xv44586/toolkit4nlp" target="_blank" rel="noopener">toolkit4nlp</a>的基础上实现一下，又刷了一遍<a href="https://arxiv.org/pdf/1905.03197.pdf" target="_blank" rel="noopener">论文</a>,发现作者提到用UniLM做问题生成，来增强QA任务的性能，觉得很有意思，所以想尝试一下。</p><h1><span id="unilm">UniLM</span><a href="#unilm" class="header-anchor"></a></h1><p>因为这篇 UniLM 是主角，所以简单介绍一下该模型。该模型是通过灵活使用 attention mask ，将 NLG 与 NLU 任务统一在来一起，所以叫 unified LM，<br>他的做法是将 left-to-right/right-to-left/masked lm/seq2seq lm/放在一个框架里训练，从而让模型兼具 NLU 与 NLG 的能力。<br><img src="/2020/08/22/qa-augmentation/lm.png" alt><br>而为了达到这个训练，只需要在 bert 的基础上根据不同的 lm 调整 attention mask 即可。所以利用 bert 做 NLG 时，只需要调整 attention mask<br>为 seq2seq lm 对应mask即可。</p><h1><span id="shu-ju-zeng-qiang">数据增强</span><a href="#shu-ju-zeng-qiang" class="header-anchor"></a></h1><p>通常增强都是同义词/近义词替换，subsequence的随机删除/重复/互换等，我之前在做百度比赛时尝试过随机删除和随机两个片段互换位置，提升不是<br>非常大而论文里大问题生成带来大提升还是相当大的：<br><img src="/2020/08/22/qa-augmentation/table9.png" alt><br>仔细想一下，由于attention机制，互换只是改变了position embedding部分内容，而这部分的互换对模型的影响是很弱的；随机删除可能会破坏语义，<br>所以增加模型robust的同时可能会降低模型性能。而问题生成，则可以看作是同义词/近义词替换的句子级别替换，所以理论上能带来不错的提升。<br>从对抗的角度来看，生成的问题在语义上与原问题基本一致，这也正好符合<code>输入的微小改变</code>，从而让模型在这种带有微小扰动的前提下仍然能很好的预测。</p><h1><span id="shi-yan">实验</span><a href="#shi-yan" class="header-anchor"></a></h1><p>既然UniLM具有很强的NLG能力能力，那就有很多不同的玩法。首先，可以训练一个模型，来针对 context 和 answer 生成对应的问题，来对问题进行<br><code>“换个问法”</code>，其次，既然可以对问题<cdoe>“换个问法”,自然也可以<code>“换个问题”</code>,也就是根据 context 生成新的问题<br>和答案。另外，由于是扩增训练数据，所以有一个技巧是做生成是将 train data 与 dev data 互换，不过由于我用的是百度比赛数据，dev data 太少，<br>所以我是 train + dev。</cdoe></p><h2><span id="wen-ti-sheng-cheng">问题生成</span><a href="#wen-ti-sheng-cheng" class="header-anchor"></a></h2><p>问题生成时，就是将 context 与 answer 拼接，然后生成对应的question。具体样本形如：<code> [CLS] answer + context [SEP] question [SEP]</code> .<br>模型直接用bert base权重按UniLM的seq2seq方式来构建，可以看到效果还是很不错的，比如：</p><blockquote><br>context：报雅思或者托付培训班,一般情况下要900元左右。 雅思和托福考试可以自学: 一、基础知识准备:单词、基本语法、长难句分析; 二、板块训练:听说读写,四个板块; 三、合理备考计划,可以参见中国上别人经验结合自己的自身条件; 四、效果强化跟踪,使用合理的备考软件或者是自测题目随时跟踪自己的学习状态<br>question：雅思班价格<br>answer: [‘900元’, ‘900元左右’]<br>generate question: 雅思班报名多少钱<br></blockquote><blockquote>context：USB电压有5伏 USB一般4根线, 中间两根是数据线, 左右各为 +- 线 只要不短路是不会烧主板该插口的 ,我想你应该这样做,手机的线的一端直接插入手提电脑,另一头剪掉头子,从线中分离出四根线, 用万用表测出(红色+和其它色如黑-)剩下两根用胶布包扎(不用)然后 在这两根线上(正电极中最好串一50到100欧电阻)后接入一支高亮度发光二极管就成功了.<br>question：usb线电压<br>answer: [‘5伏’]<br>generate question: usb线电压 </blockquote><p>解码时，有两种选择：随机抽样与 beam search 。随机抽样可以增加问题的多样性，并且可以生成多个问题；beam search近似最优，得到一个最优的<br>问题。由于我们是使用 train data 训练模型，在对 train data 生成新的问题时，beam search 将可能产生很多一摸一样的问题，这样将降低新增<br>数据的量；而随机抽样能产生很多新的问题，但可能新生成的问题与答案并不配套，还需要一些后处理之后才能真正拿来用。这里两种方式都拿来做实验，<br>并对生成的问题做一个简单的过滤：新生成的问题与原问题中有70%以上的字是重合的。<br>$$<br>\begin{array}{c|c|c}<br>\hline \\<br>\text{base line} &amp; \text{beam search} &amp; \text{random sample}\\<br>\hline \\<br>80.39\% &amp; 81.0\% &amp; 79.8\%<br>\end{array}<br>$$</p><p>random sample的样本经过了很多次过滤之后才能基本达到baseline的效果，所以生成的问题如果”问非所答”，对最终的效果反而是不好的，这也符合预期。</p><h2><span id="wen-ti-da-an-dui-sheng-cheng">问题答案对生成</span><a href="#wen-ti-da-an-dui-sheng-cheng" class="header-anchor"></a></h2><p>问题答案对生成时，由于答案是在 context 内的，相对问题生成简单一些，所以我们先生成答案，再根据 context 和生成的 answer 来生成对应的<br>question。不过为了让问题答案对更丰富多样，解码答案时我们采用随机抽样，而生成问题时，为了让问题尽量准确，我们采用 beam search。<br>样本形如 <code>[CLS]context[SEP]answer[SEP][question][SEP]</code>，生成的效果如下：</p><p><blockquote><br>context：您好，孕妇整个孕期体重增加12.5公斤左右，在增加的这12.5公斤中，胎儿的体重占3公斤左右，胎盘和羊水约是2公斤左右。在孕早期（怀孕3个月以内）增加2公斤，中期（怀孕3－6个月）以及末期（怀孕7－9个月）各增加5公斤左右。所以怀孕6个月体重增加7公斤左右比较正常。希望我的回答对你有所帮助。<br>question：孕妇6个月体重增加多少<br>answer: 7公斤左右<br>generate question: 孕妇6个月体重增加多少<br>generate answer: 12.5公斤左右<br></blockquote><br>不过也由于train data 参与训练，所以很多生成的问题答案对与原始问题答案对一致，如果有更多的外部数据，可以利用外部数据来训练。<br>$$<br>\begin{array}{c|c|c|c}<br>\hline \\<br>\text{base line} &amp; \text{beam search} &amp; \text{random sample} &amp; \text{question answer generation}\\<br>\hline \\<br>80.39\% &amp; 81.0\% &amp; 79.8\% &amp; 81.76\% \\<br>\hline<br>\end{array}<br>$$</p><h1><span id="zong-jie">总结</span><a href="#zong-jie" class="header-anchor"></a></h1><p>通过生成新的问题与新的问题答案对能在一定程度上提高qa 任务的性能，在生成问题时，用beam search 得到的新问题虽然量少但由于更准确，所以<br>能带来一定的提升；用随机采样生成的问题会有部分与答案无关的或者语义有点不通顺的问题，所以可能反而会导致性能降低；问题答案对的生成时，<br>先生成相对简单的回答再生成对应问题，能对性能带来不错的提升，在做qa相关任务时，可以尝试使用一下。<br>实验代码：<br><a href="https://github.com/xv44586/toolkit4nlp/blob/master/examples/qa_baseline.py" target="_blank" rel="noopener">qa_baseline</a><br><a href="https://github.com/xv44586/toolkit4nlp/blob/master/examples/qa_question_generation_seq2seq.py" target="_blank" rel="noopener">qa_question_generation_seq2seq</a><br><a href="https://github.com/xv44586/toolkit4nlp/blob/master/examples/qa_question_answer_generation_seq2seq.py" target="_blank" rel="noopener">qa_question_answer_generation_seq2seq</a></p><h1><span id="guan-yu-tou-tu">关于头图</span><a href="#guan-yu-tou-tu" class="header-anchor"></a></h1><p>看瓜的怒气小猫</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;/assets/css/APlayer.min.css&quot;&gt;&lt;script src=&quot;/assets/js/APlayer.min.js&quot; cla
      
    
    </summary>
    
    
      <category term="NLP" scheme="https://xv44586.github.io/categories/NLP/"/>
    
    
      <category term="QA" scheme="https://xv44586.github.io/tags/QA/"/>
    
      <category term="NLG" scheme="https://xv44586.github.io/tags/NLG/"/>
    
      <category term="UniLM" scheme="https://xv44586.github.io/tags/UniLM/"/>
    
  </entry>
  
  <entry>
    <title>Knowledge Distillation (1) &amp;#58; 模块替换之bert-of-theseus-下篇</title>
    <link href="https://xv44586.github.io/2020/08/19/bert-of-theseus-2/"/>
    <id>https://xv44586.github.io/2020/08/19/bert-of-theseus-2/</id>
    <published>2020-08-19T14:12:28.000Z</published>
    <updated>2020-10-25T02:55:33.025Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><div class="toc"><!-- toc --><ul><li><a href="#fu-xian-shi-de-wen-ti">复现时的问题</a><ul><li><a href="#si-kao-1-wei-shi-me-shi-xiao">思考1：为什么失效</a></li><li><a href="#si-kao-er-bert-of-theseus-you-xiao-de-ben-zhi-shi-shi-me">思考二 ：bert-of–theseus有效的本质是什么</a></li><li><a href="#shi-yan-1">实验1</a></li><li><a href="#si-kao-san-zhi-jie-zai-predecessor-shang-chou-successor-xing-bu-xing">思考三：直接在predecessor 上抽successor行不行？</a></li><li><a href="#shi-yan-2">实验2</a></li></ul></li><li><a href="#zong-jie">总结</a></li><li><a href="#guan-yu-tou-tu">关于头图</a></li></ul><!-- tocstop --></div><p>上一篇中介绍了bert-of-theseus论文的主要思路，并贴了两组实验的结论，这篇是对上篇的后续一些思考与实验。</p><h1><span id="fu-xian-shi-de-wen-ti">复现时的问题</span><a href="#fu-xian-shi-de-wen-ti" class="header-anchor"></a></h1><p>在复现时，遇到最大的问题就是结果不稳定。首先每次训练predecessor时，其最优结果就会有上下1个点左右的波动，而因为theseus 中引入了随机数<br>来概率替换对应block，所以结果上一言难尽，有时能比12层bert低0.6个点, 有时只能达到直接3层fine tuning 的效果，于是我做了些观察与思考。</p><h2><span id="si-kao-1-wei-shi-me-shi-xiao">思考1：为什么失效</span><a href="#si-kao-1-wei-shi-me-shi-xiao" class="header-anchor"></a></h2><p>在训练theseus model时，其中抽出的successor在每个epoch结束后在验证集上的结果有时会很高，基本到达只比三层fine-tuning低6个点，有时又很<br>低，基本不到0.1%, 第一种明显是successor在theseus中训练太多，以至于接近直接fine tuning，而另一种情况下可能是successor训练不充足，<br>也可能是替换次数太少导致没有被训练，而且大多数情况下successor的验证集上都是不到0.1%。<br>为了验证第二种情况下是否是未替换导致successor在做fine tuning，我将successor进行单独fine tuning后,将得到的classifier 拼回predecessor，<br>发现此时在验证集上d结果只下降了2个点，所以此时大概率是替换次数过少，基本没有训练到successor，所以导致结果不好，而这里开始我以为是我<br>实现问题，后来来来回回检查了一周，也没发现问题，于是我就想换一种更稳定的方式。</p><h2><span id="si-kao-er-bert-of-theseus-you-xiao-de-ben-zhi-shi-shi-me">思考二 ：bert-of–theseus有效的本质是什么</span><a href="#si-kao-er-bert-of-theseus-you-xiao-de-ben-zhi-shi-shi-me" class="header-anchor"></a></h2><p>熟悉bert的同学肯定对warm up不陌生，而warm up之所以有效，我认为比较重要的一点是如果在最初的steps中，模型提前拟合了样本，进入了一个局部<br>最优区域，后期无论你怎么迭代他都跳不出来，而由已经<code>fine tuned predecessor</code>带着一起再进行训练，也和warm up有些相似，即用小的<br>步子带着你朝着更优的方向走几步，跳出来，让你有进入更好的局部最优点的可能，此外，概率替换的思路也与<code>Dropout</code>有几分相似，让successor<br>有一定的几率参与训练，从而让successor在缺少predecessor的情况下也有一定的robust。<br><a href="https://spaces.ac.cn/archives/7575" target="_blank" rel="noopener">苏剑林的博客</a>里也提到了替换的数学形式：<br>$$<br>\begin{equation}\begin{aligned}<br>&amp;\varepsilon^{(l)}\sim U(\{0, 1\})\\<br>&amp;x^{(l)} = x_p^{(l)} \times \varepsilon^{(l)} + x_s^{(l)} \times \left(1 - \varepsilon^{(l)}\right)\\<br>&amp;x_p^{(l+1)} = F_p^{(l+1)}\left(x^{(l)}\right)\\<br>&amp;x_s^{(l+1)} = F_s^{(l+1)}\left(x^{(l)}\right)<br>\end{aligned}\end{equation}<br>$$<br>同时，他也提到$\epsilon$能否不取非0即1，那既然我们是想让successor在task方向上warm up一下，那直接相加，即此时 $\epsilon = k$,<br>k是常数也是可以的。此时只要调节k 就能避免successor训练不充分或太充分的情况了，模型也就稳定了，可以满足我们的要求了。</p><h2><span id="shi-yan-1">实验1</span><a href="#shi-yan-1" class="header-anchor"></a></h2><p>实验代码其实比较容易修改，只需将BinaryRandomChoice 层替换为相加即可。具体代码在<a href="https://github.com/xv44586/toolkit4nlp/blob/master/examples/classification_ifytek_bert_of_theseus.py" target="_blank" rel="noopener">classification_ifytek_bert_of_theseus</a><br>中可以看到。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ProportionalAdd</span><span class="params">(Layer)</span>:</span></span><br><span class="line">    <span class="string">"""将两层的结果乘比例后相加，output = (input_1 * proportion + input_2 * (1 - proportion)) / 2</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, proportion=<span class="number">0.5</span>, **kwargs)</span>:</span></span><br><span class="line">        super(ProportionalAdd, self).__init__(**kwargs)</span><br><span class="line">        self.supports_masking = <span class="literal">True</span></span><br><span class="line">        self.proportion = proportion</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">compute_mask</span><span class="params">(self, inputs, mask=None)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> mask <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">return</span> mask[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">call</span><span class="params">(self, inputs)</span>:</span></span><br><span class="line">        source, target = inputs</span><br><span class="line">        source = source * self.proportion</span><br><span class="line">        target = target * (<span class="number">1</span> - self.proportion)</span><br><span class="line">        output = (source + target)/<span class="number">2</span></span><br><span class="line">        <span class="keyword">return</span> K.in_train_phase(output, target)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">compute_output_shape</span><span class="params">(self, input_shape)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> input_shape[<span class="number">1</span>]</span><br></pre></td></tr></table></figure><p>文本分类：CLUE的iflytek数据集</p><p>$$<br>\begin{array}{c|c|c}<br>\hline<br>&amp; \text{直接微调} &amp; \text{BERT-of-Theseus}\\<br>\hline<br>\begin{array}{c}\text{层数} \\ \\text{效果}\end{array} &amp; \begin{array}{ccc}\text{完整12层} &amp; \text{前6层} &amp; \text{前3层}<br>\\ 60.11\% &amp; 58.99\%  &amp; 57.96\%\end{array} &amp; \begin{array}{cc}\text{6层} &amp; \text{3层} \\ 59.7\%  &amp; 59.5\% \end{array}\\<br>\hline<br>\end{array}<br>$$</p><p>结果上看确实更稳定了，也更好一点点了，基本比predecessor低<code>0.5%~1%</code> .</p><h2><span id="si-kao-san-zhi-jie-zai-predecessor-shang-chou-successor-xing-bu-xing">思考三：直接在predecessor 上抽successor行不行？</span><a href="#si-kao-san-zhi-jie-zai-predecessor-shang-chou-successor-xing-bu-xing" class="header-anchor"></a></h2><p>既然我们说bert-of-theseus有效的原因是在task 的方向进行了warm up，那predecessor已经在task上fine tuned了，能不能<code>直接抽取某几<br>层作为successor来直接fine tuning?</code>此外，之前我们也说了，predecessor与successor的classifer差距很小，那我们能不能改变successor<br>的classifer的学习率，让他进一步学习，来弥补一部分前三层无法拟合的分布呢？</p><h2><span id="shi-yan-2">实验2</span><a href="#shi-yan-2" class="header-anchor"></a></h2><p>具体实验代码<a href="https://github.com/xv44586/toolkit4nlp/blob/master/examples/two_stage_fine_tuning.py" target="_blank" rel="noopener">two-stage-fine-tuning</a><br>实验时尝试了<code>随机初始化classifier/predecessor classifier初始化classifier/ 放大classifier lr</code>组合策略，最后的结果就不贴了，基本都没有<br>超过3层bert fine tuning的效果。</p><h1><span id="zong-jie">总结</span><a href="#zong-jie" class="header-anchor"></a></h1><p>尝试分析了bert-of-theseus复现中的问题，并尝试了一些修复方案，同时，实验测试了theseus model的必要性，最后结论是binary random choice<br>策略不如 proportion add 策略稳定，同时，theseus是必须的。</p><h1><span id="guan-yu-tou-tu">关于头图</span><a href="#guan-yu-tou-tu" class="header-anchor"></a></h1><p><a href="https://github.com/JetRunner/BERT-of-Theseus" target="_blank" rel="noopener">论文原作者配图</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;/assets/css/APlayer.min.css&quot;&gt;&lt;script src=&quot;/assets/js/APlayer.min.js&quot; cla
      
    
    </summary>
    
    
      <category term="NLP" scheme="https://xv44586.github.io/categories/NLP/"/>
    
    
      <category term="BERT" scheme="https://xv44586.github.io/tags/BERT/"/>
    
      <category term="Distillation" scheme="https://xv44586.github.io/tags/Distillation/"/>
    
  </entry>
  
  <entry>
    <title>Knowledge Distillation (1) &amp;#58; 模块替换之bert-of-theseus-上篇</title>
    <link href="https://xv44586.github.io/2020/08/09/bert-of-theseus/"/>
    <id>https://xv44586.github.io/2020/08/09/bert-of-theseus/</id>
    <published>2020-08-09T13:26:26.000Z</published>
    <updated>2020-10-25T02:55:33.066Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><div class="toc"><!-- toc --><ul><li><a href="#mo-xing-ya-suo">模型压缩</a><ul><li><a href="#jian-zhi">剪枝</a></li><li><a href="#liang-hua">量化</a></li><li><a href="#zhi-shi-zheng-liu">知识蒸馏</a></li><li><a href="#quan-chong-gong-xiang">权重共享</a></li><li><a href="#quan-chong-fen-jie">权重分解</a></li><li><a href="#mo-xing-ya-suo-de-bi-yao-xing">模型压缩的必要性</a></li><li><a href="#bert-of-theseus">Bert of theseus</a></li><li><a href="#ju-ti-liu-cheng">具体流程</a></li><li><a href="#shi-yan-xiao-guo">实验效果</a></li></ul></li><li><a href="#guan-yu-tou-tu">关于头图</a></li></ul><!-- tocstop --></div><blockquote>如果忒修斯的船上的木头被逐渐替换，直到所有的木头都不是原来的木头，那这艘船还是原来的那艘船吗？<br><br>-普鲁塔克</blockquote><p>最近遇到一个需要对算法加速的场景，了解到了一个比较简洁实用的方法：<a href="https://arxiv.org/abs/2002.02925" target="_blank" rel="noopener">Bert-of-theseus</a>,<br>了解了原理后参考代码实验后，验证了其有效性，所以总结一下。</p><h1><span id="mo-xing-ya-suo">模型压缩</span><a href="#mo-xing-ya-suo" class="header-anchor"></a></h1><p>模型在设计之初都是过参数化的，这是因为模型的参数量与复杂度代表着模型的容量与学习能力，但当我们实际使用时，我们需要更好的部署他（低资源），更快的响应（快速推理），常常需要进行模型压缩。<br>模型压缩就是<code>简化大的模型，得到推理快资源占用低的小模型</code>，而想”即要马而跑又不用吃草”通常是很难的，所以压缩后的模型常常也会有不同程度的牺牲，如模型性能下降。<br>此外，模型压缩是作用在推理阶段，带来的常常是训练时间的增加。<br>模型压缩又分为两种方式：一种是<code>剪枝(Pruning)</code>与<code>量化(Quantization)</code>,一种是<code>知识蒸馏(Knowledge Distillation)</code>,<br>还有一种是<code>权重共享（Sharing）与因数分解（Factorization）</code>。该部分内容推荐一篇博客：<a href="http://mitchgordon.me/machine/learning/2019/11/18/all-the-ways-to-compress-BERT.html" target="_blank" rel="noopener">All The Ways You Can Compress BERT</a></p><h2><span id="jian-zhi">剪枝</span><a href="#jian-zhi" class="header-anchor"></a></h2><p>剪枝技术是通过将大模型中一些”不重要”的连接剪断，得到一个”稀疏”结构的模型。剪枝又分为”结构性剪枝”与”非结构性剪枝”.剪枝可以作用在权重粒度，<br>也可以作用在attention heads / layer粒度上。不过剪枝技术感觉会逐步被<cdoe>NAS（Neural Architecture Search）取。</cdoe></p><h2><span id="liang-hua">量化</span><a href="#liang-hua" class="header-anchor"></a></h2><p>量化不改变模型的网络结构，而是改变模型的参数的数据格式，通常模型在建立与训练时使用的是 float32 格式的，量化就是将格式转换为 <code>low-bit</code>, 如 float16 甚至二值化，如此即提速又省显存。</p><h2><span id="zhi-shi-zheng-liu">知识蒸馏</span><a href="#zhi-shi-zheng-liu" class="header-anchor"></a></h2><p>知识蒸馏是训练一个小模型(student)来学习大模型(teacher)，由于大模型是之前已经fine-tuning的，所以此时学习的目标已经转换为对应的logit而<br>不再是one-hot编码了，所以student有可能比teacher的性能更好。这样即小又准的模型实在太好了。不过为了达到这样的效果，通常设计小模型时不<br>光要学习大模型的输出，还要学习各个中间层结果，相关矩阵等，这就需要仔细设计模型的结构与loss及loss融合方案了。一种简单的方法是只学习大模型的logit，这与对label做embedding有点类似，不过我没做过实验还。</p><h2><span id="quan-chong-gong-xiang">权重共享</span><a href="#quan-chong-gong-xiang" class="header-anchor"></a></h2><p>将部分权重在多个层中共享以达到压缩模型的效果，如ALBERT中共享self-attention中的参数</p><h2><span id="quan-chong-fen-jie">权重分解</span><a href="#quan-chong-fen-jie" class="header-anchor"></a></h2><p>将权重矩阵进行因数分解，形成两个低秩的矩阵相乘的形式，从而降低计算量</p><h2><span id="mo-xing-ya-suo-de-bi-yao-xing">模型压缩的必要性</span><a href="#mo-xing-ya-suo-de-bi-yao-xing" class="header-anchor"></a></h2><p>看了上面模型压缩的方法，每一个都有种”脱裤子放屁”的感觉，与其训练一个大模型，再费力把它变小，为何不直接开始就弄个小的呢？<br>首先，模型在设计之初是都是会或多或少的过参数化，因为模型的参数量与复杂度代表着模型的容量与学习能力；<br>其次，开始就用一个小模型，那这个小模型也是需要设计的，不能随便拿来一个，而设计一个性能高参数规模小的小模型难度是非常大的，往往是模型小了性能也低了；<br>第三点，大模型压缩后与小模型虽然参数规模相当，但是对应的模型空间并不相同<br>此外，为了更好的部署，如手机或FPGA等，得到精度更高模型更小(distillation)或者利用硬件加速(low-bit)，模型压缩都是值得试一试的手段。<br>更详细的讨论，可以参考<a href="https://www.zhihu.com/question/303922732" target="_blank" rel="noopener">为什么要压缩模型，而不直接训练一个小的CNN</a></p><h2><span id="bert-of-theseus">Bert of theseus</span><a href="#bert-of-theseus" class="header-anchor"></a></h2><p>Bert of theseus 方法属于上面提到的知识蒸馏，知识蒸馏中我们提到，在蒸馏时，我们不光要学习teacher的输出，对中间层我们也希望他们直接尽量相似，<br>那想象一个这种状态对应对理想情况：<code>中间层的结果一致，最终的结果一致</code>,既然我们的期望中间结果一致，那也就意味着两者可以互相替换。<br>正如开头提到的忒修斯之船一样。所以核心思想是：<br><code>与其设计复杂的loss来让中间层结果相似不如直接用小模型替换大模型来训练</code><br>通过复杂loss来达到与中间层结果相似可以看作是一种整体渐进式的逼近，让小模型一点点去学习，而直接替换可以看作是一种简单粗暴的方式，<br>但是他不需要设计各种loss，优化目标也是同一个，就只有一个下游任务相关的loss，突出一个<code>简洁</code>。<br>这就好比高中上学一样，即使花高价也要让孩子去一所好高中，因为学校的”氛围”能让孩子的学习成绩进步，其实是因为周围的孩子带着一起学，<br>弱鸡也能学的比平时更多一点。bert-of-theseus也是类似的道理，跟着大佬（teacher）总比单独fine-tuning效果好。</p><h2><span id="ju-ti-liu-cheng">具体流程</span><a href="#ju-ti-liu-cheng" class="header-anchor"></a></h2><p>如果直接将小模型替换大模型，那其实是在对小模型进行微调，与大模型就脱离了，也达不到对应的效果，所以作者采用了一种概率替换的方式。<br>首先呢，想象我们现在已经训练好了一个6层的BERT，我们成为<code>Predecessor（前辈）</code>, 而我们需要训练一个三层的bert，<br>他的结果近似12层BERT的效果，我们成为<code>Successor(传承者)</code>,那 bert-of-theseus的模型结构如<a href="https://spaces.ac.cn/archives/7575" target="_blank" rel="noopener">下图</a>所示：</p><p><img src="/2020/08/09/bert-of-theseus/bert-of-theseus.png" alt="bert-of-theseus"></p><p>在bert-of-theseus中，首先固定predecessor的权重，然后将6层的Bert分为3个block，每个block与successor的一层对应，训练过程分为两个stage：<br>首先用successor中的层概率替换predecessor中对应的block，在下游任务中直接fine-tuning（只训练successor），<br>然后将successor从bert-of-theseus中分离出来，单独在下游任务中进行fine-tuning，直到指标不再上升。<br>所谓替换，就是输出的替换，在进入下一层前在predecessor和successor的输出中二选一。<br>替换概率作者也给出了两种方式，一种是固定 0.5,一种是线性从0-1,如下图所示：<br><img src="/2020/08/09/bert-of-theseus/figure2.png" alt></p><h2><span id="shi-yan-xiao-guo">实验效果</span><a href="#shi-yan-xiao-guo" class="header-anchor"></a></h2><p>实验代码主要参考<a href="https://github.com/bojone/bert-of-theseus" target="_blank" rel="noopener">bert-of-theseus</a>, 实验主要做了三组，一组文本分类两组ner-crf，结果如下：</p><p>文本分类：CLUE的iflytek数据集</p><p>$$<br>\begin{array}{c|c|c}<br>\hline<br>&amp; \text{直接微调} &amp; \text{BERT-of-Theseus}\\<br>\hline<br>\begin{array}{c}\text{层数} \\ \\text{效果}\end{array} &amp; \begin{array}{ccc}\text{完整12层} &amp; \text{前6层} &amp; \text{前3层}<br>\\ 60.11\% &amp; 58.99\%  &amp; 57.96\%\end{array} &amp; \begin{array}{cc}\text{6层} &amp; \text{3层} \\ 59.6\%  &amp; 59.3\% \end{array}\\<br>\hline<br>\end{array}<br>$$</p><p>ner-crf: 公司数据<br>$$<br>\begin{array}{c|c|c}<br>\hline<br>&amp; \text{直接微调} &amp; \text{BERT-of-Theseus}\\<br>\hline<br>\begin{array}{c}\text{层数} \\ \\text{效果}\end{array} &amp; \begin{array}{ccc}\text{完整12层} &amp; \text{前6层} &amp; \text{前3层}<br>\\ 97.5\% &amp; 97.0\%  &amp; 96.1\%\end{array} &amp; \begin{array}{cc}\text{6层} &amp; \text{3层} \\ 97.3\%  &amp; 96.6\% \end{array}\\<br>\hline<br>\end{array}<br>$$</p><p>可以看到，相比直接那前几层微调，bert-of-theseus的效果确实更好，此外，我还尝试了线性策略的替换概率，效果上差别不大。<br>实验代码：<a href="https://github.com/xv44586/toolkit4nlp/blob/master/examples/classification_ifytek_bert_of_theseus.py" target="_blank" rel="noopener">classification_ifytek_bert_of_theseus</a><br><a href="https://github.com/xv44586/toolkit4nlp/blob/master/examples/sequence_labeling_ner_bert_of_theseus.py" target="_blank" rel="noopener">sequence_labeling_ner_bert_of_theseus</a></p><h1><span id="guan-yu-tou-tu">关于头图</span><a href="#guan-yu-tou-tu" class="header-anchor"></a></h1><p><a href="https://github.com/JetRunner/BERT-of-Theseus" target="_blank" rel="noopener">论文原作者配图</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;/assets/css/APlayer.min.css&quot;&gt;&lt;script src=&quot;/assets/js/APlayer.min.js&quot; cla
      
    
    </summary>
    
    
      <category term="NLP" scheme="https://xv44586.github.io/categories/NLP/"/>
    
    
      <category term="BERT" scheme="https://xv44586.github.io/tags/BERT/"/>
    
      <category term="Distillation" scheme="https://xv44586.github.io/tags/Distillation/"/>
    
  </entry>
  
  <entry>
    <title>optimizer of bert</title>
    <link href="https://xv44586.github.io/2020/08/01/optimizer-in-bert/"/>
    <id>https://xv44586.github.io/2020/08/01/optimizer-in-bert/</id>
    <published>2020-08-01T12:48:48.000Z</published>
    <updated>2020-10-25T02:55:33.059Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><div class="toc"><!-- toc --><ul><li><a href="#zheng-ti-you-hua-fang-an">整体优化方案</a></li><li><a href="#adam-in-bert">Adam in bert</a><ul><li><a href="#weight-decay">weight decay</a><ul><li><a href="#weight-decay-1">weight decay</a></li><li><a href="#l2-regularization">L2 regularization</a></li></ul></li></ul></li><li><a href="#learning-rate">Learning rate</a><ul><li><a href="#learning-rate-decay">Learning rate decay</a></li><li><a href="#warmup">warmup</a></li></ul></li><li><a href="#zong-jie">总结</a></li><li><a href="#guan-yu-tou-tu">关于头图</a></li></ul><!-- tocstop --></div><p>最近尝试实现了 bert ,在最后 pretraining 是发现 bert 中的优化方法比较有趣，所以记录一下自己的理解。</p><h1><span id="zheng-ti-you-hua-fang-an">整体优化方案</span><a href="#zheng-ti-you-hua-fang-an" class="header-anchor"></a></h1><p>bert中的优化方案可以总结为：线性分段学习率 + weight decay Adam</p><h1><span id="adam-in-bert">Adam in bert</span><a href="#adam-in-bert" class="header-anchor"></a></h1><p>首先简单回忆一下 Adam Optimizer：<br>整体框架：<br>$$<br>g_{t}=\bigtriangledown f(w_{t})<br>$$<br>$$<br>m_{t}=\Phi (g_{1},g_{2},…,g_{t})<br>$$<br>$$<br>v_{t}=\Psi (g_{1},g_{2},…,g_{t})<br>$$<br>$$<br>\eta =\alpha \cdot m_{t}/\sqrt{V_{t}}<br>$$<br>$$<br>\omega_{t+1}=\omega_{t}-\eta_{t}<br>$$</p><p>其中一阶动量 m 与二阶动量 v 的计算方式：<br>$$<br>m_{t}=\beta_{1}m_{t-1} + (1-\beta_{1})\cdot g_{t}<br>$$<br>$$<br>v_{t}=\beta_{2}v_{t-1} + (1-\beta_{2})\cdot g_{t}^{2}<br>$$<br>参数一般取值：ß1=0.9，ß2=0.999<br>而也是这个原因，初期对一阶动量与二阶动量v的估算都偏小，会导致优化方向朝着 0 走，所以，一般会进行一个修正（bias correct），方式是：<br>$$<br>\hat{m_{t}}=m_{t}/1-{\beta_{1}}^{t}<br>$$<br>$$<br>\hat{v_{t}}=v_{t}/1-{\beta_{2}}^{t}<br>$$<br>而 bert 中实现都 Adam 却没有进行这个修正，至于原因，放在下面一起说。</p><h2><span id="weight-decay">weight decay</span><a href="#weight-decay" class="header-anchor"></a></h2><p>在 bert 中对 Adam 进行了weight decay，具体代码上是这一段：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Just adding the square of the weights to the loss function is *not*</span></span><br><span class="line"><span class="comment"># the correct way of using L2 regularization/weight decay with Adam,</span></span><br><span class="line"><span class="comment"># since that will interact with the m and v parameters in strange ways.</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Instead we want ot decay the weights in a manner that doesn't interact</span></span><br><span class="line"><span class="comment"># with the m/v parameters. This is equivalent to adding the square</span></span><br><span class="line"><span class="comment"># of the weights to the loss with plain (non-momentum) SGD.</span></span><br><span class="line"><span class="keyword">if</span> self._do_use_weight_decay(param_name):</span><br><span class="line">      update += self.weight_decay_rate * param</span><br></pre></td></tr></table></figure></p><p>这里讲到<code>直接将权重的平方加入到loss 上进行L2 regularization 在 Adam 上是一种错误到方式</code></p><h3><span id="weight-decay">weight decay</span><a href="#weight-decay" class="header-anchor"></a></h3><p>Weight decay是在每次更新的梯度基础上减去一个梯度</p><p>$$\theta_{t+1}=(1-\lambda )\theta_{t} -\alpha \bigtriangledown f_{t}(\theta_{t})$$</p><h3><span id="l2-regularization">L2 regularization</span><a href="#l2-regularization" class="header-anchor"></a></h3><p>L2 regularrization是在参数上加上L2惩罚</p><p>$$ f_{t}^{reg}(\theta)=f_{t}(\theta)+\frac{ {\lambda }’}{2}\left \| \theta\right \| _{2}^{2}$$</p><p>可以看出，在标准SGD下，两者是等价的<br>但是，在Adam下，两者却不是。我们将Adam下的梯度更新完整公式写出来：</p><p>$$ \theta_{t}\leftarrow \theta_{t-1} -\alpha \frac{\beta_{1}m_{t-1}+(1-\beta_{1})(\bigtriangledown f_{t}+\lambda \theta_{t-1})}{\sqrt{\hat{v_{t}}} + \varepsilon  }$$</p><p>而与参数有关的是右上角的部分：<code>$\frac{\lambda \theta_{t-1}}{\sqrt{v_{t}}}$</code> 而这一项表明，在梯度变化越大的方向上，v的值也越大，但对应的权重约束却越小，这显然是不合理的，此外，L2 与 weight decay 都是各个方向同性的，<br>所以针对这一问题，一种调整方式是将梯度更新与weight decay 解偶，<br><img src="/2020/08/01/optimizer-in-bert/de.png" alt><br>具体参考<a href="https://arxiv.org/pdf/1711.05101.pdf" target="_blank" rel="noopener">DECOUPLED WEIGHT DECAY REGULARIZATION</a><br>而 bert 中也是使用了这种weight decay 方式，来达到与L2正则等效</p><h1><span id="learning-rate">Learning rate</span><a href="#learning-rate" class="header-anchor"></a></h1><h3><span id="learning-rate-decay">Learning rate decay</span><a href="#learning-rate-decay" class="header-anchor"></a></h3><p>通常，为了让模型在后期避免震荡，更加稳定，都会随着训练的进行，将learning rate 进行调整，即越是后期learning rate 越小。</p><h3><span id="warmup">warmup</span><a href="#warmup" class="header-anchor"></a></h3><p>而bert中的learning rate的调整是两段线性调整学习率：前 10% steps 将learning rate 从 0 增长到 init_learning_rate，然后，再一致递减 到0<br>而warmup为何有效？</p><ol><li>可以避免较早的对mini-batch过拟合，即较早的进入不好的局部最优而无法跳出；</li><li>保持模型深层的稳定性<br>具体可以参考<a href="https://www.zhihu.com/question/338066667/answer/771252708" target="_blank" rel="noopener">warmup 为什么有效</a></li></ol><p>此外，由于warmup要求前期保持较小的更新，所以Adam中由于前期会导致更新变小而需要进行的bias correct也可以去掉了。这也就是最初留下到那个问题到答案</p><h1><span id="zong-jie">总结</span><a href="#zong-jie" class="header-anchor"></a></h1><p>bert在 pretraining 为了让模型收敛到一个较好的点，不但在优化器 Adam 上使用了与 L2 regularization等效的weight decay，为了避免模型前期过早拟合进入local minimal，使用了warmup 策略。<br>bert作者也建议在进行fine-tuning时，使用与bert源码中相同的优化器，我也做了一些实验，提升有大概不到0.5个点（没有细调），所以在下游任务上可以尝试使用。</p><h1><span id="guan-yu-tou-tu">关于头图</span><a href="#guan-yu-tou-tu" class="header-anchor"></a></h1><p>摄于圆明园荷花池</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;/assets/css/APlayer.min.css&quot;&gt;&lt;script src=&quot;/assets/js/APlayer.min.js&quot; cla
      
    
    </summary>
    
    
      <category term="NLP" scheme="https://xv44586.github.io/categories/NLP/"/>
    
    
      <category term="Optimizer" scheme="https://xv44586.github.io/tags/Optimizer/"/>
    
      <category term="BERT" scheme="https://xv44586.github.io/tags/BERT/"/>
    
  </entry>
  
  <entry>
    <title>装机指北</title>
    <link href="https://xv44586.github.io/2020/05/05/make-a-computer/"/>
    <id>https://xv44586.github.io/2020/05/05/make-a-computer/</id>
    <published>2020-05-05T01:20:56.000Z</published>
    <updated>2020-05-05T05:05:15.577Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><div class="toc"><!-- toc --><ul><li><a href="#ying-jian-pian">硬件篇</a><ul><li><a href="#xian-qia">显卡</a></li><li><a href="#cpu">CPU</a></li><li><a href="#zhu-ban">主板</a></li><li><a href="#san-re">散热</a></li><li><a href="#cun-chu">存储</a></li><li><a href="#dian-yuan-yu-ji-xiang">电源与机箱</a></li></ul></li><li><a href="#an-zhuang">安装</a></li><li><a href="#ruan-jian-an-zhuang">软件安装</a><ul><li><a href="#xi-tong-an-zhuang">系统安装</a></li><li><a href="#an-zhuang-nvidia-qu-dong">安装Nvidia驱动</a></li><li><a href="#cuda-de-an-zhuang-yu-xie-zai">CUDA的安装与卸载</a><ul><li><a href="#xie-zai-cuda">卸载cuda</a></li><li><a href="#an-zhuang-cuda">安装cuda</a></li></ul></li><li><a href="#an-zhuang-cudnn">安装cudnn</a></li><li><a href="#python-huan-jing">Python环境</a><ul><li><a href="#conda-pei-zhi">conda配置</a></li><li><a href="#an-zhuang-jupyter">安装jupyter</a></li></ul></li><li><a href="#an-zhuang-tensorflow-gpu">安装tensorflow-gpu</a></li></ul></li><li><a href="#zong-jie">总结</a></li><li><a href="#guan-yu-tou-tu">关于头图</a></li></ul><!-- tocstop --></div><p>  今年回来，第一件事就是要打造一个自己的实验环境，而这也是我第一次自己从硬件开始，所以前前后后差不多折腾了大半个月，总算是搞定了。为了纪念这次从0开始打造自己的深度学习实验环境，所以写了这篇指北。</p><h1><span id="ying-jian-pian">硬件篇</span><a href="#ying-jian-pian" class="header-anchor"></a></h1><p>  关于硬件，最主要的就是显卡、CPU、主板和散热了，接下来一个一个介绍经验。</p><h2><span id="xian-qia">显卡</span><a href="#xian-qia" class="header-anchor"></a></h2><p>  显卡的选择主要参考两个维度：1.显存大小；2.浮点计算能力。<br>  显卡主要分AMD与Nvidia系列。因为Nvidia有CUDA加持，加速计算，自然是Nvidia系列了，Nvidia显卡目前针对PC有三个系列：Quadro、GeForce和Tesla。其中Quadro系列是专业绘图，GeoForce是专业游戏显卡（可绘图可计算），而Tesla是专业计算卡。综合考虑价格与 state-of-the-art 的模型对硬件的最低要求，最终选择了2080Ti。关于GPU的选型，可以参考<a href="https://zhuanlan.zhihu.com/p/61411536" target="_blank" rel="noopener">深度学习GPU对比</a><br>  确定了型号，就是出品厂家选择了，主要区别就是公版非公版。公版就是Nvidia自己设计自己出的，而非公就是第三方厂商出的，包括evga，技嘉，微星等等。有一篇2080ti进行深度学习时的显卡性能测评的文章，找不到地址了，结论是evga &gt; Nvidia &gt; others 。evga与Nvidia的主要区别有两个：1.价格上evga略高 10% 左右；2. Nvidia 采用双风扇风冷，evga 采用单风扇风冷-水冷混合。最终选择了公版。</p><h2><span id="cpu">CPU</span><a href="#cpu" class="header-anchor"></a></h2><p>  CPU主要有两个系列：Intel 和 AMD 。也是因为主要用来做计算，所以肯定首选 AMD。目前ADM系列顶配是 3990X，但是价格大概在三万左右，太感人了。第二的是 3700X ，京东上一千三上下，那就是他了。</p><h2><span id="zhu-ban">主板</span><a href="#zhu-ban" class="header-anchor"></a></h2><p>  CPU确定了，主板型号基本就定了。 主要参考如下图：<br>  <img src="/2020/05/05/make-a-computer/board.png" alt="cpu-主板对应型号参考"><br>  看了一些测评，最终选择了微星<a href="https://item.jd.com/8259910.html" target="_blank" rel="noopener">B450</a></p><h2><span id="san-re">散热</span><a href="#san-re" class="header-anchor"></a></h2><p>  散热目前两个方式：风冷和水冷。两者的区别主要参考<a href="https://www.zhihu.com/question/57695465/answer/440467918" target="_blank" rel="noopener">风冷与水冷区别</a><br>  水冷在散热上还是要强一些的（240以上），所以打算试水一款水冷。主要推荐两款：<a href="https://item.m.jd.com/product/100003859323.html?wxa_abtest=o&amp;utm_user=plusmember&amp;ad_od=share&amp;utm_source=androidapp&amp;utm_medium=appshare&amp;utm_campaign=t_335139774&amp;utm_term=Wxfriends&amp;from=singlemessage&amp;isappinstalled=0" target="_blank" rel="noopener">乔思伯光影240</a> <a href="https://item.m.jd.com/product/6454809.html?wxa_abtest=o&amp;utm_user=plusmember&amp;ad_od=share&amp;utm_source=androidapp&amp;utm_medium=appshare&amp;utm_campaign=t_335139774&amp;utm_term=Wxfriends&amp;from=singlemessage&amp;isappinstalled=0" target="_blank" rel="noopener">九州风神水元素240T</a>。最后选择了九州风神水元素，因为买那天乔思伯涨价了～</p><h2><span id="cun-chu">存储</span><a href="#cun-chu" class="header-anchor"></a></h2><p>  存储上打算采用 32G + 1T ssd。内存自然上<a href="https://item.jd.com/8391349.html" target="_blank" rel="noopener">金士顿骇客神条</a>, ssd主要参考性价比，最终选择<a href="https://item.jd.com/100002580230.html" target="_blank" rel="noopener">三星1T SSD</a></p><h2><span id="dian-yuan-yu-ji-xiang">电源与机箱</span><a href="#dian-yuan-yu-ji-xiang" class="header-anchor"></a></h2><p>  由于目前暂时只插一张显卡，所以电源在 600W 以上即可。选一个品牌比较好的，那就是<a href="https://item.jd.com/6828141.html" target="_blank" rel="noopener">安钛克750</a> 了<br>  至于机箱，主要参考能不能够合理安放显卡、主板以及后续可能的散热。对于我当前的配置，只要是中塔的基本都够插显卡。买个安静低调的，那就他了：<a href="https://item.jd.com/100004999668.html" target="_blank" rel="noopener">爱国者M2</a><br>  最终的配置清单如下：<br>  <img src="/2020/05/05/make-a-computer/list.png" alt="list"></p><h1><span id="an-zhuang">安装</span><a href="#an-zhuang" class="header-anchor"></a></h1><p>  安装前，强烈建议多看几期安装教程视频，我主要看的是 B站 的<a href="https://www.bilibili.com/video/BV1vx41187cm" target="_blank" rel="noopener">跟装机猿搞装机</a> 系列。最困难的可能是水冷散热的安装了。由于平台不同，安装方式不同，推荐看对应水冷厂商给的安装视频。我主要参考<a href="https://www.bilibili.com/video/BV1EE411h7R1" target="_blank" rel="noopener">水元素安装教程</a><br>  安装过程大致总结一下：</p><ol><li>拿出主板和CPU，按照说明书将CPU装到主板上。</li><li>将水冷拿出，拿出硅脂，涂抹在CPU上，将冷头上的塑料膜撕掉，安装好支撑后，将水冷头贴在CPU上，安装固定。</li><li>拆开机箱侧板，将主板装上，并将水冷的风扇固定在机箱上。注意：风扇上没有挡板的是出风口，一般原则是从机箱内往外吹，注意风向。</li><li>插入内存条，固定固态硬盘</li><li>将线按说明一个一个插上</li><li>寻找机箱上显卡位置，可能需要扣掉挡板铁片。将显卡插入主板，同时固定在机箱上</li><li>放入电源，插好对应线<br>主要注意的主要是：1、水冷头上的膜一定要撕去，否则CPU上的热不能很好的传导出来。2、装之前大概看一下机箱各个位置，有些时候因为安装顺序会导致没地方下手，需要卸了重组。</li></ol><h1><span id="ruan-jian-an-zhuang">软件安装</span><a href="#ruan-jian-an-zhuang" class="header-anchor"></a></h1><h2><span id="xi-tong-an-zhuang">系统安装</span><a href="#xi-tong-an-zhuang" class="header-anchor"></a></h2><p>  系统选Linux的稳定版，所以装了CentOS 7。<br>  1.首先下载centos的镜像文件，外网可能会慢，选择<a href="http://mirrors.aliyun.com/centos/7/isos/x86_64/" target="_blank" rel="noopener">阿里源</a><br>  2.下载相应的刻录工具，插入u盘，将镜像刻录进u盘（刻录时会先格式化u盘，如果是windows系统，u盘默认是FAT32,这种格式下是没法放大于4G的单文件，所以需要进行格式转换：cmd下执行 convert e: /fs:ntfs)<br>  3.插入u盘，开机，引导开机进入u盘（大部分是自动进来），选择 test &amp; install<br>  4.一般安装时，对应的命令行中的目录是错误的，执行会报错：<br>  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ERROR，could not insert <span class="string">'floppy'</span></span><br></pre></td></tr></table></figure></p><p>  而无法进入安装界面<br>  此时需要查找u盘对应名字，修改命令：<br>  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span>:/dev &amp; ls</span><br></pre></td></tr></table></figure></p><p>  找到一个 <code>s##数字 </code>的串，我的是sdb4 ,然后重启，进入后先按 e 进入编辑模式，修改命令行<br>  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">linuxefi/images/pxeboot/vmlinuz inst.stage2=hd:LABEL=CentOS\x207\x20x86_64 xdriver=vesa nomodeset quiet</span><br><span class="line">linuxefi/images/pxeboot/vmlinuz inst.stage2=hd:/dev/sdb4 xdriver=vesa nomodeset quiet</span><br></pre></td></tr></table></figure></p><p>  由于我的显卡是2080Ti,系统自带的nouveau驱动不匹配，需要禁用暂时，所以在后面加上 <code> nouveau.modeset=0 </code><br>  最终修改后完整的命令行为：<br>  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">linuxefi/images/pxeboot/vmlinuz inst.stage2=hd:/dev/sdb4 xdriver=vesa nomodeset quiet nouveau.modeset=0</span><br></pre></td></tr></table></figure></p><p>  此时保存后退出，选择test &amp; install 即可进入安装界面<br>  进入后安装，安装时，注意软件选择中选择带网络的，剩下的就是按提示一步一步来即可。</p><h2><span id="an-zhuang-nvidia-qu-dong">安装Nvidia驱动</span><a href="#an-zhuang-nvidia-qu-dong" class="header-anchor"></a></h2><p>  1.检查显卡是否正常<br>  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ lspci | grep -i nvidia</span><br></pre></td></tr></table></figure></p><p>  2.检查驱动版本<br>  添加EIRepo源<br>  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ rpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org</span><br><span class="line">$ rpm -Uvh http://www.elrepo.org/elrepo-release-7.6-5.el7.elrepo.noarch.rpm</span><br><span class="line">``` </span><br><span class="line"></span><br><span class="line">3.安装显卡驱动检查包</span><br><span class="line">```bash</span><br><span class="line">$ yum install nvidia-detect</span><br></pre></td></tr></table></figure></p><p>  检查驱动版本<br>  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ nvidia-detect -v</span><br></pre></td></tr></table></figure></p><p>  此时会得到对应的版本信息，注意那个数字<br>  4.安装编译环境<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ yum install kernel-devel-$(uname -r) kernel-headers-$(uname -r) dkms</span><br><span class="line">$ yum -y update //注意这是升级系统</span><br><span class="line">$ yum -y install gcc kernel-devel kernel-headers dkms</span><br></pre></td></tr></table></figure></p><p>  5.禁用vouveau<br>  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ vim /etc/modprobe.d/blacklist-nouveau.conf</span><br><span class="line">    blacklist nouveau</span><br><span class="line">    options nouveau modeset=0</span><br></pre></td></tr></table></figure></p><p>  6.重新建立initramfs image文件<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ mv /boot/initramfs-$(uname -r).img /boot/initramfs-$(uname -r).img.bak</span><br><span class="line">$ dracut /boot/initramfs-$(uname -r).img $(uname -r)</span><br></pre></td></tr></table></figure></p><p>  7.reboot</p><h2><span id="cuda-de-an-zhuang-yu-xie-zai">CUDA的安装与卸载</span><a href="#cuda-de-an-zhuang-yu-xie-zai" class="header-anchor"></a></h2><h3><span id="xie-zai-cuda">卸载cuda</span><a href="#xie-zai-cuda" class="header-anchor"></a></h3>  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo yum remove <span class="string">"*cublas*"</span> <span class="string">"cuda*"</span></span><br></pre></td></tr></table></figure><p>参考：<a href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#removing-cuda-tk-and-driver" target="_blank" rel="noopener">removing-cuda</a></p><h3><span id="an-zhuang-cuda">安装cuda</span><a href="#an-zhuang-cuda" class="header-anchor"></a></h3>  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">wget path/to/your-version/install.rpm</span><br><span class="line">sudo rpm -i cuda-repo-rhel7-10-1-local-10.1.105-418.39-1.0-1.x86_64.rpm</span><br><span class="line">sudo yum clean all</span><br><span class="line">sudo yum install cuda</span><br></pre></td></tr></table></figure><p>参考：<a href="https://developer.nvidia.com/cuda-10.1-download-archive-base?target_os=Linux&amp;target_arch=x86_64&amp;target_distro=CentOS&amp;target_version=7&amp;target_type=rpmlocal" target="_blank" rel="noopener">cuda-download</a><br>注意：一定不要通过浏览器去下载，因为会非常非常非常慢，但是wget大概几分钟就搞定了</p><h2><span id="an-zhuang-cudnn">安装cudnn</span><a href="#an-zhuang-cudnn" class="header-anchor"></a></h2><p>  1.下载相应的包 libcudnn*.rpm</p><ol start="2"><li><p>安装包</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">rpm -ivh libcudnn7-*.x86_64.rpm</span><br><span class="line">rpm -ivh libcudnn7-devel-*.x86_64.rpm</span><br><span class="line">rpm -ivh libcudnn7-doc-*.x86_64.rpm</span><br></pre></td></tr></table></figure><p>3.验证</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span>  <span class="variable">$HOME</span>/cudnn_samples_v7/mnistCUDNN</span><br><span class="line"><span class="variable">$make</span> clean &amp;&amp; make</span><br><span class="line">$ ./mnistCUDNN</span><br></pre></td></tr></table></figure><p>if: Test passed! 则验证通过<br>参考：<a href="https://docs.nvidia.com/deeplearning/sdk/cudnn-install/index.html#install-linux" target="_blank" rel="noopener">cudnn-install</a></p><h2><span id="python-huan-jing">Python环境</span><a href="#python-huan-jing" class="header-anchor"></a></h2><p>python环境采用Anaconda + jupyter notebook</p><h3><span id="conda-pei-zhi">conda配置</span><a href="#conda-pei-zhi" class="header-anchor"></a></h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">conda create -n py3 python=3</span><br><span class="line">activate py3</span><br><span class="line">conda install ipykernel -n py3</span><br><span class="line">python -m ipykernel install --user --name py3 --display-name <span class="string">'py3'</span></span><br></pre></td></tr></table></figure><p>删除环境</p><figure class="highlight bash"><figcaption><span>jupyter kernelspec remove py3 ```</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">  pip 安装 与修改源</span><br><span class="line">```bash </span><br><span class="line">  conda install pip -n py3</span><br><span class="line">  vim ~/.pip/pip.conf</span><br><span class="line"></span><br><span class="line">  [global]</span><br><span class="line">  index-url=https://pypi.tuna.tsinghua.edu.cn/simple</span><br></pre></td></tr></table></figure><h3><span id="an-zhuang-jupyter">安装jupyter</span><a href="#an-zhuang-jupyter" class="header-anchor"></a></h3><figure class="highlight bash"><figcaption><span>pip install jupyter```</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">  jupyter 作为后台服务器</span><br><span class="line">  1. 添加密码</span><br><span class="line">```bash </span><br><span class="line">  ipython</span><br><span class="line">  from jupyter.auth import passwd</span><br><span class="line">  passwd()</span><br></pre></td></tr></table></figure><p>此时会让你输入两次密码，输入后得到一串hash码，保存下来， 回到bash, 添加配置文件</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">$ jupyter notebook --generate-config</span><br><span class="line">$ vim ~/.jupyter/jupyter-notebook-config.py</span><br><span class="line"></span><br><span class="line"><span class="comment"># edit</span></span><br><span class="line"></span><br><span class="line">c.NotebookApp.ip=<span class="string">'*'</span>                                  <span class="comment"># * 代表所有iP都能访问 ，也可以指定ip</span></span><br><span class="line">c.NotebookApp.password = u<span class="string">'sha1:ce...'</span>       <span class="comment"># 刚才复制的那个密文</span></span><br><span class="line">c.NotebookApp.open_browser = False       <span class="comment"># 禁止自动打开浏览器</span></span><br><span class="line">c.NotebookApp.port =8888                         <span class="comment">#指定一个端口</span></span><br><span class="line">   </span><br><span class="line">c.NotebookApp.notebook_dir = <span class="string">'/home/user/user1'</span>  <span class="comment">#指定工作空间</span></span><br><span class="line">c.PAMAuthenticator.encoding = <span class="string">'utf8'</span>         <span class="comment">#指定utf-8编码，解决读取中文路径或者文件乱码问题</span></span><br></pre></td></tr></table></figure><p>后台运行</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ nohup jupyter notebook --allow-root &gt; jupyter.log 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure></li></ol><p>  关闭后台运行<br>  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"> <span class="comment"># ps -axu | grep jupyter</span></span><br><span class="line"><span class="comment"># kill -9 pid</span></span><br></pre></td></tr></table></figure></p><h2><span id="an-zhuang-tensorflow-gpu">安装tensorflow-gpu</span><a href="#an-zhuang-tensorflow-gpu" class="header-anchor"></a></h2><p>  tensorflow-gpu对cuda有版本要求，所以在安装cuda前需要提前查看，确定自己版本。参考官网<a href="https://www.tensorflow.org/install/source" target="_blank" rel="noopener">install</a><br>  <img src="/2020/05/05/make-a-computer/gpu.png" alt="tensorflow-gpu vs cuda"><br>  还记得cuda安装时，给出的卸载方法吗？就是因为装tensorflow-gpu后发现gpu不带动的，后来才发现是cuda版本太高了～<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ pip install tensorflow-gpu==2.1</span><br></pre></td></tr></table></figure></p><p>  验证<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ ipython</span><br><span class="line">  import tensorflow as tf</span><br><span class="line">  tf.config.list_physical_devices(<span class="string">'GPU'</span>)</span><br></pre></td></tr></table></figure></p><p>  没有报错则正常</p><h1><span id="zong-jie">总结</span><a href="#zong-jie" class="header-anchor"></a></h1><p>  以上就是从零开始搭建搭建一套自己的深度学习实验平台的个人经验，整个过程从硬件到最终的软件适配都走了很多坑，希望能给你一些借鉴。</p><h1><span id="guan-yu-tou-tu">关于头图</span><a href="#guan-yu-tou-tu" class="header-anchor"></a></h1><p>  部分硬件盒子</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;/assets/css/APlayer.min.css&quot;&gt;&lt;script src=&quot;/assets/js/APlayer.min.js&quot; cla
      
    
    </summary>
    
    
      <category term="Life" scheme="https://xv44586.github.io/categories/Life/"/>
    
    
      <category term="tensorflow-gpu" scheme="https://xv44586.github.io/tags/tensorflow-gpu/"/>
    
      <category term="装机" scheme="https://xv44586.github.io/tags/%E8%A3%85%E6%9C%BA/"/>
    
      <category term="CUDA" scheme="https://xv44586.github.io/tags/CUDA/"/>
    
  </entry>
  
  <entry>
    <title>记一次npm环境问题</title>
    <link href="https://xv44586.github.io/2020/01/11/npm-environment/"/>
    <id>https://xv44586.github.io/2020/01/11/npm-environment/</id>
    <published>2020-01-11T04:31:20.000Z</published>
    <updated>2020-01-11T06:37:47.709Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><div class="toc"><!-- toc --><ul><li><a href="#qi-yin">起因</a></li><li><a href="#ddbug">Ddbug</a></li><li><a href="#jie-lun">结论</a></li><li><a href="#guan-yu-tou">关于头</a></li></ul><!-- tocstop --></div><h1><span id="qi-yin">起因</span><a href="#qi-yin" class="header-anchor"></a></h1><p>上周写完博客，本地预览时，突然报错，看了一下是 sharp.js 的问题，以为是个小场面，然后就开始了一周的痛苦修环境经历，哭了😭</p><h1><span id="ddbug">Ddbug</span><a href="#ddbug" class="header-anchor"></a></h1><ol><li>首先根据提示，重新安装  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">rm -rf node_modules/sharp</span><br><span class="line">npm i sharp</span><br></pre></td></tr></table></figure></li></ol><p>此时报错：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">c++: error: unrecognized command line option <span class="string">'-stdlib=libc++'</span></span><br><span class="line">make: *** [Release/.node] Error <span class="number">1</span></span><br><span class="line">gyp ERR! build error</span><br><span class="line">gyp ERR! stack Error: `make` failed <span class="keyword">with</span> exit code: <span class="number">2</span></span><br><span class="line">gyp ERR! stack     at ChildProcess.onExit (/usr/local/Cellar/node@<span class="number">8</span>/<span class="number">8.16</span><span class="number">.2</span>/lib/node_modules/npm/node_modules/node-gyp/lib/build.js:<span class="number">262</span>:<span class="number">23</span>)</span><br><span class="line">gyp ERR! stack     at emitTwo (events.js:<span class="number">126</span>:<span class="number">13</span>)</span><br><span class="line">gyp ERR! stack     at ChildProcess.emit (events.js:<span class="number">214</span>:<span class="number">7</span>)</span><br><span class="line">gyp ERR! stack     at Process.ChildProcess._handle.onexit (internal/child_process.js:<span class="number">198</span>:<span class="number">12</span>)</span><br></pre></td></tr></table></figure></p><p>这个问题的本质是当前的包需要通过源码编译，而当前用的是gcc（macOS），而gcc不支持当前命令，之前装环境没有遇到过这个问题，可能是我最近跟新了gcc？<br>查了一下解决这个问题最简单的方式是指定c++:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CXX=clang++ npm i xxx</span><br></pre></td></tr></table></figure></p><p>这次确实装成功了，走起！<br>此时又报新错：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">can <span class="keyword">not</span> find sharp xxx</span><br><span class="line">rm node_modules/sharp <span class="keyword">and</span> rebuild</span><br></pre></td></tr></table></figure></p><p>阿嘞？装上了又找不到？why？<br>又尝试了全局安装，依然找不到，此时，有点上头，我干脆把node_modules全部删掉，重新装吧。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">rm -rf node_modules</span><br><span class="line">CXX=clang++ npm i</span><br></pre></td></tr></table></figure></p><p>阿嘞？这次装也失败了，错误大致原因是node-gyp rebuild nodejieba失败。<br>开始以为是node-gyp的问题，后来查了一下，node-gyp是用来帮助丛源码编译的工具，所以本质上不是他的问题，还是别的问题。<br>又查了一下nodejieba, 有人说是在lunr.js中用的nodejieba在node高版本中会存在编译失败，建议用 node8.x ,python版本最好是2.7，那我上次没失败？先将node降级到node8, python切到2.7。<br>再装一次，依然失败。但是错误信息不够定位，查一下怎么看更全的日志。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">CXX=clang++ npm i --verbose</span><br><span class="line">```  </span><br><span class="line">发现两条重要信息，大概是无法找到lib下某个库，可能是本级的环境出了问题，整理一下吧。</span><br><span class="line"> ```python</span><br><span class="line">brew update</span><br><span class="line">brew cleanup</span><br><span class="line">brew doctor</span><br><span class="line">```  </span><br><span class="line">环境的一堆issue解决掉（主要是link无效），然后把之前无法找到的两个lib重新装了一次（很慢）。</span><br><span class="line">此时还是同样问题，这次又查看了一下当前环境问题，两个包没link，一个是python(其实是python3，之前link的python2)， 一个是swig，后来一想，可能是swig这个工具在源码编译是缺失导致的，</span><br><span class="line">```python</span><br><span class="line">brew link swig</span><br></pre></td></tr></table></figure></p><p>此时在装，搞定！走起，又报新错：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">FATAL Something<span class="string">'s wrong. Maybe you can find the solution here: https://hexo.io/docs/troubleshooting.html</span></span><br><span class="line"><span class="string">Error: spawn /Users/xuming/Project/blog/node_modules/optipng-bin/vendor/optipng ENOENT</span></span><br><span class="line"><span class="string">    at Process.ChildProcess._handle.onexit (internal/child_process.js:190:19)</span></span><br><span class="line"><span class="string">    at onErrorNT (internal/child_process.js:362:16)</span></span><br><span class="line"><span class="string">    at _combinedTickCallback (internal/process/next_tick.js:139:11)</span></span><br><span class="line"><span class="string">    at process._tickCallback (internal/process/next_tick.js:181:9)</span></span><br></pre></td></tr></table></figure></p><p>这是缺module，但是我是npm i，为什么还缺？此时可能只是当前node_modules的问题，为了验证本机其他环境已经ok了，新建了一个博客，验证后发现本机确实OK了。<br>额，那就缺什么装什么吧。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm i optipng-bin</span><br></pre></td></tr></table></figure></p><p>走起！一切正常！此时我的心情就好比火箭发射成功一样。折磨了一周的环境问题，终于搞定了，中间还有许多其他方向的试探，但都记不得了。- -！</p><h1><span id="jie-lun">结论</span><a href="#jie-lun" class="header-anchor"></a></h1><ol><li>npm 失败后，可以加 –verbose 参数查看详细日志，定位问题。</li><li>编译源码可能你还需要装xcode-select --install</li><li>对于 Error: spawn .../node_modules/xxx/vendor/.. ENOENT,单独安装一下对应缺失module即可。</li><li>node-gyp 和 libvips可能也会影响，建议重装一次</li><li>MacOS中，可能会gcc与clang并存，加上系统升级，可能导致相应版本不兼容问题。指定clang ：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CXX=clang++ npm i</span><br></pre></td></tr></table></figure>6. 本机环境问题，可以通过<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">brew doctor</span><br></pre></td></tr></table></figure></li></ol><h1><span id="guan-yu-tou">关于头</span><a href="#guan-yu-tou" class="header-anchor"></a></h1><p>雪中奥森</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;/assets/css/APlayer.min.css&quot;&gt;&lt;script src=&quot;/assets/js/APlayer.min.js&quot; cla
      
    
    </summary>
    
    
      <category term="Life" scheme="https://xv44586.github.io/categories/Life/"/>
    
    
      <category term="npm" scheme="https://xv44586.github.io/tags/npm/"/>
    
  </entry>
  
  <entry>
    <title>Backup</title>
    <link href="https://xv44586.github.io/2019/12/27/backup/"/>
    <id>https://xv44586.github.io/2019/12/27/backup/</id>
    <published>2019-12-27T14:24:21.000Z</published>
    <updated>2020-01-11T06:42:03.393Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><div class="toc"><!-- toc --><ul><li><a href="#pei-zhi">配置</a><ul><li><a href="#cha-jian">插件</a></li></ul></li><li><a href="#zhu-ti">主题</a></li><li><a href="#markdown">MarkDown</a><ul><li><a href="#bu-ju">布局</a></li></ul></li><li><a href="#guan-yu-tou-tu">关于头图</a></li></ul><!-- tocstop --></div><h1><span id> </span><a href="#" class="header-anchor"></a></h1><p><strong>Just for me！<br>现在使用的博客虽然使用的是开源的，但是自己做了部分修改，加上一些常用语法一段时间不用后又需要重新查，所以在此记录一下当前博客常用的。 </strong> </p><h1><span id="pei-zhi">配置</span><a href="#pei-zhi" class="header-anchor"></a></h1><p>Hexo 部署文档： <a href="http://hexo.io/docs/deployment.html" target="_blank" rel="noopener">http://hexo.io/docs/deployment.html</a><br>Hexo _config.xml 的配置 <a href="https://gist.github.com/btfak/18938572f5df000ebe06fbd1872e4e39" target="_blank" rel="noopener">https://gist.github.com/btfak/18938572f5df000ebe06fbd1872e4e39</a></p><h2><span id="cha-jian">插件</span><a href="#cha-jian" class="header-anchor"></a></h2><ul><li>hexo-toc  <a href="https://github.com/bubkoo/hexo-toc" target="_blank" rel="noopener">Insert a markdown TOC before posts be rendered</a><br>用来生产目录</li><li>hexo-renderer-marked + MathJax<br>整体顺序是先由renderer渲染，然后交给MathJax渲染Math相关，前者在遇见$ $后将escape _ 导致下标失效（_在renderer中认为是黑体，<br>所以产生这种冲突），所以修改了部分escape</li></ul><h1><span id="zhu-ti">主题</span><a href="#zhu-ti" class="header-anchor"></a></h1><ul><li>hexo-theme-skapp <a href="https://github.com/Mrminfive/hexo-theme-skapp" target="_blank" rel="noopener">https://github.com/Mrminfive/hexo-theme-skapp</a><ul><li>主要修改：</li></ul><ol><li>部分页面布局，包括footer和header</li><li>字体样式，包括部分元素样式，如<strong>code</strong></li></ol></li></ul><h1><span id="markdown">MarkDown</span><a href="#markdown" class="header-anchor"></a></h1><h2><span id="bu-ju">布局</span><a href="#bu-ju" class="header-anchor"></a></h2><ul><li><p>添加大纲<br>在正文最开始添加 </p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;!-- toc --&gt;</span><br></pre></td></tr></table></figure></li><li><p>标题<br><code> # </code> ~ <code>######</code>，<code>#</code>号的个数表示几级标题，即表示一级标题到六级标题</p></li><li><p>有序列表</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">1. **我是一级序列** </span><br><span class="line">2. **我是一级序列** </span><br><span class="line">3. **我是一级序列** </span><br><span class="line"> 1. *我是二级序列* </span><br><span class="line"> 1. *我是二级序列* </span><br><span class="line">  1. *我是二级序列*</span><br></pre></td></tr></table></figure></li></ul>  <blockquote><ol><li><strong>我是一级序列</strong> </li><li><strong>我是一级序列</strong> </li><li><strong>我是一级序列</strong> <ol><li><em>我是二级序列</em> </li><li><em>我是二级序列</em> </li><li><em>我是二级序列</em> </li></ol></li></ol></blockquote><ul><li>无序列表</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">* *列表展示  </span><br><span class="line"> * *列表展示</span><br><span class="line">  * *列表展示</span><br><span class="line">+ +列表展示</span><br><span class="line"> + +列表展示</span><br><span class="line">  + +列表展示</span><br><span class="line">- -列表展示</span><br><span class="line"> - -列表展示</span><br><span class="line">  - -列表展示</span><br></pre></td></tr></table></figure>  <blockquote><ul><li>*列表展示<ul><li>*列表展示<ul><li>*列表展示</li></ul><ul><li>+列表展示</li></ul></li></ul><ul><li>+列表展示<ul><li>+列表展示</li></ul><ul><li>-列表展示</li></ul></li></ul><ul><li>-列表展示<ul><li>-列表展示</li></ul></li></ul></li></ul></blockquote><ul><li>表格</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&amp;nbsp; | l1     | l2     </span><br><span class="line">  ----- | --- | ---- </span><br><span class="line">    w0 | $e_&#123;<span class="number">01</span>&#125;$ | $e_&#123;<span class="number">02</span>&#125;$ </span><br><span class="line">    w1 | $e_&#123;<span class="number">11</span>&#125;$ | $e_&#123;<span class="number">12</span>&#125;$ </span><br><span class="line">    w2 | $e_&#123;<span class="number">21</span>&#125;$ | $e_&#123;<span class="number">22</span>&#125;$</span><br></pre></td></tr></table></figure><p>表头与正文用–来分割，列之间用|来分割。注：列名不能使用空格，如需要列名为空，需要使用 &amp;nbsp；替换</p>  <blockquote><table><thead><tr><th>&nbsp;</th><th>l1</th><th>l2     </th></tr></thead><tbody><tr><td>  w0</td><td>$e_{01}$</td><td>$e_{02}$ </td></tr><tr><td>  w1</td><td>$e_{11}$</td><td>$e_{12}$ </td></tr><tr><td>  w2</td><td>$e_{21}$</td><td>$e_{22}$ </td></tr></tbody></table></blockquote><ul><li><p>强调</p> **加粗** __加粗__ _斜体_  ***加粗并斜体*** ~~删除线～~ <blockquote><p><strong>加粗</strong> <strong>加粗</strong> _斜体_  <strong><em>加粗并斜体</em></strong> ~~删除线～~</p></blockquote></li><li><p>高亮</p></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">用&lt;code&gt; content &lt;/code&gt; 来包裹想要高亮的元素</span><br></pre></td></tr></table></figure>  <blockquote><p>用<code> content </code> 来包裹想要高亮的元素</p></blockquote><ul><li><p>关闭MarkDown</p><blockquote><p>{% raw %} content {% endraw %}</p><p>这种方式将会忽略空格回车等，有些场景也会失效，此时可以用 <strong>代码块</strong> 代替</p></blockquote></li><li><p>引用</p><blockquote><p>{% blockquote 江泽民%}科技是第一生产力 {% endblockquote %} </p></blockquote><blockquote><p>科技是第一生产力</p><footer><strong>江泽民</strong></footer></blockquote></li><li><p>Math</p><blockquote><p>行内公式用 $包裹，多行时用$$包裹<br>使用的是MathJax，语法可参考博客<a href="https://blog.csdn.net/ethmery/article/details/50670297" target="_blank" rel="noopener">MathJax基本语法</a> 和官方文档(<a href="https://math.meta.stackexchange.com/questions/5020/mathjax-basic-tutorial-and-quick-reference" target="_blank" rel="noopener">https://math.meta.stackexchange.com/questions/5020/mathjax-basic-tutorial-and-quick-reference</a>)<br><code>调试参考<a href="https://www.quicklatex.com/" target="_blank" rel="noopener">quicklatex</a></code></p></blockquote></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$</span><br><span class="line"> states = $$\begin&#123;pmatrix&#125;</span><br><span class="line"> e_&#123;<span class="number">01</span>&#125;&amp;e_&#123;<span class="number">01</span>&#125;\\\\</span><br><span class="line"> e_&#123;<span class="number">02</span>&#125;&amp;e_&#123;<span class="number">02</span>&#125;\\\\</span><br><span class="line"> \end&#123;pmatrix&#125;$$</span><br><span class="line">$</span><br></pre></td></tr></table></figure>  <blockquote><p>$<br>states = $$\begin{pmatrix}<br>e_{01}&amp;e_{01}\\<br>e_{02}&amp;e_{02}\\<br>\end{pmatrix}$$<br>$</p><p><strong>注：公式内\ 会被转义，需要用双\，尤其在矩阵中。</strong></p></blockquote><ul><li>代码<blockquote><p>使用三个<code>`</code>包裹，如果需要显示三个 <code>`</code>， 可以用四个。也可以用  {%codeblock%}</p></blockquote></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">```</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">do</span><span class="params">(self, job_func, *args, **kwargs)</span>:</span></span><br><span class="line">        print(<span class="string">'hello world'</span>)  </span><br><span class="line">  ```</span><br></pre></td></tr></table></figure>   <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">do</span><span class="params">(self, job_func, *args, **kwargs)</span>:</span></span><br><span class="line">   print(<span class="string">'hello world'</span>)  </span><br><span class="line">   </span><br></pre></td></tr></table></figure><p>$$log(Z_{(0-&gt;1-&gt;2)}) = log(exp(states[0]) + exp(states[1])) \\<br>=log((exp(e_{01}+e_{11}+t_{11}) + exp(e_{02}+e_{11}+t_{21}))exp(e_{21} + t_{11}) + (exp(e_{01}+e_{12}+t_{12}) + exp(e_{02}+e_{12}+t_{22}))exp(e_{21}+t_{21})) \\+<br>log((exp(e_{01}+e_{11}+t_{11}) + exp(e_{02}+e_{11}+t_{21}))exp(e_{22} + t_{12}) + (exp(e_{01}+e_{12}+t_{12}) + exp(e_{02}+e_{12}+t_{22}))exp(e_{22}+t_{22})) \\<br>= log(exp(e_{01}+e_{11}+t_{11}+e_{21}+t_{11}) + exp(e_{02}+e_{11}+t_{21}+e_{21}+t_{11}) \\ +<br>exp(e_{01}+e_{12}+t_{12} +e_{21}+t_{21}) + exp(e_{02}+e_{12}+t_{22}+e_{21}+t_{21}) \\+<br>exp(e_{01}+e_{11}+t_{11} +e_{22}+t_{12}) + exp(e_{01}+e_{11}+t_{11}+e_{22}+t_{12}) \\+<br>exp(e_{01}+e_{12}+t_{12} +e_{22}+t_{22}) + exp(e_{01}+e_{12}+t_{12}+e_{22}+t_{21}))$$</p><h1><span id="guan-yu-tou-tu">关于头图</span><a href="#guan-yu-tou-tu" class="header-anchor"></a></h1><p> 望京SOHO夜景</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;/assets/css/APlayer.min.css&quot;&gt;&lt;script src=&quot;/assets/js/APlayer.min.js&quot; cla
      
    
    </summary>
    
    
      <category term="Life" scheme="https://xv44586.github.io/categories/Life/"/>
    
    
      <category term="Hexo" scheme="https://xv44586.github.io/tags/Hexo/"/>
    
      <category term="MarkDown" scheme="https://xv44586.github.io/tags/MarkDown/"/>
    
  </entry>
  
  <entry>
    <title>from softmax to crf</title>
    <link href="https://xv44586.github.io/2019/12/26/from-softmax-to-crf/"/>
    <id>https://xv44586.github.io/2019/12/26/from-softmax-to-crf/</id>
    <published>2019-12-26T12:45:56.000Z</published>
    <updated>2020-10-25T02:55:33.052Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><div class="toc"><!-- toc --><ul><li><a href="#xu-lie-biao-zhu">序列标注</a><ul><li><a href="#mo-xing">模型</a></li><li><a href="#shu-xue-xing-shi">数学形式</a></li></ul></li><li><a href="#yan-shi-jian-zhou-softmax">沿时间轴Softmax</a></li><li><a href="#crf">CRF</a></li><li><a href="#xian-xing-lian-crf">线性链CRF</a></li><li><a href="#qiu-jie">求解</a></li><li><a href="#demo">demo</a></li><li><a href="#guan-yu-tou-tu">关于头图</a></li></ul><!-- tocstop --></div><p>又做NER相关东西， 用到了CRF，所以想给组里人从头一步一步的将CRF讲一遍，希望大家看完能明白CRF的数学模型已经工程上的使用。<br>网上关于CRF大多数都是将他与HMM及概率图模型一起对比着讲，但是我觉得这需要一些背景知识，鉴于上次分享发现大家并没有什么背景知识，<br>所以这次希望能尽量减少背景知识就能让人搞懂CRF。</p><h1><span id="xu-lie-biao-zhu">序列标注</span><a href="#xu-lie-biao-zhu" class="header-anchor"></a></h1><h2><span id="mo-xing">模型</span><a href="#mo-xing" class="header-anchor"></a></h2><p>通常CRF出现在序列标注任务中，所以我们先来看看序列标注主要是做什么的。<br>序列标注是NLP中一个重要的任务，它包括分词、词性标注、命名实体识等。下面用一个分词的例子来简单说明。（<a href="https://spaces.ac.cn/archives/5542/comment-page-1#comments" target="_blank" rel="noopener">原文</a>)<br>假设我们现在用$bmes$四标签来进行分词，其中b 代表begin即词的开头， m代表middle即词内，e代表end即词的结尾，s代表single即单独成词。<br>现在我们有一个字符串序列 “今天天气不错”，如果对应的分词结果为“今天/天气/不/错”，则其标签序列为“bebess”。由于在序列标注中，我们认为正确的标签序列是唯一的，<br>所以我们的目标就是在所有可能的标签序列中（如bbbbbb,ssssss)挑选出真实的标签序列（bebess), 即最大化概率$P(bebess|今天天气不错）$。<br><img src="/2019/12/26/from-softmax-to-crf/seg.png" alt="4tag分词网络示意图"><br>即在上图中，所有从左至右的连线中，选出黄色的那条。</p><h2><span id="shu-xue-xing-shi">数学形式</span><a href="#shu-xue-xing-shi" class="header-anchor"></a></h2><p>我们假设输入序列是$X=[x_1, x_2, x_3, …, x_n]$,对应的输出序列是 $Y = [y_1, y_2, …, y_n]$,<br>label的集合为$L = [l_1, l_2, … , l_k]$. 任务目标是让真实的输出序列的概率最大，即：<br>$$<br>Max(P(y_1,y_2,..y_n|X))<br>$$</p><h1><span id="yan-shi-jian-zhou-softmax">沿时间轴Softmax</span><a href="#yan-shi-jian-zhou-softmax" class="header-anchor"></a></h1><p>直接对上述模型进行求解比较困难，所以我们先将问题简化，然后在对简化后的问题进行求解。<br>首先，我们引入朴素假设：即标签之间独立不相关，对应的目标就简化为：<br>$$<br>Max(P(y_1|X)P(y_2|X)…P(y_n|X))<br>$$<br>为了对$P(y_i|X)$进行建模，通常我们先通过RNNs（LSTM，BiLSTM, etc)来捕获输入X的全局信息，获得隐藏状态序列$\bar{x_1}, \bar{x_2}, …, \bar{x_n}$,<br>此时的$\bar{x_i}$可以看作是$x_i$ 通过X获取的特征，由于RNNs可以捕获全局信息，所以我们认为特征$\bar{x_i}$之间互不相关，对应的<br>$$P(y_i|X) = P(y_i|\bar{x_i})$$<br>我们的目标：<br>$$<br>Max(P(y_1|X)P(y_2|X)…P(y_n|X))<br>= Max(P(y_1|\bar{x_1})P(y_2|\bar{x_2})..P(y_n|\bar{x_n}))<br>= Max(\prod(P(y_i|\bar{x_i})))<br>$$<br>此时只需要$Max(P(y_i|\bar{x_i}))$进行求解，即沿时间轴一步一步的对RNNs的隐藏输出通过softmax来最大化对应目标标签概率。<br><img src="/2019/12/26/from-softmax-to-crf/softmax.png" alt="沿时间轴softmax"></p><h1><span id="crf">CRF</span><a href="#crf" class="header-anchor"></a></h1><p>因为在上一个方案中，我们做了朴素建设，将输出序列看作是相互独立的一元模型，这样会引入一些问题，如在分词中（bmes），m- 标签不能出现在s- 后面，<br>s- 标签不能出现在b- 和m-后面等，所以即使在上述方案中，至少也需要人为的设置一个“转移矩阵”，将不合理的转移方式得分置为0，来避免不合理方案的出现。<br>而上述方案出现错误的原因，本质上是因为我们的朴素假设：标签之间相互独立。为了解决上述方案的问题，我们至少需要在输出端显式考虑标签的关联性，即输出标签与上下文相关。<br><img src="/2019/12/26/from-softmax-to-crf/crf_example.png" alt="显式考虑输出端上下文"><br>显式考虑输出端上下文相关</p><p>现在我们回到原始目标上来，原始目标是$Max(P(y_1,y_2,..y_n|X)) $, 上个方案中我们是因为直接对$P(y_1, y_2,…y_n|x_1, x_2, …,x_n)$直接建模很难，<br>所以才做出了假设，简化目标。现在让我们换个思路，为了求解上述概率，我们还可以穷举出输出序列所有的可能结果$Y_1, Y_2, …, Y_{k^n}$,<br>然后如果能计算出当前输入X对应每种可能的输出序列的“值”， 则我们可以通过Softmax计算出真实输出序列的概率，即得到$P(Y_{true}|X)$。<br><code>假设一：我们可以学习一个打分函数f，通过函数f可以得到输出序列关于输入的得分，即$score_i = f(Y_i, X)$</code><br>此时，我们的目标就转化为 $P(Y|X) = \frac{exp(f(y_1, y_2,…y_n; X))}{Z(X)}$.<br>其中$Z(X) = \sum_{i=1}^{k^n}(exp(f(Y_i, X)))$。即此时的概率P是一个指数分布。<br>此时我们的方案是<code>1</code>个<code>$k^n$</code>多分类问题，即我们是对一个完整的输出序列为单位来计算概率（路径积分），而上一个方案中，是<code>n</code>个<code>k</code>分类问题，<br>这是两个方案的不同点之一。<br>在方案一中我们也说过，直接对完整序列建模比较困难，此时我们直接对$f(Y_i, X)$求解也会面临相同的困难，为了避免方案一的问题，我们不再使用一元模型，改为二元模型。<br><code>引入一阶马尔可夫假设，且其关联性是加性的。即当前输出标签只与前一个输出标签相关，其总得分是对所有得分求和。</code><br>此时的目标就转化为<br>$$<br>P(y_1, y_2, …, y_n|X)<br>= P(y_1|X)P(y_2|y_1;X)…P(y_n|y_{n-1}|X)<br>= P(y_1|X)\frac{P(y_1,y_2|X)}{P(y_1|X)P(y_2|X)} P(y_2|X) … \frac{P(y_{n-1}, y_n|X)}{P(y_{n-1}|X)P(y_n|X)} P(y_n|X)<br>$$<br>假设一中我们假设P是一个指数分布，所以此时我们引入两个函数e 和 t：e对$P(y_i|X)$建模, t 对$\frac{P(y_1,y_2|X)}{P(y_1|X)P(y_2|X)}$建模，即：<br>$$<br>P(y_i|X) = exp(e(y_i, X))<br>\frac{P(y_{i-1},y_1|X)}{P(y_{i-1}|X)P(y_i|X)} = P(y_i|X)exp(t(y_{i-i}, y_i; X))<br>$$</p><p>此时的目标就化简为：<br>$$<br>P(y_1, y_2, …, y_n|X)<br>= \frac{exp(f(y_1, y_2,…y_n; X))}{Z(X)}<br>= \frac{1}{Z(X)} exp(e(y_i,X) + t(y_1, y_2; X) + e(y_2, X) + … + t(y_{n-1}, y_n; X) + e(y_n, X))<br>$$<br>此时我们只需要对每个标签和相邻标签打分，然后将所有打分求和，即可得到总得分，然后对目标进行求解。</p><h1><span id="xian-xing-lian-crf">线性链CRF</span><a href="#xian-xing-lian-crf" class="header-anchor"></a></h1><p>虽然上面已经做了大量简化，但是求解时依然比较困难，主要是在求解t中，因为需要同时对输入X与标签$y_i$, $y_{i-1}$同时考虑，而在e中，<br>已经将输入与输出的关联进行了建模，此时我们引入线性链假设：假设t与输入X无关，则此时$ t(y_{i-1}, y_i;X) = t(y_{i-1}, y_i)$，那打分函数f简化为：<br>$$<br>f(y_1, y_2, …, y_n;X)<br>= e(y_1,X) + t(y_1, y_2) + e(y_2, X) + … + t(y_{n-1},y_n;X) + e(y_n,X)<br>$$<br>此时t就是一个待训练的参数矩阵，而e则可以通过RNNs来建模，概率分布也变为：</p><p>$$<br>P(y_1, y_2,…,y_n|x_1, x_2,…,x_n)<br>= exp(e(y_1, X) + \sum_{i=1}^{n-1}[t(y_i, y_{i+1}) + e(y_{i+1}, X)])) \frac{1}{Z(X)}<br>$$</p><h1><span id="qiu-jie">求解</span><a href="#qiu-jie" class="header-anchor"></a></h1><p>为了求解模型，我们用最大似然法， 即：</p><p>$$loss = -logP(y_1, y_2, …, y_n|x_1, x_2, …, x_n)$$<br>将上式代入：</p><p>$$loss = logZ(X) - (e(y_1, X) + \sum_{i=1}^{n-1}[t(y_i, y_{i+1}) + e( y_{i+1} , X)]) $$</p><p>减号后面的项通过添加一个待训练的参数矩阵循环计算即可得到结果，难算的前面的归一化因子Z(X)。前面我们也说了，我们此时是以路径为单位，<br>则此时Z(X) 需要我们穷举所有可能的路径比对其打分求和，而此时的路径有 $k^n$条，是指数级的，直接算效率太低，几乎不可能。<br>在假设二中，我们引入了一阶马尔可夫假设，当前标签只与前一个标签有联系，因此我们可以递归的计算归一化因子，这使得原来是指数级的计算量降低为线性级别。<a href="https://spaces.ac.cn/archives/5542/comment-page-1#comments" target="_blank" rel="noopener">原文</a><br>（这点是求解归一化因子的关键，最初我在推导时一直卡在这点上）<br>具体的: 将计算到时刻t的归一化因子记为Zt，并将它安装标签分为k个部分，即：</p><p>$$Zt = Zt^1 + Zt^2 + … + Zt^k$$<br>其中$Zt^i$表示以标签i为终点的所有路径的得分指数和，此时，我们写出递归公式：</p><p>$$Z_{t+1}^1 = (Zt^1 T_{11} + Zt^2 T_{21} + … + Zt^k T_{k1})E_{t+1}(1|X)$$</p><p>$$…  $$</p><p>$$Z_{t+1}^k = (Zt^1 T_{1k} + Zt^2 T{2k} + … + Zt^k T_{kk})E_{t+1}(k|X)$$</p><p>其中T是矩阵t的各个元素取指数形式，即$T_{ij} = exp(t_{ij})$, E是e的指数形式，即$E_{ij} = exp(e_{ij})$, 而$e_{ij}$是指时刻i时RNNs对label j的打分。<br><img src="/2019/12/26/from-softmax-to-crf/logz.png" alt="logz"></p><p>上式带有指数形式，我们取对数来简化计算过程。<br>$$<br>log(Z_{t+1}^1) = log((Zt^1 T_{11} + Zt^2 T_{21} + … + Zt^k T_{k1})E_{t+1}(1|X) )  \\<br>=log(exp(log(Zt^1) + t_{11}) + exp(log(Zt^2) + t_{21}) + … + exp(log(Zt^k) + t_{k1}) exp(e_{t+1}(1|X)))  \\<br>= log(exp(log(Zt^1) + t_{11} + e_{t+1}(1|X)) + exp(log(Zt^2) + t_{21} + e_{t+1}(1|X)) + … + exp(log(Zt^k) + t_{k1} + e_{t+1}(1|X)))\\<br>= log(\sum_k(log(Zt^k) + t_{k1} + e_{t+1}(1|X)))<br>$$</p><p>上面的过程比较曲折，对有些同学可能不太好理解，我们用一个简单的例子来帮助理解。<br>我们假设我们现在有一个输入$X=[w_0,w_1, w_2]$, 标签集合为$L=[l_1, l_2]$. RNNs对e完成了建模，即：</p><table><thead><tr><th>&nbsp;</th><th>l1</th><th>l2     </th></tr></thead><tbody><tr><td>w0</td><td>$e_{01}$</td><td>$e_{02}$ </td></tr><tr><td>w1</td><td>$e_{11}$</td><td>$e_{12}$ </td></tr><tr><td>w2</td><td>$e_{21}$</td><td>$e_{22}$ </td></tr></tbody></table><p>其中$e_{ij}$代表第i个字是第j个标签的得分。<br>转移矩阵t:</p><table><thead><tr><th>&nbsp;</th><th>l1</th><th>l2 </th></tr></thead><tbody><tr><td>l1</td><td>t11</td><td>t12  </td></tr><tr><td>l2</td><td>t21</td><td>t22  </td></tr></tbody></table><p>其中$t_{ij}$代表第i个标签转换为第j个标签的得分。<br>接下来我们按从$w_0$到$w_2$的方向一步一步来进行计算。首先，我们引入两个变量: states, cur，其中:  </p><ul><li>states代表上一个时刻计算的最终结果，即对应$log(Z_t^i)$</li><li><p>cur代表当前时刻各个标签的得分，即对应$e_t^i$</p></li><li><p><code>$w_0$:</code></p></li><li>states = None</li><li>$cur = [e_{01}, e_{02}]$<br>此时:<br>$$log(Z) = exp(e_{01}) + exp(e_{02})$$</li></ul><ul><li><code>$w_0$ –&gt; $w_1$:</code></li><li>states = $[e_{01}, e_{02}]$</li><li>cur = $[e_{11}, e{12}]$</li></ul><ol><li>扩展states:<br>$<br>states = $$\begin{pmatrix}<br>e_{01}&amp;e_{01}\\<br>e_{02}&amp;e_{02}\\<br>\end{pmatrix}$$<br>$</li></ol><ol start="2"><li>扩展cur:<br>$<br>cur = $$\begin{pmatrix}<br>e_{11}&amp;e_{12}\\<br>e_{11}&amp;e_{12}\\<br>\end{pmatrix}$$<br>$</li></ol><ol start="3"><li>将cur, states 与转移矩阵t 求和:</li></ol><p>$<br>score = $$\begin{pmatrix}<br>e_{11}&amp;e_{12}\\<br>e_{11}&amp;e_{12}\\<br>\end{pmatrix}$$<br>$+$ $$\begin{pmatrix}<br>e_{01}&amp;e_{01}\\<br>e_{02}&amp;e_{02}\\<br>\end{pmatrix}$$<br>$+$ $$\begin{pmatrix}<br>t_{11}&amp;t_{12}\\<br>t_{21}&amp;t_{22}\\<br>\end{pmatrix}$$<br>$=$ $$\begin{pmatrix}<br>e_{01} + e_{11} + t_{11} &amp; e_{01} + e_{12} + t_{12}\\<br>e_{02} + e_{11} + t_{21} &amp; e_{02} + e_{12} + t_{22}\\<br>\end{pmatrix}$$<br>$</p><ol start="4"><li>对score取指数形式然后求和，得到新的states:<br>$$<br>states = [log(exp(e_{01} + e_{11} + t_{11}) + exp(e_{02} + e_{11} + t_{21})), log(exp(e_{01} + e_{12} + t_{12}) + exp(e_{02} + e_{12} + t_{22}))]<br>$$<br>其中，states中的每个元素即对应着式中$logZ_{t}^i$, 此时的$log(Z)= \sum_k(exp(log(Z^k)))$:</li></ol><p>$$<br>log(Z_{0,1}) = log(exp(log(exp(e_{01} + e_{11} + t_{11}) + exp(e_{02} + e_{11} + t_{21}))) + exp(log(exp(e_{01} + e_{12} + t_{12}) + exp(e_{02} + e_{12} + t_{22})))) \\<br>= log(exp(e_{01} + e_{11} + t_{11}) + exp(e_{02} + e_{11} + t_{21}) + exp(e_{01} + e_{12} + t_{12}) + exp(e_{02} + e_{12} + t_{22}))<br>$$</p><p>当序列长度为2，标签有两个时，所有可能的标签序列为$(label_1-&gt;label_1, label_2-&gt;label_1, label_1-&gt;label_2, label_2-&gt;label_2)$,而对应的序列得分，即对应上式中的项，即：</p><ul><li>$ S_1: label_1-&gt;label_1:$<br>$ S_1 = e_{01} + e_{11} + t_{11} $</li><li>$S_2: label_2-&gt;label_1:$<br>$ S_2 = e_{02} + e_{11} + t_{21}$</li><li>$S_3 = label_1-&gt;label_2:$<br>$ S_3 = e_{01} + e_{12} + t_{12}$</li><li>$S_4 = label_2-&gt;label_2:$<br>$ S_4 = e_{02} + e_{12} + t_{22}$</li></ul><ul><li><code>$w_0$ -&gt; $w_1$ -&gt; $w_2$:</code></li><li>$states = [log(exp(e_{01} + e_{11} + t_{11}) + exp(e_{02} + e_{11} + t_{21})), log(exp(e_{01} + e_{12} + t_{12}) + exp(e_{02} + e_{12} + t_{22}))] $</li><li>$cur = [e_{21}, e_{22}]$</li></ul><p>与上面的做法一样，也分为4步：</p><ol><li>扩展states:<br>$<br>states = $$\begin{pmatrix}<br>log(exp(e_{01} + e_{11} + t_{11}) + exp(e_{02} + e_{11} + t_{21}))&amp;log(exp(e_{01} + e_{11} + t_{11}) + exp(e_{02} + e_{11} + t_{21}))\\<br>log(exp(e_{01} + e_{12} + t_{12}) + exp(e_{02} + e_{12} + t_{22}))&amp;log(exp(e_{01} + e_{12} + t_{12}) + exp(e_{02} + e_{12} + t_{22}))\\<br>\end{pmatrix}$$<br>$</li></ol><ol start="2"><li>cur：<br>$<br>cur = $$\begin{pmatrix}<br>e_{21} &amp;e_{22}\\<br>e_{21} &amp;e_{22}\\<br>\end{pmatrix}$$<br>$</li></ol><ol start="3"><li>将states，cur与转义矩阵t求和：</li></ol><p>$$<br>scores = \begin{pmatrix}<br>log(exp(e_{01}+e_{11}+t_{11}) + exp(e_{02}+e_{11}+t_{21})) &amp; log(exp(e_{01}+e_{11}+t_{11}) + exp(e_{02}+e_{11}+t_{21})) \\<br>log(exp(e_{01}+e_{12}+t_{12}) + exp(e_{02}+e_{12}+t_{22})) &amp; log(exp(e_{01}+e_{12}+t_{12}) + exp(e_{02}+e_{12}+t_{22}))\\<br>\end{pmatrix} \\+<br>\begin{pmatrix}<br>e_{21} &amp;e_{22}\\<br>e_{21} &amp;e_{22}\\<br>\end{pmatrix} \\+<br>\begin{pmatrix}<br>t_{11}&amp; t_{12}\\<br>t_{21}&amp;t_{22}\\<br>\end{pmatrix} \\=<br>\begin{pmatrix}<br>log(exp(e_{01}+e_{11}+t_{11}) + exp(e_{02}+e_{11}+t_{21})) + e_{21} + t_{11} &amp;log(exp(e_{01}+e_{11}+t_{11}) + exp(e_{02}+e_{11}+t_{21})) + e_{22} + t_{12}\\<br>log(exp(e_{01}+e_{12}+t_{12}) + exp(e_{02}+e_{12}+t_{22})) + e_{21} + t_{21} &amp;log(exp(e_{01}+e_{12}+t_{12}) + exp(e_{02}+x_{12}+t_{22})) + e_{22} + t_{22}\\<br>\end{pmatrix}<br>$$</p><ol start="4"><li>对score取指数形式然后求和，得到新的states:</li></ol><p>$$ states = [\\<br>log(exp(log(exp(e_{01}+e_{11}+t_{11}) + exp(e_{02}+e_{11}+t_{21})) + e_{21} + t_{11})+exp(log(exp(e_{01}+e_{12}+t_{12}) + exp(e_{02}+e_{12}+t_{22})) + e_{21} + t_{21})), \\<br>log(exp(log(exp(e_{01}+e_{11}+t_{11}) + exp(e_{02}+e_{11}+t_{21})) + e_{22} + t_{12})+ exp(log(exp(e_{01}+e_{12}+t_{12}) + exp(e_{02}+x_{12}+t_{22})) + e_{22} + t_{22})))] \\<br> = [log((exp(e_{01}+e_{11}+t_{11}) + exp(e_{02}+e_{11}+t_{21}))exp(e_{21} + t_{11}) + (exp(e_{01}+e_{12}+t_{12}) + exp(e_{02}+e_{12}+t_{22}))exp(e_{21}+t_{21})),\\<br>log((exp(e_{01}+e_{11}+t_{11}) + exp(e_{02}+e_{11}+t_{21}))exp(e_{22} + t_{12}) + (exp(e_{01}+e_{12}+t_{12}) + exp(e_{02}+e_{12}+t_{22}))exp(e_{22}+t_{22}))]<br>$$</p><p>现在，我们用states计算一下$(Z_2)$:</p><p>$$<br>log(Z_{(0-&gt;1-&gt;2)}) = log(exp(states[0]) + exp(states[1])) \\<br>=log((exp(e_{01}+e_{11}+t_{11}) + exp(e_{02}+e_{11}+t_{21}))exp(e_{21} + t_{11}) + (exp(e_{01}+e_{12}+t_{12}) + exp(e_{02}+e_{12}+t_{22}))exp(e_{21}+t_{21})) \\+<br>log((exp(e_{01}+e_{11}+t_{11}) + exp(e_{02}+e_{11}+t_{21}))exp(e_{22} + t_{12}) + (exp(e_{01}+e_{12}+t_{12}) + exp(e_{02}+e_{12}+t_{22}))exp(e_{22}+t_{22})) \\<br>= log(exp(e_{01}+e_{11}+t_{11}+e_{21}+t_{11}) + exp(e_{02}+e_{11}+t_{21}+e_{21}+t_{11}) \\ +<br>exp(e_{01}+e_{12}+t_{12} +e_{21}+t_{21}) + exp(e_{02}+e_{12}+t_{22}+e_{21}+t_{21}) \\+<br>exp(e_{01}+e_{11}+t_{11} +e_{22}+t_{12}) + exp(e_{01}+e_{11}+t_{11}+e_{22}+t_{12}) \\+<br>exp(e_{01}+e_{12}+t_{12} +e_{22}+t_{22}) + exp(e_{01}+e_{12}+t_{12}+e_{22}+t_{21}))<br>$$</p><p>上式也就是我们要求的最终结果$log(Z)$,其中指数内对应着所有路径的得分。<br>到此，上例中的整个归一化因子的计算过程也就完成了，而CRF中最难的部分也就解决了。</p><h1><span id="demo">demo</span><a href="#demo" class="header-anchor"></a></h1><p>搞懂了理论部分，下面写一个demo来验证一下。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CRF</span><span class="params">(Layer)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, mask_label=False, **kwargs)</span>:</span></span><br><span class="line">        self.mask_label = <span class="number">1</span> <span class="keyword">if</span> mask_label <span class="keyword">else</span> <span class="number">0</span></span><br><span class="line">        super(CRF, self).__init__(**kwargs)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">build</span><span class="params">(self, input_shape)</span>:</span></span><br><span class="line">        self.num_label = input_shape[<span class="number">-1</span>] - self.mask_label</span><br><span class="line">        self.trans = self.add_weight(name=<span class="string">'crf_trans'</span>,</span><br><span class="line">                                     shape=(self.num_label, self.num_label),</span><br><span class="line">                                     trainable=<span class="literal">True</span>,</span><br><span class="line">                                     initializer=<span class="string">'glorot_uniform'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">path_score</span><span class="params">(self, inputs, labels)</span>:</span></span><br><span class="line">        <span class="string">'''</span></span><br><span class="line"><span class="string">        :param inputs: (batch_size, timesteps, num_label), obtained from rnn(lstm, bilstm. etc.)</span></span><br><span class="line"><span class="string">        :param labels: one-hot, (batch_size, timesteps, num_label) , real target series</span></span><br><span class="line"><span class="string">        :return:  path score</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        point_score = K.sum(K.sum(inputs * labels, <span class="number">2</span>), <span class="number">1</span>, keepdims=<span class="literal">True</span>)</span><br><span class="line">        label_pre = K.expand_dims(labels[:, :<span class="number">-1</span>], <span class="number">3</span>)</span><br><span class="line">        label_next = K.expand_dims(labels[:, <span class="number">1</span>:], <span class="number">2</span>)</span><br><span class="line">        label_trans = label_pre * label_next</span><br><span class="line">        trans = K.expand_dims(K.expand_dims(self.trans, <span class="number">0</span>), <span class="number">0</span>)</span><br><span class="line">        trans_score = K.sum(K.sum(label_trans * trans, [<span class="number">2</span>, <span class="number">3</span>]), <span class="number">1</span>, keepdims=<span class="literal">True</span>)</span><br><span class="line">        <span class="keyword">return</span> point_score + trans_score</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">log_norm_pre</span><span class="params">(self, inputs, states)</span>:</span></span><br><span class="line">        <span class="string">'''</span></span><br><span class="line"><span class="string">        expand previous states and inputs, sum with trans</span></span><br><span class="line"><span class="string">        :param inputs: (batch_size, num_label), current word emission scores</span></span><br><span class="line"><span class="string">        :param states: (batch_size, num_label), all paths  score of previous word</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        states = K.expand_dims(states[<span class="number">0</span>], <span class="number">2</span>)</span><br><span class="line">        inputs = K.expand_dims(inputs, <span class="number">1</span>)</span><br><span class="line">        trans = K.expand_dims(self.trans, <span class="number">0</span>)</span><br><span class="line">        scores = states + trans + inputs</span><br><span class="line">        output = K.logsumexp(scores, <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> output, [output]</span><br><span class="line">        <span class="comment"># states = K.expand_dims(states[0], 2)  # (batch_size, output_dim, 1)</span></span><br><span class="line">        <span class="comment"># trans = K.expand_dims(self.trans, 0)  # (1, output_dim, output_dim)</span></span><br><span class="line">        <span class="comment"># output = K.logsumexp(states + trans, 1)  # (batch_size, output_dim)</span></span><br><span class="line">        <span class="comment"># return output + inputs, [output + inputs]</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">loss</span><span class="params">(self, y_true, y_pre)</span>:</span></span><br><span class="line">        <span class="string">'''</span></span><br><span class="line"><span class="string">        :param inputs: (batch_size, timesteps, num_label)</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        <span class="comment"># mask = 1 - y_true[:, 1: -1] if self.mask_label else None</span></span><br><span class="line">        <span class="comment"># # y_true, y_pred = y_true[:, :, :self.num_label], y_pre[:, :, :self.num_label]</span></span><br><span class="line">        <span class="comment"># real_path_score = self.path_score(y_pre, y_true)</span></span><br><span class="line">        <span class="comment"># init_states = [y_pre[:, 0]]</span></span><br><span class="line">        <span class="comment"># log_norm, _ = K.rnn(self.log_norm_pre, initial_states=init_states, inputs=y_pre[:, 1:], mask=mask)  # log(Z)</span></span><br><span class="line">        <span class="comment"># log_norm_score = K.logsumexp(log_norm, 1, keepdims=True)</span></span><br><span class="line">        <span class="comment"># return log_norm_score - real_path_score</span></span><br><span class="line">        mask = <span class="number">1</span> - y_true[:, <span class="number">1</span>:, <span class="number">-1</span>] <span class="keyword">if</span> self.mask_label <span class="keyword">else</span> <span class="literal">None</span></span><br><span class="line">        y_true, y_pre = y_true[:, :, :self.num_label], y_pre[:, :, :self.num_label]</span><br><span class="line">        init_states = [y_pre[:, <span class="number">0</span>]]  <span class="comment"># 初始状态</span></span><br><span class="line">        log_norm, _, _ = K.rnn(self.log_norm_pre, y_pre[:, <span class="number">1</span>:], init_states, mask=mask)  <span class="comment"># 计算Z向量（对数）</span></span><br><span class="line">        log_norm = K.logsumexp(log_norm, <span class="number">1</span>, keepdims=<span class="literal">True</span>)  <span class="comment"># 计算Z（对数）</span></span><br><span class="line">        path_score = self.path_score(y_pre, y_true)  <span class="comment"># 计算分子（对数）</span></span><br><span class="line">        <span class="keyword">return</span> log_norm - path_score  <span class="comment"># 即log(分子/分母)</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">call</span><span class="params">(self, inputs)</span>:</span>  <span class="comment"># crf 只是loss，不改变inputs</span></span><br><span class="line">        <span class="keyword">return</span> inputs</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">accuracy</span><span class="params">(self, y_true, y_pred)</span>:</span></span><br><span class="line">        mask = <span class="number">1</span> - y_true[:, :, <span class="number">-1</span>] <span class="keyword">if</span> self.mask_label <span class="keyword">else</span> <span class="literal">None</span></span><br><span class="line">        y_true, y_pred = y_true[:, :, :self.num_label], y_pred[:, :, :self.num_label]</span><br><span class="line">        isequal = K.equal(K.argmax(y_true, <span class="number">2</span>), K.argmax(y_pred, <span class="number">2</span>))</span><br><span class="line">        isequal = K.cast(isequal, <span class="string">'float32'</span>)</span><br><span class="line">        <span class="keyword">if</span> mask == <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">return</span> K.mean(isequal)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> K.sum(isequal * mask) / K.sum(mask)</span><br></pre></td></tr></table></figure></p><p>结果：<br><img src="/2019/12/26/from-softmax-to-crf/result.png" alt="result"></p><h1><span id="guan-yu-tou-tu">关于头图</span><a href="#guan-yu-tou-tu" class="header-anchor"></a></h1><p>初雪下的红果果</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;/assets/css/APlayer.min.css&quot;&gt;&lt;script src=&quot;/assets/js/APlayer.min.js&quot; cla
      
    
    </summary>
    
    
      <category term="NLP" scheme="https://xv44586.github.io/categories/NLP/"/>
    
    
      <category term="CRF" scheme="https://xv44586.github.io/tags/CRF/"/>
    
  </entry>
  
  <entry>
    <title>分享一个有趣的游戏</title>
    <link href="https://xv44586.github.io/2019/12/09/longton/"/>
    <id>https://xv44586.github.io/2019/12/09/longton/</id>
    <published>2019-12-09T14:35:44.000Z</published>
    <updated>2019-12-13T13:29:33.341Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><div class="toc"><!-- toc --><ul><li><a href="#guan-yu-tou-tu">关于头图</a></li></ul><!-- tocstop --></div><p>今天第一次知道了一个有趣的游戏，Langton的蚂蚁，动手自己画了一个后，决定分享一下。这个游戏的有趣体现在两个方面：<br><em>1：</em> 这个游戏是个零玩家游戏，整个过程也十分的简单：有一个像围棋盘一样画满方格的画布，初始时，整个画布都是空白，<br>一只蚂蚁在画布的某一个地方，如果当前空格为白色，则将当前空格去反，然后左转90度并前进一格；如果当前空格为黑色，则将当前空格颜色去反，<br>然后右转90度并前进一格，如此往复。<br><em>2：</em> 最后的结果非常有意思，开始时，整个画布是复杂无规律的复杂图像，很难想象是这么简单的规则产生的，但当蚂蚁走了一万步以后，整个运动过程<br>进入了循环，而图像也开始变为有规律的图像。</p><p>开始的前一百步如上图，到一万步还有点时间，所以为直接跳过中间一万步，给出一万步后的一百步。感兴趣有耐心的可以跑下代码观察一下这个有点神奇的游戏。Have fun！</p><p><img src="/2019/12/09/longton/ant.gif" alt><br>    <strong>前一百步</strong></p><p><img src="/2019/12/09/longton/ant_r.gif" alt><br>    <strong>规律出现后的一百步</strong></p><p>Langlon的蚂蚁游戏代码</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Date    : 2019/12/9</span></span><br><span class="line"><span class="comment"># @Author  : mingming.xu</span></span><br><span class="line"><span class="comment"># @File    : test.py</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> animation</span><br><span class="line"><span class="keyword">import</span> matplotlib.ticker <span class="keyword">as</span> plticker</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Direction</span><span class="params">(object)</span>:</span></span><br><span class="line">    D = [<span class="string">'E'</span>, <span class="string">'N'</span>, <span class="string">'W'</span>, <span class="string">'S'</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, position, direct)</span>:</span></span><br><span class="line">        self.direct = direct</span><br><span class="line">        self.position = position</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">go_one_step</span><span class="params">(self, left=True)</span>:</span></span><br><span class="line">        lr = <span class="number">1</span> <span class="keyword">if</span> left <span class="keyword">else</span> <span class="number">-1</span></span><br><span class="line">        direct = self.D[(self.D.index(self.direct) + <span class="number">1</span> * lr) % len(self.D)]</span><br><span class="line">        next_position = &#123;</span><br><span class="line">            <span class="string">'E'</span>: <span class="keyword">lambda</span> p: [p[<span class="number">0</span>], p[<span class="number">1</span>] + <span class="number">1</span> * lr],</span><br><span class="line">            <span class="string">'N'</span>: <span class="keyword">lambda</span> p: [p[<span class="number">0</span>] - <span class="number">1</span> * lr, p[<span class="number">1</span>]],</span><br><span class="line">            <span class="string">'W'</span>: <span class="keyword">lambda</span> p: [p[<span class="number">0</span>], p[<span class="number">1</span>] - <span class="number">1</span> * lr],</span><br><span class="line">            <span class="string">'S'</span>: <span class="keyword">lambda</span> p: [p[<span class="number">0</span>] + <span class="number">1</span> * lr, p[<span class="number">1</span>]]</span><br><span class="line">        &#125;</span><br><span class="line">        position = next_position[self.direct](self.position)</span><br><span class="line">        <span class="keyword">return</span> Direction(position=position, direct=direct)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">N = <span class="number">100</span>  <span class="comment"># length of matrix</span></span><br><span class="line">lc, hc = <span class="number">1</span>, <span class="number">-1</span>  <span class="comment"># color for negative and positive</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">fig, ax = plt.subplots(figsize=(<span class="number">50</span>, <span class="number">50</span>))</span><br><span class="line">data = np.zeros((N, N)) + lc</span><br><span class="line">data[int(N/<span class="number">2</span>), int(N/<span class="number">2</span>)] *= <span class="number">-1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># remove axis</span></span><br><span class="line">ax.get_yaxis().set_visible(<span class="literal">False</span>) <span class="comment">#不显示y轴</span></span><br><span class="line">ax.get_xaxis().set_visible(<span class="literal">False</span>) <span class="comment">#不显示x轴</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># add text</span></span><br><span class="line">time_template = <span class="string">'step = %d'</span></span><br><span class="line">time_text = plt.text(<span class="number">0.5</span>, N+<span class="number">0.1</span>, <span class="string">''</span>, fontdict=&#123;<span class="string">'size'</span>: <span class="number">20</span>, <span class="string">'color'</span>: <span class="string">'red'</span>&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment">#add grid</span></span><br><span class="line"><span class="comment"># myInterval = 1</span></span><br><span class="line"><span class="comment"># loc = plticker.MultipleLocator(base=myInterval)</span></span><br><span class="line"><span class="comment"># ax.xaxis.set_major_locator(loc)</span></span><br><span class="line"><span class="comment"># ax.yaxis.set_major_locator(loc)</span></span><br><span class="line"><span class="comment"># ax.grid(which='major', axis='both', linestyle='-')</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># imshow</span></span><br><span class="line">ln = plt.imshow(data, animated=<span class="literal">True</span>, cmap=<span class="string">'gray'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">dct = Direction(position=[int(N / <span class="number">2</span>), int(N / <span class="number">2</span>)], direct=<span class="string">'N'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">init</span><span class="params">()</span>:</span></span><br><span class="line">    ax.set_xlim(<span class="number">0</span>, N)</span><br><span class="line">    ax.set_ylim(<span class="number">0</span>, N+<span class="number">5</span>)</span><br><span class="line">    time_text.set_text(<span class="string">''</span>)</span><br><span class="line">    <span class="keyword">return</span> ln, time_text</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">move</span><span class="params">(dct, data)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    当前为白色方格，则对当前方格取反，左转前进一格；若当前为黑色方格，取反后右转前进一格</span></span><br><span class="line"><span class="string">    :param dct:</span></span><br><span class="line"><span class="string">    :param mat:</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    pos = dct.position</span><br><span class="line">    <span class="keyword">if</span> data[pos[<span class="number">0</span>], pos[<span class="number">1</span>]] &gt; <span class="number">0</span>:</span><br><span class="line">        data[pos[<span class="number">0</span>], pos[<span class="number">1</span>]] *= <span class="number">-1</span></span><br><span class="line">        dct_ = dct.go_one_step(left=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        data[pos[<span class="number">0</span>], pos[<span class="number">1</span>]] *= <span class="number">-1</span></span><br><span class="line">        dct_ = dct.go_one_step(left=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> dct_, data</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">update</span><span class="params">(f)</span>:</span></span><br><span class="line">    <span class="keyword">global</span> dct</span><br><span class="line">    <span class="keyword">global</span> data</span><br><span class="line">    dct, data = move(dct, data)</span><br><span class="line">    ln.set_data(data)</span><br><span class="line">    time_text.set_text(time_template % f)</span><br><span class="line">    <span class="keyword">return</span> ln, time_text</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">data_gen</span><span class="params">()</span>:</span></span><br><span class="line">    frame = <span class="number">0</span></span><br><span class="line">    max_step = <span class="number">11000</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> frame &lt; max_step:</span><br><span class="line">        frame += <span class="number">1</span></span><br><span class="line">        <span class="keyword">yield</span> frame</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">anim = animation.FuncAnimation(fig, update, frames=data_gen, interval=<span class="number">10</span>,</span><br><span class="line">                               init_func=init, blit=<span class="literal">True</span>, repeat=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">anim.save(<span class="string">'ant.gif'</span>, writer=<span class="string">'imagemagick'</span>, fps=<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><h1><span id="guan-yu-tou-tu">关于头图</span><a href="#guan-yu-tou-tu" class="header-anchor"></a></h1><p>游戏的前一百步</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;/assets/css/APlayer.min.css&quot;&gt;&lt;script src=&quot;/assets/js/APlayer.min.js&quot; cla
      
    
    </summary>
    
    
      <category term="Math" scheme="https://xv44586.github.io/categories/Math/"/>
    
    
      <category term="Game" scheme="https://xv44586.github.io/tags/Game/"/>
    
  </entry>
  
  <entry>
    <title>有趣的概率统计题</title>
    <link href="https://xv44586.github.io/2019/11/30/statistics/"/>
    <id>https://xv44586.github.io/2019/11/30/statistics/</id>
    <published>2019-11-30T02:28:23.000Z</published>
    <updated>2019-11-30T07:15:58.387Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><div class="toc"><!-- toc --><ul><li><a href="#fen-xiang-yi-ge-you-qu-de-gai-lu-ti">分享一个有趣的概率题</a></li><li><a href="#guan-yu-tou-tu">关于头图</a></li></ul><!-- tocstop --></div><p>昨晚下雪了，开心😄！</p><h1><span id="fen-xiang-yi-ge-you-qu-de-gai-lu-ti">分享一个有趣的概率题</span><a href="#fen-xiang-yi-ge-you-qu-de-gai-lu-ti" class="header-anchor"></a></h1><p>一段线段上，任意取两不重合的点，将这条线段切分成三段，问，这三条线段组成三角形点概率是多少？</p><p>现在我们将问题转化一下，假设原始线段长度为1，即$(0，1)$表示原始线段，此时，随机在$(0，1)$范围内选两个点a，b，组成$(0，a)$，$(a，b)$，$(b，1)$三个线段，<br>此时原始问题等价于现在的三个线段组成三角形的概率。<br>现在我们来考虑一下，三条线段分别为$A$， $B$，$C$，其中$A &gt;= B &gt;= C$,则A的长度必定在$[1/3, 1)$,而要组成三角形，则需要 $B + C &gt; A$,所以 B + C 的长度为$(1/2, 1)$,<br>而对应的A的长度也就在[1/3, 1/2)内，所以，最终能构成三角形的概率即为 $A_{triangle} / A_{all} = (1/2 - 1/3) / (1 - 1/3) = 1/4$</p><p>看似非常复杂的问题，从最基本的数学知识就能解答，还真是有趣！ </p><h1><span id="guan-yu-tou-tu">关于头图</span><a href="#guan-yu-tou-tu" class="header-anchor"></a></h1><p>2019年的第一场雪，摄于望京地铁站</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;/assets/css/APlayer.min.css&quot;&gt;&lt;script src=&quot;/assets/js/APlayer.min.js&quot; cla
      
    
    </summary>
    
    
      <category term="Math" scheme="https://xv44586.github.io/categories/Math/"/>
    
    
      <category term="Statistics" scheme="https://xv44586.github.io/tags/Statistics/"/>
    
  </entry>
  
</feed>
