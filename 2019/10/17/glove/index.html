<!DOCTYPE html><html lang="zh-cn"><head><meta name="generator" content="Hexo 3.9.0"><meta charset="utf-8"><title>Glove模型 | 小蛋子</title><meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no"><meta name="format-detection" content="telephone=no"><meta name="author" content="[object Object]"><meta name="designer" content="minfive"><meta name="keywords" content="NLP, 机器学习, 深度学习, Python, Backend"><meta name="description" content="NLP | Machine Learning | Developer"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black"><meta name="format-detection" content="telephone=yes"><meta name="mobile-web-app-capable" content="yes"><meta name="robots" content="all"><link rel="canonical" href="https://xv44586.github.io/2019/10/17/glove/index.html"><link rel="icon" type="image/png" href="/img/favicon.ico" sizes="32x32"><meta name="google-site-verification" content="tbK2z0UTHcAWdqNCgEwykaDA9vvvXnN4ZSp_LFbAbDc"><meta name="baidu-site-verification" content="NBO0j1DAOy"><meta name="baidu-site-verification" content="ulZR80nUkv"><link rel="stylesheet" href="/scss/base/index.css"><link rel="alternate" href="/atom.xml" title="小蛋子"><script>var _hmt=_hmt||[];!function(){var e=document.createElement("script"),t=(e.src="https://hm.baidu.com/hm.js?b1d2a1d2b250300950a8ffb5caa20818",document.getElementsByTagName("script")[0]);t.parentNode.insertBefore(e,t)}()</script><link rel="stylesheet" href="/scss/views/page/post.css"><link rel="alternate" href="/atom.xml" title="小蛋子" type="application/atom+xml"></head><body ontouchstart><div id="page-loading" class="page page-loading" style="background-image:url(/other/loading.gif)"></div><div id="page" class="page js-hidden"><header class="page__small-header page__header--small"><nav class="page__navbar"><div class="page__container navbar-container"><a class="page__logo" href="/" title="小蛋子" alt="小蛋子"><img src="/img/lg.png" alt="小蛋子"></a><nav class="page__nav"><ul class="nav__list clearfix"><li class="nav__item"><a href="/" alt="首页" title="首页">首页</a></li><li class="nav__item"><a href="/archives" alt="归档" title="归档">归档</a></li><li class="nav__item"><a href="/about" alt="关于" title="关于">关于</a></li></ul></nav><button class="page__menu-btn" type="button"><i class="iconfont icon-menu"></i></button></div></nav></header><main class="page__container page__main"><div class="page__content"><article class="page__post"><div class="post__cover"><img src="/2019/10/17/glove/sk.jpeg" alt="Glove模型"></div><header class="post__info"><h1 class="post__title">Glove模型</h1><div class="post__mark"><div class="mark__block"><i class="mark__icon iconfont icon-write"></i><ul class="mark__list clearfix"><li class="mark__item"><a href="https://github.com/xv44586">小蛋子</a></li></ul></div><div class="mark__block"><i class="mark__icon iconfont icon-time"></i><ul class="mark__list clearfix"><li class="mark__item"><span>2019-10-17</span></li></ul></div><div class="mark__block"><i class="mark__icon iconfont icon-tab"></i><ul class="mark__list clearfix"><li class="mark__item"><a href="/tags/Glove/">Glove</a></li></ul></div><div class="mark__block"><i class="mark__icon iconfont icon-eye"></i><ul class="mark__list clearfix"><li id="busuanzi_container_page_pv" class="mark__item"><span id="busuanzi_value_page_pv"></span>次</li></ul></div></div></header><div class="post__content"><div class="toc"><ul><li><a href="#yi-zheng-ti-si-lu">一、整体思路</a></li><li><a href="#er-ji-ben-jia-she">二、基本假设</a></li><li><a href="#san-mo-xing">三、模型</a></li><li><a href="#si-dui-bi">四、对比</a></li><li><a href="#wu-si-kao">五、思考</a></li><li><a href="#zai-si-kao">再思考：</a></li><li><a href="#guan-yu-tou-tu">关于头图</a></li></ul></div><h1><span id="yi-zheng-ti-si-lu">一、整体思路</span><a href="#yi-zheng-ti-si-lu" class="header-anchor"></a></h1><p>获取词向量基本上有两种思路：</p><ul><li>1.利用全局统计信息，进行矩阵分解（如LSA）来获取词向量，这样获得的词向量往往在词相似性任务上表现不好，表明这是一个次优的向量空间结构；</li><li>2.利用局部上下文窗口单独训练，但是统计信息作为有用的先验知识，没有很好的利用到。</li></ul><p>Glove：结合两种训练方式，获取更好的词向量</p><h1><span id="er-ji-ben-jia-she">二、基本假设</span><a href="#er-ji-ben-jia-she" class="header-anchor"></a></h1><p>词的共现次数与其语义的相关性往往不是严格成比例，所以直接用共线性来表征词之间相关性效果不好，因此，作者通过引入第三个词，通过词之间的差异来刻画相关性。差异选择用两个词与同一个词的共现概率的次数来更好的判断词之间的相关性。比率：$ratio_{i,j,k}=\frac{Pi,k}{Pj,k} $<br>看下面这个例子：<br><img src="/2019/10/17/glove/table1.png" alt="image.png"><br>ice 与solid相关性高，而steam与solid相关性弱，对应比例大于1；ice与gas相关性弱，steam与gas相关性高，对应比例小于1，ice与steam都与water相关，对应比例约等于1，ice与steam与fashion都不相关，对应比例也是约等于1.<br>相关性的规律：<br><img src="/2019/10/17/glove/ratio.png" alt="image.png"></p><h1><span id="san-mo-xing">三、模型</span><a href="#san-mo-xing" class="header-anchor"></a></h1><p>模型的数学形式为：<br><img src="/2019/10/17/glove/1.png" alt><br>其中$w_i$, $w_j$ 与$w_k$分属不同的两个词向量空间（参考skipgram），对于F函数，我们希望他能够在向量空间内预测$p(P_{ik}/P_{jk})$这个比率，由于向量空间的线性结构，最自然的方式就是用向量的差，即：<br><img src="/2019/10/17/glove/2.png" alt><br>等式的右侧是一个标量，左侧F函数可以是一个复杂函数，而我们上面提到我们希望捕捉向量的线性结构，所以避免使用复杂函数，首先将参数做内积：<br><img src="/2019/10/17/glove/3.png" alt><br>在窗口滑动的过程中，中心词与上下文词的角色会相互转化，但是当词的位置互换后，其相关性应该是保持一致的，所以，F函数需要对<code>和</code>操作与<code>商</code>操作上同态（这里同态的意思是F函数在左右两侧应该是一致的，也就是 $F((w_i - w_j)）= F(w_i) / F(w_j)$：<br><img src="/2019/10/17/glove/4.png" alt><br>其中：<br><img src="/2019/10/17/glove/5.png" alt></p><p>为了解决 上式4，F函数的形式就是exp(指数形式），最终求解后：<br><img src="/2019/10/17/glove/6.png" alt><br>上式中，等式左侧是对称的，即$W_i^T*W_j = W_j^T*W_i$, 而右侧是不对称的，即$log(p_{ij}) != log(P_{ji})$. 如果上式的右侧没有$log(x_i)$,则等式的左右就对称了，考虑到与$k$无关，所以把这一项并入到$i$的偏差项中，即：<br><img src="/2019/10/17/glove/7.png" alt><br>由于上式中有$log$，所以需要处理0值，同时，对于低频与高频的共线词都不能过度训练，于是，优化目标就变成了：<br><img src="/2019/10/17/glove/8.png" alt><br>其中，权重函数$f(x)$需要满足：</p><ul><li>1， f(0)=0</li><li>2, 非减以避免低频共现过度训练</li><li>3，抑制高频共现避免过度训练<br>最后采用的$f(x)$ 形式为：<br><img src="/2019/10/17/glove/9.png" alt><br>实验中他们采用的是xmax=100, a=3/4<br><img src="/2019/10/17/glove/scratch.png" alt="完整过程"></li></ul><h1><span id="si-dui-bi">四、对比</span><a href="#si-dui-bi" class="header-anchor"></a></h1><p>与局部窗口方式对比：<br><img src="/2019/10/17/glove/comp.png" alt="与local window对比"><br>优化目标使用不同的损失函数，并带有调和函数来降低高频词的影响。<br>语义相似性结果对比：<br><img src="/2019/10/17/glove/result.png" alt="不同模型对比"></p><h1><span id="wu-si-kao">五、思考</span><a href="#wu-si-kao" class="header-anchor"></a></h1><ul><li>1.相对与word2vec, Glove引入了词频统计信息，这是很重要的全局信息。</li><li>2.word2vec的训练次数与词频相关，Glove的训练中词频是loss的weight，高频低频词的overweight的情况更低。</li><li>3.将基于局部窗口的模型中，相同词进行合并，修改对应object：<img src="/2019/10/17/glove/13.png" alt><br>其中$H$为交叉熵，相对Glove的object：<br><img src="/2019/10/17/glove/16.png" alt><br>loss由交叉熵改为最小二乘，$X_i$改为$f(X_i)$函数进行调和。</li><li>4.Glove中的左右词向量也是两个不同的词向量空间，与word2vec一样，虽然Glove模型上看上去可以使用同一个词向量空间做，但是作者说是因为更好优化且模型更稳定，不同的时，最后的结果是左右词向量求和（虽然word2vec也可以这么做）</li></ul><p>Demo:<a href="https://github.com/xv44586/Papers/blob/master/NLP/WordVector/GloveDemo.ipynb" target="_blank" rel="noopener">https://github.com/xv44586/Papers/blob/master/NLP/WordVector/GloveDemo.ipynb</a></p><hr><h1><span id="zai-si-kao">再思考：</span><a href="#zai-si-kao" class="header-anchor"></a></h1><ul><li>1.通常我们都是根据模型来推导其对应的性质，而Glove是因为其应该具有的性质，来反推模型，这种方式也给人提供了一种新思路。</li><li>2.为什么两种模型都有两套词向量空间（中心词向量和上下文词向量）？虽然两个作者都说是因为更好优化且模型更稳定，那有没有更合理的理论上的解释呢？我的理解是：对于word2vec，模型直接对概率$p(w|context)$,如skipgram中，直接对$P(w_2|w_1)$进行建模，而$P(w_2|w_1$)与$P(w_1|w_2)$并不一定相等，所以需要针对词的位置区分，也就是需要两套不一样的词向量空间；而Glove中，如上文中公式（6）所示，模型右侧有一个与位置有关的参数，虽然通过引入两个bias可以一定程度上消除这个位置相关的参数，但是这个参数并不是均匀分布，所以仅通过bias不能完全解决这个问题，而引入两个不同的词向量空间，相当于是引入了位置信息，这样能更好的解决这个问题。其最本质的原因是在窗口滑动过程中，词位置变化的同时信息可能是不对称的，即以a为中心词的窗口中的b在以b为窗口时，a可能丢失。</li><li>3.对于上式8，存在一个比较严重的问题，模型为了消去位置相关参数，将其吸收进bias内，而这个bias的引入，就导致了一个严重的问题，即模型不适定。<br><img src="/2019/10/17/glove/ret.png" alt><br>即当你求得一组解后，你可以给这组解加上一个常数向量，其还是一组解。那这个问题就很严重了，你无法评估你得到的解是哪组解。如果加上的是非常大的常数向量，那这组词向量在很多度量上就失去了意义（如余弦距离）<h1><span id="guan-yu-tou-tu">关于头图</span><a href="#guan-yu-tou-tu" class="header-anchor"></a></h1>摄于北京某水库</li></ul><div class="post__prevs"><div class="post__prev"><a href="/2019/10/17/randomForest/" title="随机森林模型中是不是树越多越好"><i class="iconfont icon-prev"></i>随机森林模型中是不是树越多越好</a></div><div class="post__prev post__prev--right"><a href="/2019/10/17/dropout/" title="Dropout--深度神经网络中的Bagging">Dropout--深度神经网络中的Bagging<i class="iconfont icon-next"></i></a></div></div></div></article></div><aside class="page__sidebar"><form id="page-search-from" class="page__search-from" action="/search/"><label class="search-form__item"><input class="input" type="text" name="search" placeholder="Search..."> <i class="iconfont icon-search"></i></label></form><div class="sidebar__block"><h3 class="block__title">简介</h3><p class="block__text">NLP | Machine Learning | Developer</p></div><div class="sidebar__block"><h3 class="block__title">文章分类</h3><ul class="block-list"><li class="block-list-item"><a class="block-list-link" href="/categories/Programming/">Programming</a><span class="block-list-count">4</span></li><li class="block-list-item"><a class="block-list-link" href="/categories/NLP/">NLP</a><span class="block-list-count">29</span></li><li class="block-list-item"><a class="block-list-link" href="/categories/Math/">Math</a><span class="block-list-count">5</span></li><li class="block-list-item"><a class="block-list-link" href="/categories/MachineLearning/">MachineLearning</a><span class="block-list-count">8</span></li><li class="block-list-item"><a class="block-list-link" href="/categories/Life/">Life</a><span class="block-list-count">6</span></li></ul></div><div class="sidebar__block"><h3 class="block__title">最新文章</h3><ul class="block-list latest-post-list"><li class="latest-post-item"><a href="/2022/09/08/tokenizers/" title="tokenizers 总结"><div class="item__cover"><img src="/2022/09/08/tokenizers/cannot_code.PNG" alt="tokenizers 总结"></div><div class="item__info"><h3 class="item__title">tokenizers 总结</h3><span class="item__text">2022-09-08</span></div></a></li><li class="latest-post-item"><a href="/2022/07/06/horovod-multi-nodes/" title="训练加速篇（3）horovod之多机多卡"><div class="item__cover"><img src="/2022/07/06/horovod-multi-nodes/cat.JPG" alt="训练加速篇（3）horovod之多机多卡"></div><div class="item__info"><h3 class="item__title">训练加速篇（3）horovod之多机多卡</h3><span class="item__text">2022-07-06</span></div></a></li><li class="latest-post-item"><a href="/2022/07/05/nohup-debug/" title="nohup踩坑记"><div class="item__cover"><img src="/2022/07/05/nohup-debug/dl.jpeg" alt="nohup踩坑记"></div><div class="item__info"><h3 class="item__title">nohup踩坑记</h3><span class="item__text">2022-07-05</span></div></a></li><li class="latest-post-item"><a href="/2022/05/25/horovod/" title="训练加速篇（2）-horovod"><div class="item__cover"><img src="/2022/05/25/horovod/cat.JPG" alt="训练加速篇（2）-horovod"></div><div class="item__info"><h3 class="item__title">训练加速篇（2）-horovod</h3><span class="item__text">2022-05-25</span></div></a></li></ul></div><div class="sidebar__block"><h3 class="block__title">文章标签</h3><ul class="block-list tag-list clearfix"><li class="tag-item"><a class="tag-link" href="/tags/BERT/">BERT</a></li><li class="tag-item"><a class="tag-link" href="/tags/BPE/">BPE</a></li><li class="tag-item"><a class="tag-link" href="/tags/Bagging/">Bagging</a></li><li class="tag-item"><a class="tag-link" href="/tags/Boosting/">Boosting</a></li><li class="tag-item"><a class="tag-link" href="/tags/CCF/">CCF</a></li><li class="tag-item"><a class="tag-link" href="/tags/CRF/">CRF</a></li><li class="tag-item"><a class="tag-link" href="/tags/CUDA/">CUDA</a></li><li class="tag-item"><a class="tag-link" href="/tags/Classification/">Classification</a></li><li class="tag-item"><a class="tag-link" href="/tags/Competition/">Competition</a></li><li class="tag-item"><a class="tag-link" href="/tags/Deep-Learning/">Deep Learning</a></li><li class="tag-item"><a class="tag-link" href="/tags/Distillation/">Distillation</a></li><li class="tag-item"><a class="tag-link" href="/tags/EDA/">EDA</a></li><li class="tag-item"><a class="tag-link" href="/tags/FastBERT/">FastBERT</a></li><li class="tag-item"><a class="tag-link" href="/tags/Few-shot/">Few-shot</a></li><li class="tag-item"><a class="tag-link" href="/tags/Game/">Game</a></li><li class="tag-item"><a class="tag-link" href="/tags/Glove/">Glove</a></li><li class="tag-item"><a class="tag-link" href="/tags/Hexo/">Hexo</a></li><li class="tag-item"><a class="tag-link" href="/tags/LR/">LR</a></li><li class="tag-item"><a class="tag-link" href="/tags/Language-Model/">Language Model</a></li><li class="tag-item"><a class="tag-link" href="/tags/Loss/">Loss</a></li><li class="tag-item"><a class="tag-link" href="/tags/MarkDown/">MarkDown</a></li><li class="tag-item"><a class="tag-link" href="/tags/Math/">Math</a></li><li class="tag-item"><a class="tag-link" href="/tags/Matrix/">Matrix</a></li><li class="tag-item"><a class="tag-link" href="/tags/NLG/">NLG</a></li><li class="tag-item"><a class="tag-link" href="/tags/Optimizer/">Optimizer</a></li><li class="tag-item"><a class="tag-link" href="/tags/Python/">Python</a></li><li class="tag-item"><a class="tag-link" href="/tags/QA/">QA</a></li><li class="tag-item"><a class="tag-link" href="/tags/R-Drop/">R-Drop</a></li><li class="tag-item"><a class="tag-link" href="/tags/Random-Forest/">Random Forest</a></li><li class="tag-item"><a class="tag-link" href="/tags/Segmentation/">Segmentation</a></li><li class="tag-item"><a class="tag-link" href="/tags/SimCSE/">SimCSE</a></li><li class="tag-item"><a class="tag-link" href="/tags/Statistics/">Statistics</a></li><li class="tag-item"><a class="tag-link" href="/tags/Survey/">Survey</a></li><li class="tag-item"><a class="tag-link" href="/tags/T5/">T5</a></li><li class="tag-item"><a class="tag-link" href="/tags/UniLM/">UniLM</a></li><li class="tag-item"><a class="tag-link" href="/tags/Unigram/">Unigram</a></li><li class="tag-item"><a class="tag-link" href="/tags/WordPiece/">WordPiece</a></li><li class="tag-item"><a class="tag-link" href="/tags/Words-Distance/">Words Distance</a></li><li class="tag-item"><a class="tag-link" href="/tags/Xgboost/">Xgboost</a></li><li class="tag-item"><a class="tag-link" href="/tags/debug/">debug</a></li><li class="tag-item"><a class="tag-link" href="/tags/faster-decoder/">faster decoder</a></li><li class="tag-item"><a class="tag-link" href="/tags/horovod/">horovod</a></li><li class="tag-item"><a class="tag-link" href="/tags/multi-task/">multi-task</a></li><li class="tag-item"><a class="tag-link" href="/tags/nohup/">nohup</a></li><li class="tag-item"><a class="tag-link" href="/tags/npm/">npm</a></li><li class="tag-item"><a class="tag-link" href="/tags/simbert/">simbert</a></li><li class="tag-item"><a class="tag-link" href="/tags/skipgram/">skipgram</a></li><li class="tag-item"><a class="tag-link" href="/tags/speed-up/">speed-up</a></li><li class="tag-item"><a class="tag-link" href="/tags/swift/">swift</a></li><li class="tag-item"><a class="tag-link" href="/tags/tensorflow-gpu/">tensorflow-gpu</a></li><li class="tag-item"><a class="tag-link" href="/tags/word2vec/">word2vec</a></li><li class="tag-item"><a class="tag-link" href="/tags/信息熵/">信息熵</a></li><li class="tag-item"><a class="tag-link" href="/tags/新词发现/">新词发现</a></li><li class="tag-item"><a class="tag-link" href="/tags/样本不均衡/">样本不均衡</a></li><li class="tag-item"><a class="tag-link" href="/tags/装机/">装机</a></li><li class="tag-item"><a class="tag-link" href="/tags/领域词挖掘/">领域词挖掘</a></li></ul></div></aside></main><footer class="page__footer"><section class="footer__top"><div class="page__container footer__container"><div class="footer-top__item footer-top__item--2"><h3 class="item__title">关于</h3><div class="item__content"><p class="item__text">本站是基于 Hexo 搭建的静态资源博客，主要用于分享日常学习、生活及工作的一些心得总结。</p><ul class="footer__contact-info"><li class="contact-info__item"><i class="iconfont icon-address"></i> <span>Beijing, China</span></li><li class="contact-info__item"><i class="iconfont icon-email2"></i> <span>xv44586@gmail.com</span></li></ul></div></div><div class="footer-top__item"><h3 class="item__title">友情链接</h3><div class="item__content"><ul class="footer-top__list"><li class="list-item"><a href="http://www.matrix67.com/" title="Matrix67" target="_blank">Matrix67</a></li><li class="list-item"><a href="https://spaces.ac.cn/" title="Spaces" target="_blank">科学空间</a></li></ul></div></div></div></section><section class="footer__bottom"><div class="page__container footer__container"><p class="footer__copyright">© <a href="https://github.com/Mrminfive/hexo-theme-skapp" target="_blank">Skapp</a> 2017 powered by <a href="http://hexo.io/" target="_blank">Hexo</a>, made by <a href="https://github.com/Mrminfive" target="_blank">minfive</a>. modified by <a href="https://github.com/xv44586" target="_blank">小蛋子</a></p><ul class="footer__social-network clearfix"><li class="social-network__item"><a href="https://github.com/xv44586" target="_blank" title="github"><i class="iconfont icon-github"></i></a></li><li class="social-network__item"><a href="xv44586@gmail.com" target="_blank" title="email"><i class="iconfont icon-email"></i></a></li></ul></div></section></footer><div id="back-top" class="back-top back-top--hidden js-hidden"><i class="iconfont icon-top"></i></div></div><script src="/js/common.js"></script><script src="/js/page/post.js"></script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
            tex2jax: {
                inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
                processEscapes: true,
                skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
            }
            });</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
            var all = MathJax.Hub.getAllJax(), i;
                for (i=0; i < all.length; i += 1) {
                all[i].SourceElement().parentNode.className += ' has-jax';
                }
            });</script><script type="text/javascript" src="//cdn.jsdelivr.net/npm/mathjax@2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script></body></html>