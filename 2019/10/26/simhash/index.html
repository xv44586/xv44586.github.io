<!DOCTYPE html><html lang="zh-cn"><head><meta name="generator" content="Hexo 3.9.0"><meta charset="utf-8"><title>文档查重之SimHash算法 | 小蛋子</title><meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no"><meta name="format-detection" content="telephone=no"><meta name="author" content="[object Object]"><meta name="designer" content="minfive"><meta name="keywords" content="NLP, 机器学习, 深度学习, Python, Backend"><meta name="description" content="NLP | Machine Learning | Developer"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black"><meta name="format-detection" content="telephone=yes"><meta name="mobile-web-app-capable" content="yes"><meta name="robots" content="all"><link rel="canonical" href="https://xv44586.github.io/2019/10/26/simhash/index.html"><link rel="icon" type="image/png" href="/img/favicon.ico" sizes="32x32"><meta name="google-site-verification" content="tbK2z0UTHcAWdqNCgEwykaDA9vvvXnN4ZSp_LFbAbDc"><meta name="baidu-site-verification" content="NBO0j1DAOy"><meta name="baidu-site-verification" content="ulZR80nUkv"><link rel="stylesheet" href="/scss/base/index.css"><link rel="alternate" href="/atom.xml" title="小蛋子"><script>var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?b1d2a1d2b250300950a8ffb5caa20818";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><link rel="stylesheet" href="/scss/views/page/post.css"><link rel="alternate" href="/atom.xml" title="小蛋子" type="application/atom+xml"></head><body ontouchstart><div id="page-loading" class="page page-loading" style="background-image:url(/other/loading.gif)"></div><div id="page" class="page js-hidden"><header class="page__small-header page__header--small"><nav class="page__navbar"><div class="page__container navbar-container"><a class="page__logo" href="/" title="小蛋子" alt="小蛋子"><img src="/img/lg.png" alt="小蛋子"></a><nav class="page__nav"><ul class="nav__list clearfix"><li class="nav__item"><a href="/" alt="首页" title="首页">首页</a></li><li class="nav__item"><a href="/archives" alt="归档" title="归档">归档</a></li><li class="nav__item"><a href="/about" alt="关于" title="关于">关于</a></li></ul></nav><button class="page__menu-btn" type="button"><i class="iconfont icon-menu"></i></button></div></nav></header><main class="page__container page__main"><div class="page__content"><article class="page__post"><div class="post__cover"><img src="/2019/10/26/simhash/snow.jpeg" alt="文档查重之SimHash算法"></div><header class="post__info"><h1 class="post__title">文档查重之SimHash算法</h1><div class="post__mark"><div class="mark__block"><i class="mark__icon iconfont icon-write"></i><ul class="mark__list clearfix"><li class="mark__item"><a href="https://github.com/xv44586">小蛋子</a></li></ul></div><div class="mark__block"><i class="mark__icon iconfont icon-time"></i><ul class="mark__list clearfix"><li class="mark__item"><span>2019-10-26</span></li></ul></div><div class="mark__block"><i class="mark__icon iconfont icon-tab"></i><ul class="mark__list clearfix"><li class="mark__item"><a href="/tags/Words-Distance/">Words Distance</a></li></ul></div><div class="mark__block"><i class="mark__icon iconfont icon-eye"></i><ul class="mark__list clearfix"><li id="busuanzi_container_page_pv" class="mark__item"><span id="busuanzi_value_page_pv"></span>次</li></ul></div></div></header><div class="post__content"><div class="toc"><ul><li><a href="#simhash">SimHash</a></li><li><a href="#guan-yu-tou-tu">关于头图</a></li></ul></div><h1><span id="simhash">SimHash</span><a href="#simhash" class="header-anchor"></a></h1><p>不同网站间相互转载内容的情况非常常见，即使同一网站，不同的URL地址也可能对应相同内容，只是以不同的形式显示出来（不同的UI），而我们在爬取大量内容时，除了靠URL去重外，还需按文档内容排重<br>指纹可以判断人的身份，比如侦探把从犯罪现场采集的指纹与指纹库中的指纹做个对比，就能确定犯罪嫌疑人的身份。类似的，我们用一个文档的语义指纹来代表文档的语义，如采用一个二进制数组来代表。从而判断文档之间的相似性转化为判断两个语义指纹之间的相似性。<br>SimHash是Google在2007年发表的论文《Detecting Near-Duplicates for Web Crawling 》中提到的一种指纹生成算法或者叫指纹提取算法，被Google广泛应用在亿级的网页去重的Job中，作为locality sensitive hash（局部敏感哈希）的一种，其主要思想是降维，即将一篇若干数量的文本内容用一个长度较短的数组来表示，而这个数组与这篇文档的主要的特征所对应。如在没有犯罪嫌疑人的身份证和指纹时，一个人的特征有无数多个，而我们可以通过调查犯罪嫌疑人的姓名，性别，出生日期，身高，体重，当天穿的衣服，外貌等一些主要特征来甄别嫌疑人的身份。simhash也是将复杂的特征，降维来简化。<br>SimHash计算过程：<br><img src="/2019/10/26/simhash/sim.png" alt="simhash计算流程"></p><ul><li>1.对文档提取特征及特征对应的权重</li><li>2.对特征进行hash，生成对应的hash值</li><li>3.hash值加权：对特征hash值的每一位做循环处理：如果该位值为1，则用weight代替，否则，用-weight代替</li><li>4.求和：将特征hash加权后的结果，按位求和，然后将结果按位二值化：大于0则为1，否则为0，即得到最后的SimHash值。</li></ul><p>SimHash的计算依据是要比较的对象的特征，对于结构化的记录，可以按列提取特征；对于非结构化的文档，特征可以用全文提取topk关键词、标题、最长的几句话、每段的首句、尾句等。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> jieba.analyse <span class="keyword">as</span> analyse</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SimHash</span><span class="params">(object)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, content, topK=<span class="number">50</span>)</span>:</span></span><br><span class="line"></span><br><span class="line">        self.topK = topK</span><br><span class="line"></span><br><span class="line">        self.simhash = self.getSimHash(content)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getSimHash</span><span class="params">(self, content)</span>:</span></span><br><span class="line"></span><br><span class="line">        seg = jieba.cut(content)</span><br><span class="line"></span><br><span class="line"><span class="comment">#        jieba.analyse.set_stop_words('stopword.txt')</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">#topk words and it's tf/idf</span></span><br><span class="line"></span><br><span class="line">        keyWords = jieba.analyse.extract_tags(</span><br><span class="line"></span><br><span class="line">            <span class="string">'|'</span>.join(seg), topK=self.topK, withWeight=<span class="literal">True</span>, allowPOS=())</span><br><span class="line"></span><br><span class="line"><span class="comment">#        print(keyWords)</span></span><br><span class="line"></span><br><span class="line">        word_list = []</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> feature, weight <span class="keyword">in</span> keyWords:</span><br><span class="line"></span><br><span class="line">            feature = self.string_hash(feature)</span><br><span class="line"></span><br><span class="line">            temp = []</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> feature:</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> i == <span class="string">'1'</span>:</span><br><span class="line"></span><br><span class="line">                    temp.append(weight)</span><br><span class="line"></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line"></span><br><span class="line">                    temp.append(-weight)</span><br><span class="line"></span><br><span class="line">            word_list.append(temp)</span><br><span class="line"></span><br><span class="line">        hashSum = np.sum(np.array(word_list), axis=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">        simhash = <span class="string">''</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> code <span class="keyword">in</span> hashSum:</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> code &gt; <span class="number">0</span>:</span><br><span class="line"></span><br><span class="line">                simhash += <span class="string">'1'</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line"></span><br><span class="line">                simhash += <span class="string">'0'</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> simhash</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">string_hash</span><span class="params">(self,source)</span>:</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> source == <span class="string">""</span>:</span><br><span class="line"></span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line"></span><br><span class="line">            x = ord(source[<span class="number">0</span>]) &lt;&lt; <span class="number">7</span></span><br><span class="line"></span><br><span class="line">            m = <span class="number">1000003</span></span><br><span class="line"></span><br><span class="line">            mask = <span class="number">2</span> ** <span class="number">128</span> - <span class="number">1</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> c <span class="keyword">in</span> source:</span><br><span class="line"></span><br><span class="line">                x = ((x * m) ^ ord(c)) &amp; mask</span><br><span class="line"></span><br><span class="line">            x ^= len(source)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> x == <span class="number">-1</span>:</span><br><span class="line"></span><br><span class="line">                x = <span class="number">-2</span></span><br><span class="line"></span><br><span class="line">            x = bin(x).replace(<span class="string">'0b'</span>, <span class="string">''</span>).zfill(<span class="number">64</span>)[<span class="number">-64</span>:]</span><br><span class="line"></span><br><span class="line"><span class="comment">#            print(source,x)</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><p><strong>海明距离</strong></p><p>得到文档的SimHash值后，我们还需要判断两个文档是否相似。对相同长度的数字序列，我们采用海明距离来衡量其相似性。海明距离是指两个码字对应比特位（数字序列对应位置）不同的比特位个数。如1011101和1001001的第三位和第五位有差别，所以对应的海明距离为2。<br>计算两个数的海明距离时，我们先把两个数按位异或（XOR），然后计算结果中1的个数，结果就是海明距离。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">hamDis</span><span class="params">(l1, l2)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#异或</span></span><br><span class="line"></span><br><span class="line">    lxor = int(l1,<span class="number">2</span>) ^ int(l2,<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">    c = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#计算异或结果1的个数</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span>(lxor):</span><br><span class="line"></span><br><span class="line">        lxor &amp;= lxor<span class="number">-1</span></span><br><span class="line"></span><br><span class="line">        c += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> c</span><br></pre></td></tr></table></figure><p>把文档转化成SimHash后，文档的排重就变成了海明距离计算问题：给出一个f位的语义指纹集合F和一个语义指纹fg，找出F中是否存在与fg只有k位差异的语义指纹。<br>当k值很小而要找的语义指纹集合中的元素不多时，可以用逐次探查法：先把所有和当前指纹差k位的指纹扩展出来，然后用折半查找法在排好序的指纹集合中查找；<br>如果是面对的是海量的数据，且动态的增加，逐次探查法的效率将越来越慢。当k值较小，如不大于3时，我们使用一种快速方法。首先，我们将64位分成4份，当k为3时，则有一份中两者相等。<br><img src="/2019/10/26/simhash/match.png" alt><br>所以我们在存储时，将数据扩展为4份，每份以其中16位为k，剩余的部分为v，查找时精确匹配这16位。<br><img src="/2019/10/26/simhash/search.png" alt><br>除此之外，对于一个已经排序的容量为$2^d$的f位指纹集合，由于指纹集合中有很多的位组合存在，所以高d位只有少量重复存在，所以在搜索时，也可以找出高d位与当前指纹相同的集合f‘，缩小查找份范围。</p><p>Simhash算法对长文本500字+比较适用，短文本可能偏差较大，最后使用海明距离，求相似，在google的论文给出的数据中，64位的签名，在海明距离为3的情况下，可认为两篇文档是相似的或者是重复的，当然这个值只是参考值，针对自己的应用可以自测取值。</p><h1><span id="guan-yu-tou-tu">关于头图</span><a href="#guan-yu-tou-tu" class="header-anchor"></a></h1><p>摄于河南老家冬雪</p><div class="post__prevs"><div class="post__prev"><a href="/2019/10/22/cutwords/" title="分词算法综述"><i class="iconfont icon-prev"></i>分词算法综述</a></div><div class="post__prev post__prev--right"><a href="/2019/11/24/tm-1111/" title="天猫双十一销售额相关思考">天猫双十一销售额相关思考<i class="iconfont icon-next"></i></a></div></div></div></article></div><aside class="page__sidebar"><form id="page-search-from" class="page__search-from" action="/search/"><label class="search-form__item"><input class="input" type="text" name="search" placeholder="Search..."> <i class="iconfont icon-search"></i></label></form><div class="sidebar__block"><h3 class="block__title">简介</h3><p class="block__text">NLP | Machine Learning | Developer</p></div><div class="sidebar__block"><h3 class="block__title">文章分类</h3><ul class="block-list"><li class="block-list-item"><a class="block-list-link" href="/categories/Programming/">Programming</a><span class="block-list-count">3</span></li><li class="block-list-item"><a class="block-list-link" href="/categories/NLP/">NLP</a><span class="block-list-count">16</span></li><li class="block-list-item"><a class="block-list-link" href="/categories/Math/">Math</a><span class="block-list-count">4</span></li><li class="block-list-item"><a class="block-list-link" href="/categories/MachineLearning/">MachineLearning</a><span class="block-list-count">7</span></li><li class="block-list-item"><a class="block-list-link" href="/categories/Life/">Life</a><span class="block-list-count">5</span></li></ul></div><div class="sidebar__block"><h3 class="block__title">最新文章</h3><ul class="block-list latest-post-list"><li class="latest-post-item"><a href="/2020/10/25/adabelief/" title="AdaBelief-更稳定的优化器"><div class="item__cover"><img src="/2020/10/25/adabelief/opt.jpg" alt="AdaBelief-更稳定的优化器"></div><div class="item__info"><h3 class="item__title">AdaBelief-更稳定的优化器</h3><span class="item__text">2020-10-25</span></div></a></li><li class="latest-post-item"><a href="/2020/10/19/triangle/" title="一切三段成三角形"><div class="item__cover"><img src="/2020/10/19/triangle/triangle.png" alt="一切三段成三角形"></div><div class="item__info"><h3 class="item__title">一切三段成三角形</h3><span class="item__text">2020-10-19</span></div></a></li><li class="latest-post-item"><a href="/2020/10/14/focal-loss/" title="样本不均衡之难易不均衡"><div class="item__cover"><img src="/2020/10/14/focal-loss/gn.jpeg" alt="样本不均衡之难易不均衡"></div><div class="item__info"><h3 class="item__title">样本不均衡之难易不均衡</h3><span class="item__text">2020-10-14</span></div></a></li><li class="latest-post-item"><a href="/2020/09/30/location/" title="年轻人的第一个swift：ios 模拟定位打卡"><div class="item__cover"><img src="/2020/09/30/location/s.jpeg" alt="年轻人的第一个swift：ios 模拟定位打卡"></div><div class="item__info"><h3 class="item__title">年轻人的第一个swift：ios 模拟定位打卡</h3><span class="item__text">2020-09-30</span></div></a></li></ul></div><div class="sidebar__block"><h3 class="block__title">文章标签</h3><ul class="block-list tag-list clearfix"><li class="tag-item"><a class="tag-link" href="/tags/BERT/">BERT</a></li><li class="tag-item"><a class="tag-link" href="/tags/Bagging/">Bagging</a></li><li class="tag-item"><a class="tag-link" href="/tags/Boosting/">Boosting</a></li><li class="tag-item"><a class="tag-link" href="/tags/CRF/">CRF</a></li><li class="tag-item"><a class="tag-link" href="/tags/CUDA/">CUDA</a></li><li class="tag-item"><a class="tag-link" href="/tags/Classification/">Classification</a></li><li class="tag-item"><a class="tag-link" href="/tags/Deep-Learning/">Deep Learning</a></li><li class="tag-item"><a class="tag-link" href="/tags/Distillation/">Distillation</a></li><li class="tag-item"><a class="tag-link" href="/tags/FastBERT/">FastBERT</a></li><li class="tag-item"><a class="tag-link" href="/tags/Game/">Game</a></li><li class="tag-item"><a class="tag-link" href="/tags/Glove/">Glove</a></li><li class="tag-item"><a class="tag-link" href="/tags/Hexo/">Hexo</a></li><li class="tag-item"><a class="tag-link" href="/tags/LR/">LR</a></li><li class="tag-item"><a class="tag-link" href="/tags/Language-Model/">Language Model</a></li><li class="tag-item"><a class="tag-link" href="/tags/Loss/">Loss</a></li><li class="tag-item"><a class="tag-link" href="/tags/MarkDown/">MarkDown</a></li><li class="tag-item"><a class="tag-link" href="/tags/NLG/">NLG</a></li><li class="tag-item"><a class="tag-link" href="/tags/Optimizer/">Optimizer</a></li><li class="tag-item"><a class="tag-link" href="/tags/Python/">Python</a></li><li class="tag-item"><a class="tag-link" href="/tags/QA/">QA</a></li><li class="tag-item"><a class="tag-link" href="/tags/Random-Forest/">Random Forest</a></li><li class="tag-item"><a class="tag-link" href="/tags/Segmentation/">Segmentation</a></li><li class="tag-item"><a class="tag-link" href="/tags/Statistics/">Statistics</a></li><li class="tag-item"><a class="tag-link" href="/tags/Survey/">Survey</a></li><li class="tag-item"><a class="tag-link" href="/tags/UniLM/">UniLM</a></li><li class="tag-item"><a class="tag-link" href="/tags/Words-Distance/">Words Distance</a></li><li class="tag-item"><a class="tag-link" href="/tags/Xgboost/">Xgboost</a></li><li class="tag-item"><a class="tag-link" href="/tags/npm/">npm</a></li><li class="tag-item"><a class="tag-link" href="/tags/skipgram/">skipgram</a></li><li class="tag-item"><a class="tag-link" href="/tags/swift/">swift</a></li><li class="tag-item"><a class="tag-link" href="/tags/tensorflow-gpu/">tensorflow-gpu</a></li><li class="tag-item"><a class="tag-link" href="/tags/word2vec/">word2vec</a></li><li class="tag-item"><a class="tag-link" href="/tags/信息熵/">信息熵</a></li><li class="tag-item"><a class="tag-link" href="/tags/新词发现/">新词发现</a></li><li class="tag-item"><a class="tag-link" href="/tags/样本不均衡/">样本不均衡</a></li><li class="tag-item"><a class="tag-link" href="/tags/装机/">装机</a></li><li class="tag-item"><a class="tag-link" href="/tags/领域词挖掘/">领域词挖掘</a></li></ul></div></aside></main><footer class="page__footer"><section class="footer__top"><div class="page__container footer__container"><div class="footer-top__item footer-top__item--2"><h3 class="item__title">关于</h3><div class="item__content"><p class="item__text">本站是基于 Hexo 搭建的静态资源博客，主要用于分享日常学习、生活及工作的一些心得总结。</p><ul class="footer__contact-info"><li class="contact-info__item"><i class="iconfont icon-address"></i> <span>Beijing, China</span></li><li class="contact-info__item"><i class="iconfont icon-email2"></i> <span>xv44586@gmail.com</span></li></ul></div></div><div class="footer-top__item"><h3 class="item__title">友情链接</h3><div class="item__content"><ul class="footer-top__list"><li class="list-item"><a href="http://www.matrix67.com/" title="Matrix67" target="_blank">Matrix67</a></li><li class="list-item"><a href="https://spaces.ac.cn/" title="Spaces" target="_blank">科学空间</a></li></ul></div></div></div></section><section class="footer__bottom"><div class="page__container footer__container"><p class="footer__copyright">© <a href="https://github.com/Mrminfive/hexo-theme-skapp" target="_blank">Skapp</a> 2017 powered by <a href="http://hexo.io/" target="_blank">Hexo</a>, made by <a href="https://github.com/Mrminfive" target="_blank">minfive</a>. modified by <a href="https://github.com/xv44586" target="_blank">小蛋子</a></p><ul class="footer__social-network clearfix"><li class="social-network__item"><a href="https://github.com/xv44586" target="_blank" title="github"><i class="iconfont icon-github"></i></a></li><li class="social-network__item"><a href="xv44586@gmail.com" target="_blank" title="email"><i class="iconfont icon-email"></i></a></li></ul></div></section></footer><div id="back-top" class="back-top back-top--hidden js-hidden"><i class="iconfont icon-top"></i></div></div><script src="/js/common.js"></script><script src="/js/page/post.js"></script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
            tex2jax: {
                inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
                processEscapes: true,
                skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
            }
            });</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
            var all = MathJax.Hub.getAllJax(), i;
                for (i=0; i < all.length; i += 1) {
                all[i].SourceElement().parentNode.className += ' has-jax';
                }
            });</script><script type="text/javascript" src="//cdn.jsdelivr.net/npm/mathjax@2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script></body></html>