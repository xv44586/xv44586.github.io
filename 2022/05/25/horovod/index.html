<!DOCTYPE html><html lang="zh-cn"><head><meta name="generator" content="Hexo 3.9.0"><meta charset="utf-8"><title>训练加速篇（2）-horovod | 小蛋子</title><meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no"><meta name="format-detection" content="telephone=no"><meta name="author" content="[object Object]"><meta name="designer" content="minfive"><meta name="keywords" content="NLP, 机器学习, 深度学习, Python, Backend"><meta name="description" content="NLP | Machine Learning | Developer"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black"><meta name="format-detection" content="telephone=yes"><meta name="mobile-web-app-capable" content="yes"><meta name="robots" content="all"><link rel="canonical" href="https://xv44586.github.io/2022/05/25/horovod/index.html"><link rel="icon" type="image/png" href="/img/favicon.ico" sizes="32x32"><meta name="google-site-verification" content="tbK2z0UTHcAWdqNCgEwykaDA9vvvXnN4ZSp_LFbAbDc"><meta name="baidu-site-verification" content="NBO0j1DAOy"><meta name="baidu-site-verification" content="ulZR80nUkv"><link rel="stylesheet" href="/scss/base/index.css"><link rel="alternate" href="/atom.xml" title="小蛋子"><script>var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?b1d2a1d2b250300950a8ffb5caa20818";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><link rel="stylesheet" href="/scss/views/page/post.css"><link rel="alternate" href="/atom.xml" title="小蛋子" type="application/atom+xml"></head><body ontouchstart><div id="page-loading" class="page page-loading" style="background-image:url(/other/loading.gif)"></div><div id="page" class="page js-hidden"><header class="page__small-header page__header--small"><nav class="page__navbar"><div class="page__container navbar-container"><a class="page__logo" href="/" title="小蛋子" alt="小蛋子"><img src="/img/lg.png" alt="小蛋子"></a><nav class="page__nav"><ul class="nav__list clearfix"><li class="nav__item"><a href="/" alt="首页" title="首页">首页</a></li><li class="nav__item"><a href="/archives" alt="归档" title="归档">归档</a></li><li class="nav__item"><a href="/about" alt="关于" title="关于">关于</a></li></ul></nav><button class="page__menu-btn" type="button"><i class="iconfont icon-menu"></i></button></div></nav></header><main class="page__container page__main"><div class="page__content"><article class="page__post"><div class="post__cover"><img src="/2022/05/25/horovod/cat.JPG" alt="训练加速篇（2）-horovod"></div><header class="post__info"><h1 class="post__title">训练加速篇（2）-horovod</h1><div class="post__mark"><div class="mark__block"><i class="mark__icon iconfont icon-write"></i><ul class="mark__list clearfix"><li class="mark__item"><a href="https://github.com/xv44586">小蛋子</a></li></ul></div><div class="mark__block"><i class="mark__icon iconfont icon-time"></i><ul class="mark__list clearfix"><li class="mark__item"><span>2022-05-25</span></li></ul></div><div class="mark__block"><i class="mark__icon iconfont icon-tab"></i><ul class="mark__list clearfix"><li class="mark__item"><a href="/tags/speed-up/">Speed-Up</a></li><li class="mark__item"><a href="/tags/horovod/">Horovod</a></li></ul></div><div class="mark__block"><i class="mark__icon iconfont icon-eye"></i><ul class="mark__list clearfix"><li id="busuanzi_container_page_pv" class="mark__item"><span id="busuanzi_value_page_pv"></span>次</li></ul></div></div></header><div class="post__content"><div class="toc"><ul><li><a href="#horovod">horovod</a></li><li><a href="#da-huan-jing">搭环境</a><ul><li><a href="#docker">docker</a></li></ul></li><li><a href="#local">local</a><ul><li><a href="#nccl">NCCL</a><ul><li><a href="#yan-zheng-yi-xia">验证一下</a></li></ul></li><li><a href="#mpirun">mpirun</a></li><li><a href="#nvidia-tensorflow">nvidia-tensorflow</a></li><li><a href="#horovod-1">horovod</a></li></ul></li><li><a href="#huan-jing-zhong-cai-guo-de-keng">环境中踩过的坑</a><ul><li><a href="#nccl">nccl</a></li><li><a href="#horovod-2">horovod</a></li></ul></li><li><a href="#dai-ma-ceng-mian-xiu-gai">代码层面修改</a></li><li><a href="#run-code">run code</a></li><li><a href="#jia-su-xiao-guo">加速效果</a></li><li><a href="#guan-yu-tou-tu">关于头图</a></li></ul></div><h1><span id="horovod">horovod</span><a href="#horovod" class="header-anchor"></a></h1><p><a href="https://github.com/horovod/horovod" target="_blank" rel="noopener">horovod</a>是Uber 团队开发的分布式训练框架，他可以满足让你尽量少的修改代码即可将在单卡训练的脚本横行扩展为多卡并行训练，同时又兼顾训练的加速。目前支持tensorflow/keras/pytorch/mxnet.底层通信主要依赖<a href="https://github.com/NVIDIA/nccl" target="_blank" rel="noopener">NCCL</a>/<a href="https://github.com/facebookincubator/gloo" target="_blank" rel="noopener">Gloo</a>（测试后NCCL是最快的）,支持MPI（CPU 训练更快）。由于其训练加速效果比tensorflow 原生的distributedStrategy 快很多，所以在分布式训练时，推荐使用。<br>下面主要针对tensorflow1.x 下做分布式训练进行说明。</p><h1><span id="da-huan-jing">搭环境</span><a href="#da-huan-jing" class="header-anchor"></a></h1><p>环境主要依赖tensorflow1.x/horovod/nccl/mpi ，这里有两种方式搭环境：local/docker，下面分别介绍这两种环境的搭建及踩过的坑。</p><h2><span id="docker">docker</span><a href="#docker" class="header-anchor"></a></h2><p>由于谷歌官方的tensorflow1.x 不提供对A100/3090 及更新版本的显卡的支持，这里我们推荐使用nvidia 官方维护的<a href="https://github.com/NVIDIA/tensorflow" target="_blank" rel="noopener">nvidia-tensorflow</a>，其提供了对A100/3090 等显卡的支持。支持pip/conda安装，同时也提供了对应的docker 镜像。<br>在使用镜像时，首先在<a href="https://catalog.ngc.nvidia.com/orgs/nvidia/containers/tensorflow/tags" target="_blank" rel="noopener">ngc</a> 中寻找最新镜像并pull 下来。<br></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker pull nvcr.io/nvidia/tensorflow:22.04-tf1-py3</span><br></pre></td></tr></table></figure><p></p><p>在启动时，建议设置share memory 为单张显卡显存差不多大小，否则有可能由于默认share memory size 太小（64M）导致nccl 通信时资源不足被kill。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -itd --gpus all --net=host --privileged -v /data:/data --name horovod --shm-size=32g --<span class="built_in">ulimit</span> memlock=-1 --<span class="built_in">ulimit</span> stack=67108864 nvcr.io/nvidia/tensorflow:22.04-tf1-py3</span><br></pre></td></tr></table></figure><h1><span id="local">local</span><a href="#local" class="header-anchor"></a></h1><p>在本地搭环境，主要需要安装nvidia-tensorflow/horovod/nccl/mpi,此外，由于nvidia-tensorflow 只支持ubuntu20.04，对应的OS 也要调整。</p><h2><span id="nccl">NCCL</span><a href="#nccl" class="header-anchor"></a></h2><p>安装NCCL，注意版本，为了兼顾A100，推荐使用v2.8.3-1 这个版本。<br>ref:<a href="https://github.com/NVIDIA/nccl" target="_blank" rel="noopener">nccl</a><br></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 编译nccl</span></span><br><span class="line">git <span class="built_in">clone</span> https://github.com/NVIDIA/nccl.git</span><br><span class="line"><span class="built_in">cd</span> nccl &amp;&amp; git checkout v2.8.3-1</span><br><span class="line">make -j src.build</span><br><span class="line"></span><br><span class="line"><span class="comment"># 如果第一次安装，需要安装一下依赖</span></span><br><span class="line"><span class="comment"># Install tools to create debian packages</span></span><br><span class="line">sudo apt install build-essential devscripts debhelper fakeroot</span><br><span class="line"><span class="comment"># Build NCCL deb package</span></span><br><span class="line">make pkg.debian.build</span><br><span class="line">ls build/pkg/deb/</span><br><span class="line"></span><br><span class="line"><span class="comment"># install</span></span><br><span class="line">sudo make install</span><br></pre></td></tr></table></figure><p></p><h3><span id="yan-zheng-yi-xia">验证一下</span><a href="#yan-zheng-yi-xia" class="header-anchor"></a></h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 确认horovod链接的nccl版本路径正确</span></span><br><span class="line">ldd /usr/<span class="built_in">local</span>/lib/python3.8/dist-packages/horovod/tensorflow/mpi_lib.cpython-38-x86_64-linux-gnu.so</span><br></pre></td></tr></table></figure><h2><span id="mpirun">mpirun</span><a href="#mpirun" class="header-anchor"></a></h2><p>这里我们安装<a href="https://www.open-mpi.org/" target="_blank" rel="noopener">open-mpi</a></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 安装依赖</span></span><br><span class="line">apt-get install libnuma-dev</span><br><span class="line"></span><br><span class="line"><span class="comment"># mpirun</span></span><br><span class="line">wget https://download.open-mpi.org/release/open-mpi/v4.0/openmpi-4.0.5.tar.gz &amp;&amp; tar xvf openmpi-4.0.5.tar.gz</span><br><span class="line"><span class="built_in">cd</span> openmpi-4.0.5/ &amp;&amp; ./configure --prefix=/usr/<span class="built_in">local</span>/openmpi</span><br><span class="line">make -j$(nproc) &amp;&amp; sudo make install</span><br><span class="line"><span class="built_in">echo</span> <span class="string">'export PATH=/usr/local/openmpi/bin:$PATH'</span> &gt;&gt; ~/.bashrc</span><br><span class="line"><span class="built_in">echo</span> <span class="string">'export LD_LIBRARY_PATH=/usr/local/openmpi/lib:$LD_LIBRARY_PATH'</span> &gt;&gt; ~/.bashrc</span><br><span class="line"><span class="built_in">source</span> ~/.bashrc</span><br><span class="line">mpirun --version</span><br></pre></td></tr></table></figure><h2><span id="nvidia-tensorflow">nvidia-tensorflow</span><a href="#nvidia-tensorflow" class="header-anchor"></a></h2><p>这里直接用pip 安装或conda 安装都行：<br></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pip install nvidia-pyindex</span><br><span class="line">pip install nvidia-tensorflow</span><br></pre></td></tr></table></figure><p></p><h2><span id="horovod">horovod</span><a href="#horovod" class="header-anchor"></a></h2><p>horovod 在安装时，需要安装支持NCCL ，同时建议安装最新版本</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">// 安装horovod</span><br><span class="line">pip show horovod &amp;&amp; pip uninstall horovod</span><br><span class="line">HOROVOD_WITH_MPI=1 HOROVOD_WITHOUT_GLOO=1 HOROVOD_GPU_OPERATIONS=NCCL HOROVOD_WITH_TENSORFLOW=1 HOROVOD_NCCL_LINK=SHARED pip3 install horovod==0.24.3 --no-cache-dir</span><br></pre></td></tr></table></figure><p>验证一下horovod 使用了NCCL<br></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">horovodrun --check-build</span><br></pre></td></tr></table></figure><p></p><p>对应的NCCL 前面勾选则支持NCCL<br><img src="/2022/05/25/horovod/horovod-nccl.png" alt="horovod-nccl"></p><h1><span id="huan-jing-zhong-cai-guo-de-keng">环境中踩过的坑</span><a href="#huan-jing-zhong-cai-guo-de-keng" class="header-anchor"></a></h1><p>当前在A100 的机器上进行安装测试，其他型号显卡不一定也有同样的问题。</p><h2><span id="nccl">nccl</span><a href="#nccl" class="header-anchor"></a></h2><p>针对A100，ngc 的镜像中依然存在一个坑，其安装的nccl 版本太高，导致使用中会报错，对应的修复方式时对nccl 进行降级。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 下载编译nccl</span></span><br><span class="line">git <span class="built_in">clone</span> https://github.com/NVIDIA/nccl.git</span><br><span class="line"><span class="built_in">cd</span> nccl &amp;&amp; git checkout v2.8.3-1</span><br><span class="line">make -j src.build</span><br><span class="line"></span><br><span class="line"><span class="comment"># install</span></span><br><span class="line">sudo make install</span><br></pre></td></tr></table></figure><h2><span id="horovod">horovod</span><a href="#horovod" class="header-anchor"></a></h2><p>nvcr.io/nvidia/tensorflow:22.04-tf1-py3 中的horovod 不是最新版本的，在使用梯度累计时，老版本里<a href="https://github.com/horovod/horovod/issues/2806" target="_blank" rel="noopener">有问题</a>，对应的修复在新版本的horovd 中。所以，不管是否使用梯度累计，都建议升级一下horovod。PS: 升级时参考上面安装horovod 的办法 ，注意对NCCL 的支持。</p><h1><span id="dai-ma-ceng-mian-xiu-gai">代码层面修改</span><a href="#dai-ma-ceng-mian-xiu-gai" class="header-anchor"></a></h1><p>代码层面需要引入horvod，然后将optimizer 用horovod 进行wrap，此外，evaluate 相关的内容，尽量使用一个节点即可。<br>简单的demo：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line"><span class="comment"># import horovod</span></span><br><span class="line"><span class="keyword">import</span> horovod.tensorflow.keras <span class="keyword">as</span> hvd</span><br><span class="line"></span><br><span class="line"><span class="comment"># Horovod: initialize Horovod.</span></span><br><span class="line">hvd.init()</span><br><span class="line"><span class="comment"># Horovod: pin GPU to be used to process local rank (one GPU per process)</span></span><br><span class="line">config = tf.ConfigProto()</span><br><span class="line">config.gpu_options.allow_growth = <span class="literal">True</span></span><br><span class="line">config.gpu_options.visible_device_list = str(hvd.local_rank())</span><br><span class="line">K.set_session(tf.Session(config=config))</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line"><span class="comment"># wrap optimizer</span></span><br><span class="line">optimizer = hvd.DistributedOptimizer(optimizer,</span><br><span class="line">                                    backward_passes_per_step=grad_accum_steps,</span><br><span class="line">                                    average_aggregated_gradients=<span class="literal">True</span>,</span><br><span class="line">                                    sparse_as_dense=<span class="literal">True</span>)</span><br><span class="line">                          </span><br><span class="line">...</span><br><span class="line"><span class="comment"># callback</span></span><br><span class="line">callbacks = [</span><br><span class="line">            <span class="comment"># Horovod: broadcast initial variable states from rank 0 to all other processes.</span></span><br><span class="line">            <span class="comment"># This is necessary to ensure consistent initialization of all workers when</span></span><br><span class="line">            <span class="comment"># training is started with random weights or restored from a checkpoint.</span></span><br><span class="line">            hvd.callbacks.BroadcastGlobalVariablesCallback(<span class="number">0</span>),</span><br><span class="line">            </span><br><span class="line">        ]</span><br><span class="line"><span class="comment"># evaluate only on worker 0 to prevent other workers from corrupting them.  </span></span><br><span class="line"><span class="keyword">if</span> hvd.rank() == <span class="number">0</span>:</span><br><span class="line">    callbacks.append(evaluator)</span><br><span class="line"></span><br><span class="line">...</span><br></pre></td></tr></table></figure><p></p><p>部分限制：</p><ol><li>由于horovod 是让你在单卡的代码能够平滑的迁移到多卡上，所以这里的batch size 设置的是针对单卡的，但是整个优化过程是在多卡的结果上进行的，所以需要你手动调整自己的optimizer 以适应最终的batch size(batch_size_node * node_num)</li><li>需要使用梯度累计以达到更大batch size 的效果时，需要使用horovod 提供的方式，即：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">optimizer = hvd.DistributedOptimizer(optimizer,</span><br><span class="line">                                    backward_passes_per_step=grad_accum_steps,  <span class="comment"># 累计步数</span></span><br><span class="line">                                    average_aggregated_gradients=<span class="literal">True</span>,</span><br><span class="line">                                    sparse_as_dense=<span class="literal">True</span>                        <span class="comment"># 累计步数大于1必须设为True</span></span><br><span class="line">                                    )</span><br></pre></td></tr></table></figure></li></ol><p>而直接使用bert4keras 中的实现方式会报错，具体原因未知。</p><ol start="3"><li>callback 中只支持原生的keras 的操作，其他自定义的操作都会报错，如bert4keras 中的 <code>Transformer.save_weights_as_checkpoint()</code> 就不支持。</li></ol><h1><span id="run-code">run code</span><a href="#run-code" class="header-anchor"></a></h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mpirun -np 8 --allow-run-as-root -<span class="built_in">bind</span>-to none -map-by slot -x NCCL_DEBUG=INFO -mca btl_tcp_if_include eth0 -x LD_LIBRARY_PATH -x PATH python train_hvd.py</span><br></pre></td></tr></table></figure><p>其中 $-np$ 后面的参数是显卡数量，根据使用情况自行调整。</p><h1><span id="jia-su-xiao-guo">加速效果</span><a href="#jia-su-xiao-guo" class="header-anchor"></a></h1><p>对不同的OS 不同的环境进行了训练速度对比，效果如下：</p><table><thead><tr><th>local system</th><th style="text-align:center">run where</th><th style="text-align:center">distributed</th><th style="text-align:center">speed</th></tr></thead><tbody><tr><td>centos</td><td style="text-align:center">docker</td><td style="text-align:center">tf-mirroredStrategy</td><td style="text-align:center">520 ms/step</td></tr><tr><td>centos</td><td style="text-align:center">docker</td><td style="text-align:center">horovod-without-nccl</td><td style="text-align:center">440 ms/step</td></tr><tr><td>centos</td><td style="text-align:center">docker</td><td style="text-align:center">horovod-nccl</td><td style="text-align:center">285 ms/step</td></tr><tr><td>ubuntu20.04</td><td style="text-align:center">local</td><td style="text-align:center">tf-mirroredStrategy</td><td style="text-align:center">500 ms/step</td></tr><tr><td>ubuntu20.04</td><td style="text-align:center">local</td><td style="text-align:center">horovod nccl</td><td style="text-align:center">265 ms/step</td></tr><tr><td>ubuntu20.04</td><td style="text-align:center">docker</td><td style="text-align:center">tf-mirroredStrategy</td><td style="text-align:center">500 ms/step</td></tr><tr><td><code>ubuntu20.04</code></td><td style="text-align:center"><code>docker</code></td><td style="text-align:center"><code>horovod-nccl</code></td><td style="text-align:center"><code>240 ms/step</code></td></tr></tbody></table><p>可以看到，相对于tf 原生的单机多卡的MirroredStrategy，能提速一倍之多，加速相当惊人了。</p><h1><span id="guan-yu-tou-tu">关于头图</span><a href="#guan-yu-tou-tu" class="header-anchor"></a></h1><p>可爱猫猫</p><div class="content-footer-sponsor"><h1><span id="sponsor">Buy me a coffee</span></h1><p>如果觉得这篇文章不错，对你有帮助，欢迎打赏一杯蜜雪冰城。</p><img src="/img/sponsor.JPG" alt="logo" title="sponsor"></div><div class="post__prevs"><div class="post__prev"><a href="/2022/05/23/faster-decoder/" title="faster-decoder之 decoder解码加速"><i class="iconfont icon-prev"></i>faster-decoder之 decoder解码加速</a></div><div class="post__prev post__prev--right"><a href="/2022/07/05/nohup-debug/" title="nohup踩坑记">nohup踩坑记<i class="iconfont icon-next"></i></a></div></div></div></article><script src="https://giscus.app/client.js" data-repo="xv44586/giscus" data-repo-id="R_kgDOIC6Ipg" data-category="Announcements" data-category-id="DIC_kwDOIC6Ips4CRkmo" data-mapping="pathname" data-strict="0" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="bottom" data-theme="light" data-lang="zh-CN" crossorigin="anonymous" async></script></div><aside class="page__sidebar"><form id="page-search-from" class="page__search-from" action="/search/"><label class="search-form__item"><input class="input" type="text" name="search" placeholder="Search..."> <i class="iconfont icon-search"></i></label></form><div class="sidebar__block"><h3 class="block__title">简介</h3><p class="block__text">NLP | Machine Learning | Developer</p></div><div class="sidebar__block"><h3 class="block__title">文章分类</h3><ul class="block-list"><li class="block-list-item"><a class="block-list-link" href="/categories/Programming/">Programming</a><span class="block-list-count">4</span></li><li class="block-list-item"><a class="block-list-link" href="/categories/NLP/">NLP</a><span class="block-list-count">31</span></li><li class="block-list-item"><a class="block-list-link" href="/categories/Math/">Math</a><span class="block-list-count">5</span></li><li class="block-list-item"><a class="block-list-link" href="/categories/MachineLearning/">MachineLearning</a><span class="block-list-count">8</span></li><li class="block-list-item"><a class="block-list-link" href="/categories/Life/">Life</a><span class="block-list-count">6</span></li></ul></div><div class="sidebar__block"><h3 class="block__title">最新文章</h3><ul class="block-list latest-post-list"><li class="latest-post-item"><a href="/2023/02/01/fine-tuning-at-few-shot/" title="few-shot视角下的fine-tuning"><div class="item__cover"><img src="/2023/02/01/fine-tuning-at-few-shot/himalayas.JPG" alt="few-shot视角下的fine-tuning"></div><div class="item__info"><h3 class="item__title">few-shot视角下的fine-tuning</h3><span class="item__text">2023-02-01</span></div></a></li><li class="latest-post-item"><a href="/2023/01/09/zero-to-chatgpt/" title="From zero to ChatGPT"><div class="item__cover"><img src="/2023/01/09/zero-to-chatgpt/chatgpt-bg.jpeg" alt="From zero to ChatGPT"></div><div class="item__info"><h3 class="item__title">From zero to ChatGPT</h3><span class="item__text">2023-01-09</span></div></a></li><li class="latest-post-item"><a href="/2022/09/08/tokenizers/" title="tokenizers 总结"><div class="item__cover"><img src="/2022/09/08/tokenizers/cannot_code.PNG" alt="tokenizers 总结"></div><div class="item__info"><h3 class="item__title">tokenizers 总结</h3><span class="item__text">2022-09-08</span></div></a></li><li class="latest-post-item"><a href="/2022/07/06/horovod-multi-nodes/" title="训练加速篇（3）horovod之多机多卡"><div class="item__cover"><img src="/2022/07/06/horovod-multi-nodes/cat.JPG" alt="训练加速篇（3）horovod之多机多卡"></div><div class="item__info"><h3 class="item__title">训练加速篇（3）horovod之多机多卡</h3><span class="item__text">2022-07-06</span></div></a></li></ul></div><div class="sidebar__block"><h3 class="block__title">文章标签</h3><ul class="block-list tag-list clearfix"><li class="tag-item"><a class="tag-link" href="/tags/BERT/">BERT</a></li><li class="tag-item"><a class="tag-link" href="/tags/BPE/">BPE</a></li><li class="tag-item"><a class="tag-link" href="/tags/Bagging/">Bagging</a></li><li class="tag-item"><a class="tag-link" href="/tags/Boosting/">Boosting</a></li><li class="tag-item"><a class="tag-link" href="/tags/CCF/">CCF</a></li><li class="tag-item"><a class="tag-link" href="/tags/CRF/">CRF</a></li><li class="tag-item"><a class="tag-link" href="/tags/CUDA/">CUDA</a></li><li class="tag-item"><a class="tag-link" href="/tags/ChatGPT/">ChatGPT</a></li><li class="tag-item"><a class="tag-link" href="/tags/Classification/">Classification</a></li><li class="tag-item"><a class="tag-link" href="/tags/Competition/">Competition</a></li><li class="tag-item"><a class="tag-link" href="/tags/Deep-Learning/">Deep Learning</a></li><li class="tag-item"><a class="tag-link" href="/tags/Distillation/">Distillation</a></li><li class="tag-item"><a class="tag-link" href="/tags/EDA/">EDA</a></li><li class="tag-item"><a class="tag-link" href="/tags/FastBERT/">FastBERT</a></li><li class="tag-item"><a class="tag-link" href="/tags/Few-shot/">Few-shot</a></li><li class="tag-item"><a class="tag-link" href="/tags/GPT-3/">GPT-3</a></li><li class="tag-item"><a class="tag-link" href="/tags/Game/">Game</a></li><li class="tag-item"><a class="tag-link" href="/tags/Glove/">Glove</a></li><li class="tag-item"><a class="tag-link" href="/tags/Hexo/">Hexo</a></li><li class="tag-item"><a class="tag-link" href="/tags/In-context-learning/">In-context learning</a></li><li class="tag-item"><a class="tag-link" href="/tags/LLM/">LLM</a></li><li class="tag-item"><a class="tag-link" href="/tags/LR/">LR</a></li><li class="tag-item"><a class="tag-link" href="/tags/Language-Model/">Language Model</a></li><li class="tag-item"><a class="tag-link" href="/tags/Loss/">Loss</a></li><li class="tag-item"><a class="tag-link" href="/tags/MarkDown/">MarkDown</a></li><li class="tag-item"><a class="tag-link" href="/tags/Math/">Math</a></li><li class="tag-item"><a class="tag-link" href="/tags/Matrix/">Matrix</a></li><li class="tag-item"><a class="tag-link" href="/tags/NLG/">NLG</a></li><li class="tag-item"><a class="tag-link" href="/tags/Optimizer/">Optimizer</a></li><li class="tag-item"><a class="tag-link" href="/tags/Python/">Python</a></li><li class="tag-item"><a class="tag-link" href="/tags/QA/">QA</a></li><li class="tag-item"><a class="tag-link" href="/tags/R-Drop/">R-Drop</a></li><li class="tag-item"><a class="tag-link" href="/tags/Random-Forest/">Random Forest</a></li><li class="tag-item"><a class="tag-link" href="/tags/Segmentation/">Segmentation</a></li><li class="tag-item"><a class="tag-link" href="/tags/SimCSE/">SimCSE</a></li><li class="tag-item"><a class="tag-link" href="/tags/Statistics/">Statistics</a></li><li class="tag-item"><a class="tag-link" href="/tags/Survey/">Survey</a></li><li class="tag-item"><a class="tag-link" href="/tags/T5/">T5</a></li><li class="tag-item"><a class="tag-link" href="/tags/UniLM/">UniLM</a></li><li class="tag-item"><a class="tag-link" href="/tags/Unigram/">Unigram</a></li><li class="tag-item"><a class="tag-link" href="/tags/WordPiece/">WordPiece</a></li><li class="tag-item"><a class="tag-link" href="/tags/Words-Distance/">Words Distance</a></li><li class="tag-item"><a class="tag-link" href="/tags/Xgboost/">Xgboost</a></li><li class="tag-item"><a class="tag-link" href="/tags/debug/">debug</a></li><li class="tag-item"><a class="tag-link" href="/tags/faster-decoder/">faster decoder</a></li><li class="tag-item"><a class="tag-link" href="/tags/fine-tuning/">fine-tuning</a></li><li class="tag-item"><a class="tag-link" href="/tags/horovod/">horovod</a></li><li class="tag-item"><a class="tag-link" href="/tags/multi-task/">multi-task</a></li><li class="tag-item"><a class="tag-link" href="/tags/nohup/">nohup</a></li><li class="tag-item"><a class="tag-link" href="/tags/npm/">npm</a></li><li class="tag-item"><a class="tag-link" href="/tags/simbert/">simbert</a></li><li class="tag-item"><a class="tag-link" href="/tags/skipgram/">skipgram</a></li><li class="tag-item"><a class="tag-link" href="/tags/speed-up/">speed-up</a></li><li class="tag-item"><a class="tag-link" href="/tags/swift/">swift</a></li><li class="tag-item"><a class="tag-link" href="/tags/tensorflow-gpu/">tensorflow-gpu</a></li><li class="tag-item"><a class="tag-link" href="/tags/word2vec/">word2vec</a></li><li class="tag-item"><a class="tag-link" href="/tags/信息熵/">信息熵</a></li><li class="tag-item"><a class="tag-link" href="/tags/新词发现/">新词发现</a></li><li class="tag-item"><a class="tag-link" href="/tags/样本不均衡/">样本不均衡</a></li><li class="tag-item"><a class="tag-link" href="/tags/装机/">装机</a></li><li class="tag-item"><a class="tag-link" href="/tags/领域词挖掘/">领域词挖掘</a></li></ul></div></aside></main><footer class="page__footer"><section class="footer__top"><div class="page__container footer__container"><div class="footer-top__item footer-top__item--2"><h3 class="item__title">关于</h3><div class="item__content"><p class="item__text">本站是基于 Hexo 搭建的静态资源博客，主要用于分享日常学习、生活及工作的一些心得总结。</p><ul class="footer__contact-info"><li class="contact-info__item"><i class="iconfont icon-address"></i> <span>Beijing, China</span></li><li class="contact-info__item"><i class="iconfont icon-email2"></i> <span>xv44586@gmail.com</span></li></ul></div></div><div class="footer-top__item"><h3 class="item__title">友情链接</h3><div class="item__content"><ul class="footer-top__list"><li class="list-item"><a href="http://www.matrix67.com/" title="Matrix67" target="_blank">Matrix67</a></li><li class="list-item"><a href="https://spaces.ac.cn/" title="Spaces" target="_blank">科学空间</a></li></ul></div></div></div></section><section class="footer__bottom"><div class="page__container footer__container"><p class="footer__copyright">© <a href="https://github.com/Mrminfive/hexo-theme-skapp" target="_blank">Skapp</a> 2017 powered by <a href="http://hexo.io/" target="_blank">Hexo</a>, made by <a href="https://github.com/Mrminfive" target="_blank">minfive</a>. modified by <a href="https://github.com/xv44586" target="_blank">小蛋子</a></p><ul class="footer__social-network clearfix"><li class="social-network__item"><a href="https://github.com/xv44586" target="_blank" title="github"><i class="iconfont icon-github"></i></a></li><li class="social-network__item"><a href="xv44586@gmail.com" target="_blank" title="email"><i class="iconfont icon-email"></i></a></li></ul></div></section></footer><div id="back-top" class="back-top back-top--hidden js-hidden"><i class="iconfont icon-top"></i></div></div><script src="/js/common.js"></script><script src="/js/page/post.js"></script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
            tex2jax: {
                inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
                processEscapes: true,
                skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
            }
            });</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
            var all = MathJax.Hub.getAllJax(), i;
                for (i=0; i < all.length; i += 1) {
                all[i].SourceElement().parentNode.className += ' has-jax';
                }
            });</script><script type="text/javascript" src="//cdn.jsdelivr.net/npm/mathjax@2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script></body></html>