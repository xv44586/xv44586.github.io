<!DOCTYPE html><html lang="zh-cn"><head><meta name="generator" content="Hexo 3.9.0"><meta charset="utf-8"><title>ccf问答匹配比赛（下）：如何只用“bert”夺冠 | 小蛋子</title><meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no"><meta name="format-detection" content="telephone=no"><meta name="author" content="[object Object]"><meta name="designer" content="minfive"><meta name="keywords" content="NLP, 机器学习, 深度学习, Python, Backend"><meta name="description" content="NLP | Machine Learning | Developer"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black"><meta name="format-detection" content="telephone=yes"><meta name="mobile-web-app-capable" content="yes"><meta name="robots" content="all"><link rel="canonical" href="https://xv44586.github.io/2021/01/20/ccf-qa-2/index.html"><link rel="icon" type="image/png" href="/img/favicon.ico" sizes="32x32"><meta name="google-site-verification" content="tbK2z0UTHcAWdqNCgEwykaDA9vvvXnN4ZSp_LFbAbDc"><meta name="baidu-site-verification" content="NBO0j1DAOy"><meta name="baidu-site-verification" content="ulZR80nUkv"><link rel="stylesheet" href="/scss/base/index.css"><link rel="alternate" href="/atom.xml" title="小蛋子"><script>var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?b1d2a1d2b250300950a8ffb5caa20818";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><link rel="stylesheet" href="/scss/views/page/post.css"><link rel="alternate" href="/atom.xml" title="小蛋子" type="application/atom+xml"></head><body ontouchstart><div id="page-loading" class="page page-loading" style="background-image:url(/other/loading.gif)"></div><div id="page" class="page js-hidden"><header class="page__small-header page__header--small"><nav class="page__navbar"><div class="page__container navbar-container"><a class="page__logo" href="/" title="小蛋子" alt="小蛋子"><img src="/img/lg.png" alt="小蛋子"></a><nav class="page__nav"><ul class="nav__list clearfix"><li class="nav__item"><a href="/" alt="首页" title="首页">首页</a></li><li class="nav__item"><a href="/archives" alt="归档" title="归档">归档</a></li><li class="nav__item"><a href="/about" alt="关于" title="关于">关于</a></li></ul></nav><button class="page__menu-btn" type="button"><i class="iconfont icon-menu"></i></button></div></nav></header><main class="page__container page__main"><div class="page__content"><article class="page__post"><div class="post__cover"><img src="/2021/01/20/ccf-qa-2/head.png" alt="ccf问答匹配比赛（下）：如何只用“bert”夺冠"></div><header class="post__info"><h1 class="post__title">ccf问答匹配比赛（下）：如何只用“bert”夺冠</h1><div class="post__mark"><div class="mark__block"><i class="mark__icon iconfont icon-write"></i><ul class="mark__list clearfix"><li class="mark__item"><a href="https://github.com/xv44586">小蛋子</a></li></ul></div><div class="mark__block"><i class="mark__icon iconfont icon-time"></i><ul class="mark__list clearfix"><li class="mark__item"><span>2021-01-20</span></li></ul></div><div class="mark__block"><i class="mark__icon iconfont icon-tab"></i><ul class="mark__list clearfix"><li class="mark__item"><a href="/tags/QA/">QA</a></li><li class="mark__item"><a href="/tags/CCF/">CCF</a></li><li class="mark__item"><a href="/tags/Competition/">Competition</a></li></ul></div><div class="mark__block"><i class="mark__icon iconfont icon-eye"></i><ul class="mark__list clearfix"><li id="busuanzi_container_page_pv" class="mark__item"><span id="busuanzi_value_page_pv"></span>次</li></ul></div></div></header><div class="post__content"><div class="toc"><ul><li><a href="#qian-yan">前言</a><ul><li><a href="#sai-ti">赛题</a></li><li><a href="#qa-pair">QA pair</a></li><li><a href="#qa-point">QA Point</a></li><li><a href="#pattern-exploiting-training-pet">Pattern-Exploiting Training (PET)</a></li><li><a href="#concat">Concat</a></li><li><a href="#focal-loss">focal loss</a></li><li><a href="#dui-kang-xun-lian">对抗训练</a></li><li><a href="#post-training">post training</a></li></ul></li><li><a href="#post-training">Post Training</a><ul><li><a href="#mlm">MLM</a></li><li><a href="#nsp">nsp</a></li><li><a href="#model-adaptive">model-adaptive</a></li><li><a href="#geng-xin-ci-shu">更新次数</a></li><li><a href="#zui-zhong-jie-guo">最终结果</a></li></ul></li><li><a href="#rong-ru-zhi-shi">融入知识</a></li><li><a href="#dui-bi-xue-xi">对比学习</a><ul><li><a href="#fei-jian-du-dui-bi-xue-xi">非监督对比学习</a></li><li><a href="#jian-du-dui-bi-xue-xi">监督对比学习</a></li><li><a href="#shi-yan-jie-guo">实验结果</a></li></ul></li><li><a href="#shu-ju-zeng-qiang">数据增强</a><ul><li><a href="#eda">EDA</a></li><li><a href="#wei-biao-qian">伪标签</a></li><li><a href="#shi-yan-jie-guo-1">实验结果</a></li></ul></li><li><a href="#zi-zheng-liu">自蒸馏</a></li><li><a href="#shuffle-jie-ma">shuffle 解码</a></li><li><a href="#mo-xing-rong-he">模型融合</a></li><li><a href="#shi-yan-zong-jie">实验总结</a></li><li><a href="#bi-sai-jie-guo">比赛结果</a></li><li><a href="#dai-ma">代码</a></li><li><a href="#zui-hou">最后</a></li><li><a href="#guan-yu-tou-tu">关于头图</a></li></ul><p></p></div><br>ccf问答匹配比赛也结束了一段时间了，这篇算是一个下篇吧，总结一下后期优（夺）化（冠）的心路历程。标题中的“bert”指的是bert-base系列模型，包括bert/RoBERTa/NEZHA/MacBERT/ERNIE等，而取这个有点“标题党”的标题的主要原因，也是对答辩看到有些团队使用的bert+xgb这种“大力出奇迹”做法吐个槽。<p></p><h1><span id="qian-yan">前言</span><a href="#qian-yan" class="header-anchor"></a></h1><p>在<a href="https://xv44586.github.io/2020/11/08/ccf-qa/">上一篇</a>中,笔者对比赛做了简单说明，提出了四种baseline（QA Pair/QA Point/PET/Concat),并做了部分尝试（focal loss/对抗训练/梯度惩罚/kfold/post training),没看过的同学可以先看上篇，这里只简单再介绍一下：</p><h2><span id="sai-ti">赛题</span><a href="#sai-ti" class="header-anchor"></a></h2><p>本次赛题的任务是：给定IM交流片段，片段包含一个客户问题以及随后的经纪人若干IM消息，从这些随后的经纪人消息中找出一个是对客户问题的回答。</p><ul><li>数据示例<br>$$<br>\begin{array}{c|c|c|c|c}<br>\hline<br>\text{对话id} &amp; \text{客户问题} &amp; \text{经纪人回复id} &amp; \text{经纪人回复内容} &amp; \text{回复标签} \\<br>\hline<br>1 &amp; \text{您好，请问这个户型有什么优缺点} &amp; 1 &amp; \text{你是想看看这套房子是吗} &amp; 0 \\<br>\hline<br>&amp; &amp; \text{2} &amp; \text{在的} &amp;\text{0} \\<br>\hline<br>&amp; &amp; \text{3} &amp; \text{此房房型方正 得房率高 多层不带电梯4/6楼<br>} &amp;\text{1} \\<br>\hline<br>\end{array}<br>$$</li><li>评测标准</li></ul><p>f1：2 * (精度 * 召回) / (精度 + 召回)</p><h2><span id="qa-pair">QA pair</span><a href="#qa-pair" class="header-anchor"></a></h2><p>由于回答列表是不连续的，所以不考虑问答之间的顺序关系，将其拆分为query-answer pair，然后进行判断。<br><img src="/2021/01/20/ccf-qa-2/pair.png" alt="pair"></p><h2><span id="qa-point">QA Point</span><a href="#qa-point" class="header-anchor"></a></h2><p>考虑对话连贯性、相关性，将所有回答顺序拼接后再与问题拼接，组成query-answer list，模型对一个问题的所有答案进行预测。此外，我们还给模型增加了“大局观”，即新增一个任务来预测全局所有回答中是否存在label为 1 的回答。<br><img src="/2021/01/20/ccf-qa-2/point.png" alt="point"></p><h2><span id="pattern-exploiting-training-pet">Pattern-Exploiting Training (PET)</span><a href="#pattern-exploiting-training-pet" class="header-anchor"></a></h2><p>此方案通过增加一个pattern，将任务转换为MLM任务，然后通过pattern的得分来判断对应的类别。<br>如本次比赛可以添加一个前缀pattern：“间接回答问题”/ “直接回答问题”，分别对应label 0 / 1，pattern的得分只需看第一个位置中“间”/“直”两个token的概率谁高即可。对于unlabel data，可以不增加pattern 进行mlm任务，这也在一定程度增加了模型的泛化能力。此外，通过多个不同pattern进行融合也能进一步提高其性能。<br><img src="/2021/01/20/ccf-qa-2/pet.png" alt="pet"></p><h2><span id="concat">Concat</span><a href="#concat" class="header-anchor"></a></h2><p>由于bert 中不同的transformer 层提取到的语义粒度不同，而不同粒度的信息对分类来说起到的作用也可能不同，所以可以将所有粒度的语义信息拼接后作为特征进行分类。<br><img src="/2021/01/20/ccf-qa-2/concat.png" alt="concat"></p><h2><span id="focal-loss">focal loss</span><a href="#focal-loss" class="header-anchor"></a></h2><p>由于针对性回答与非针对性回答在数量上有不小差距，大约3:1，所以也想到尝试在loss上进行调节。<br>最终结果是没有多少提升，猜测样本不均衡的问题影响是非常小的，所以将Binary-Crossentropy训练后的模型在train data上进行了predict，并借鉴之前<a href="https://xv44586.github.io/2020/10/14/focal-loss/">focal loss</a>中的方式分析了一下，画出对应的难易样本分布。根据图形上的分布结果，也证实了之前的猜测。<br><img src="/2021/01/20/ccf-qa-2/focalloss.png" alt="focalloss"></p><h2><span id="dui-kang-xun-lian">对抗训练</span><a href="#dui-kang-xun-lian" class="header-anchor"></a></h2><p>对抗训练主要尝试了<a href="https://kexue.fm/archives/7234" target="_blank" rel="noopener">FGM 方法对Embedding进行扰动</a>，线下对比提升大约一个点上下。<br>线下测试结果：</p><p>$$<br>\begin{array}{c|c}<br>\hline<br>\text{without adt} &amp; \text{with adt} \\<br>\hline<br>\text{0.831} &amp; \text{0.838} \\<br>\end{array}<br>$$</p><h2><span id="post-training">post training</span><a href="#post-training" class="header-anchor"></a></h2><p>上一篇中，提到post training 做的效果不好，然而pet 的效果又很好，两者比较矛盾，所以我也重新阅读了几篇关于优化bert 与post training 相关的论文，重新思考了一下，这篇就从重新做post training开始。</p><h1><span id="post-training">Post Training</span><a href="#post-training" class="header-anchor"></a></h1><p>post training一般包括两部分：Domain-Adaptive training 和 Task-Adaptive training，通过在同领域与任务数据上继续预训练，可以让模型更适应任务，有利于提高模型在下游的性能。而bert 在训练时主要有两个任务：mlm 与nsp ，接下来针对每个任务进行讨论。</p><h2><span id="mlm">MLM</span><a href="#mlm" class="header-anchor"></a></h2><p>在post training 阶段尝试进一步优化的只找到刘知远老师的<a href="https://arxiv.org/abs/2004.09733" target="_blank" rel="noopener">Train No Evil: Selective Masking for Task-Guided Pre-Training</a>，论文里的思路是通过建立一个二分类模型，来有针对性的选择token 来进行mask，不过由于这个方法比较麻烦，需要三个中间模型，所以没有尝试，不过这个论文给出了一个结论：在继续预训练的过程中，优化mask 策略，是可以进一步提高下游性能的。<br>让我们回归一下bert 的mask 策略即后续的改进：<br>$$<br>\begin{array}{c|c|}<br>\hline<br>\text{model} &amp; \text{mask sstrategy} \\<br>\hline<br>\text{bert} &amp; \text{random mask} \\<br>\hline<br>\text{RoBERTa} &amp; \text{dynamic mask} \\<br>\hline<br>\text{RoBERTa-wwm-ext} &amp; \text{whole word mask} \\<br>\hline<br>\text{ERNIE} &amp; \text{entity/phrase mask} \\<br>\hline<br>\text{SpanBERT} &amp; \text{n-gram mask}\\<br>\hline<br>\end{array}<br>$$</p><p>这里笔者思考后认为，不同的mask 策略本质区别是对更多的“固定搭配”进行同时mask，从而降低模型对局部、浅层信息的过拟合，增加任务的难度，提高模型的泛化能力。<br>所谓“固定搭配”，不仅仅包含词，或者说是更广义的“词”。字的固定搭配可以构成词，进一步固定搭配又可以形成短语。比如考虑“好好学习，天天向上”，“08北京奥运会”，如果只mask 其中一部分，是比较“容易”通过剩余的部分来还原的。<br>既然“固定搭配”是更广义的词，这里我们就可以来挖掘这些“固定搭配”了。最简单的方式就是新词/短语挖掘，而新词/短语挖掘最常用的方法是计算左右熵和紧密度，不过这种方式计算量较大，这次比赛笔者舍弃了这种方式，采用借鉴苏神的博客<a href="https://kexue.fm/archives/5476" target="_blank" rel="noopener">最小熵原理（二）：“当机立断”之词库构建</a>中的思路，用PMI表征紧密度，用相邻两个字之间的紧密度判断两者是否存在“固定搭配”,最终未被切分的为一个整体。最后将挖掘出的新词通过jieba 过滤掉已在词库内的，并只保留长度2~5的新词，添加到jieba的词库内。这里选择用jieba 做分词工具的原因是因为笔者用的是NEZHA，而NEZHA在训练时使用的就是jieba 处理的数据，这里与他保持一致，而长度选择上，主要借鉴spanBert中的结论。<br>最后挖掘了2736个新词，而如果是实际工作中，则可以进一步将积累的词也加入。<br><img src="/2021/01/20/ccf-qa-2/new_words.png" alt="new_words"><br>以上的方式中全程没有人为参与，所以新词的质量是无法保证的，即存在词的边界不准确。而此时的全词mask 退化为n-gram mask，依然是一种有效的提升方案。</p><h2><span id="nsp">nsp</span><a href="#nsp" class="header-anchor"></a></h2><p>原始bert 在训练时，句子级别的任务为nsp，而RoBERTa 中给出的结论是句子级别的任务没什么用，所以取消了句子级别的任务；而albert 中则将句子级别的任务切换为sop，而SpanBERT中则切换为sbo。这里笔者认为下游任务是句子级别的分类任务，所以句子级别的任务是有用的，不过由于nsp 会引入大量噪音，所以这里选择sop/aop：在qa pair格式的样本下互换qa(sop)，在q a-list格式的样本下，保持query 在最前面，只shuffle a-list(aop)。</p><p>$$<br>\begin{array}{c|c|c}<br>\hline<br>&amp; \text{without sop/aop} &amp; \text{with sop/aop} \\<br>\hline<br>\text{qa pair} &amp; \text{0.784} &amp; \text{0.79} \\<br>\hline<br>\text{q a-list} &amp; \text{0.799} &amp; \text{0.802} \\<br>\hline<br>\end{array}<br>$$</p><h2><span id="model-adaptive">model-adaptive</span><a href="#model-adaptive" class="header-anchor"></a></h2><p>由于样本的组织方式有qa pair 和 q a-list两种方式，而task 相关的数据是相对较小的，所以这里笔者认为两个阶段的样本组织方式相同的情况下，性能会更好，即：用qa pair格式post training后的模型，来微调qa pair格式的baseline，q a-list格式post training后的模型微调q a-list格式的baseline。</p><h2><span id="geng-xin-ci-shu">更新次数</span><a href="#geng-xin-ci-shu" class="header-anchor"></a></h2><p>这里参考邱锡鹏老师的<a href="http://arxiv.org/abs/1905.05583" target="_blank" rel="noopener">How to Fine-Tune BERT for Text Classification?</a>，实验时每10 个epochs保存一次模型，最后通过在下游任务上的表现，得出与论文中基本一致的结论：更新10K steps左右模型在下游的表现是最好的。<br><img src="/2021/01/20/ccf-qa-2/update.png" alt="update"></p><h2><span id="zui-zhong-jie-guo">最终结果</span><a href="#zui-zhong-jie-guo" class="header-anchor"></a></h2><p>$$<br>\begin{array}{c|c|c}<br>\hline<br>\text{post-train/fine-tuning}&amp; \text{pair} &amp; \text{point} \\<br>\hline<br>\text{pair} &amp; \text{0.79} &amp; \text{0.794} \\<br>\hline<br>\text{point} &amp; \text{0.786} &amp; \text{0.802} \\<br>\hline<br>\end{array}<br>$$</p><p>此时我们认为已经将bert的能力最大化了，于是这里也尝试了在bert 后面接一些复杂的分类层（cnn/rnn/dgcnn/..),发现都无法进一步提高，所以也证实了之前的判断。</p><h1><span id="rong-ru-zhi-shi">融入知识</span><a href="#rong-ru-zhi-shi" class="header-anchor"></a></h1><p>既然从“内部”已经无法进一步提高bert的能力，所以此时尝试融入外部知识来增强。而融合的方式主要尝试了两种：</p><ul><li><p>最底层注入<br>在Embedding 层融入外部的embedding。优点：更多的交互<br><img src="/2021/01/20/ccf-qa-2/inside.png" alt></p></li><li><p>最顶层注入<br>在transformer output 层融入外部Embedding。优点：更灵活，不局限外部知识的形式（可以是Embedding，也可以说是其他特征，如手工特征）。<br><img src="/2021/01/20/ccf-qa-2/outside.png" alt></p></li></ul><p>在知识选择上，首先想到的是Graph EMbedding，参考<a href="http://arxiv.org/abs/2004.05707" target="_blank" rel="noopener">VGCN-BERT: Augmenting BERT with Graph Embedding for Text Classification</a>,我们重跑了一下论文的代码，发现无法重现其中的结论，而我对Graph Embedding也不熟，所以放弃了这个方案。<br>然后尝试简单的embedding，即用gensim 在task data上训练了一版词向量(dims=100),作为外部知识来实验。<br>线下测试结果：<br>$$<br>\begin{array}{c|c}<br>\hline<br>\text{model} &amp; \text{score} \\<br>\hline<br>\text{bert} &amp; \text{0.831} \\<br>\hline<br>\text{external-embedding bottom} &amp; \text{0.82} \\<br>\hline<br>\text{external-embedding top} &amp; \text{0.83} \\<br>\hline<br>\end{array}<br>$$</p><p>可以看到，两种方式都是无法进一步提高的，主要原因可能是：1.词向量的质量较差；2.词向量也是bert的“内部”知识；3.融入的方式或者调参没做好。</p><h1><span id="dui-bi-xue-xi">对比学习</span><a href="#dui-bi-xue-xi" class="header-anchor"></a></h1><p>在模型上，还能通过增加新的任务来尝试提高性能。而今年比较热的一个思路就是对比学习，所以这里尝试通过增加一个对比学习任务来提高性能。<br>对比学习的主要思路是拉近到正样本之间的距离，拉远到负样本之间的距离。<br><img src="/2021/01/20/ccf-qa-2/cl.png" alt><br>对比学习主要又分为两种：监督对比学习和分监督对比学习。监督对比学习中，将相同label的样本看做是正例，其他的为负例；而非监督对比学习中，则通过对每个样本构造一对view，view之间互为正例，其他的为负例。</p><h2><span id="fei-jian-du-dui-bi-xue-xi">非监督对比学习</span><a href="#fei-jian-du-dui-bi-xue-xi" class="header-anchor"></a></h2><p>非监督对比学习中，通过互换QA位置，同时随机mask 15% 的token，来构造一对view。</p><ul><li>对应的loss：</li></ul><p><img src="/2021/01/20/ccf-qa-2/sscl.png" alt></p><ul><li>对应的模型：</li></ul><p><img src="/2021/01/20/ccf-qa-2/sscl-model.png" alt></p><h2><span id="jian-du-dui-bi-xue-xi">监督对比学习</span><a href="#jian-du-dui-bi-xue-xi" class="header-anchor"></a></h2><p>这里主要follow <a href="http://arxiv.org/abs/2011.01403" target="_blank" rel="noopener">Supervised Contrastive Learning for Pre-trained Language Model Fine-tuning</a>,修改对应loss.</p><ul><li>loss</li></ul><p><img src="/2021/01/20/ccf-qa-2/scl.png" alt></p><ul><li>model</li></ul><p><img src="/2021/01/20/ccf-qa-2/sc-model.png" alt></p><h2><span id="shi-yan-jie-guo">实验结果</span><a href="#shi-yan-jie-guo" class="header-anchor"></a></h2><ul><li>线下结果：</li></ul><p>$$<br>\begin{array}{c|c}<br>\hline<br>\text{model} &amp; \text{score} \\<br>\hline<br>\text{bert} &amp; \text{0.831} \\<br>\hline<br>\text{self-supervised contrastive learning} &amp; \text{0.80} \\<br>\hline<br>\text{supervised contrastive learning} &amp; \text{0.824} \\<br>\hline<br>\end{array}<br>$$</p><ul><li><p>非监督对比学习结果可视化<br><img src="/2021/01/20/ccf-qa-2/ssc-vis.png" alt></p></li><li><p>监督对比学习结果可视化<br><img src="/2021/01/20/ccf-qa-2/sc-vis.png" alt></p></li></ul><p>可以看到，两种方式都没有带来提升，而可视化图中可以看到，非监督对比学习的效果并不好，存在大量重叠但颜色不同的点，说明对比学习任务的结果不好，这里的原因猜测主要有两点：1.模型的设计与调参时有问题，batch size（32）太小，没有BN 层等，都有可能是性能不好的原因；2.构造view 的方式过于简单粗暴，由于样本长度大多较短，随机mask 后即有可能引入错误的label 信息，又可能引起view 间语义的gap过大，无法互为正例。<br>监督学习效果图中，不同label的数据被分到了不同的簇中，说明对比学习的还是相当不错，不过由于此次比赛中的label 代表的是“是否是针对问题的回答”，label 相同但内涵不同，所以强行将相同label的样本聚合，并不能带来提升。</p><h1><span id="shu-ju-zeng-qiang">数据增强</span><a href="#shu-ju-zeng-qiang" class="header-anchor"></a></h1><p>数据增强主要尝试了两种方式：EDA 和伪标签。</p><h2><span id="eda">EDA</span><a href="#eda" class="header-anchor"></a></h2><p>EDA主要包括四种方式：随机替换、随机删除、随机重复和随机互换。<br>由于词向量质量较差，所以操作时选择从当前句子中随机选取一个词作为“同义词”进行操作。<br>操作比例为10%，每个样本构造四个样本。<br>用训练过的模型对数据进行过滤，保留置信度高(&gt;0.7)的样本。</p><h2><span id="wei-biao-qian">伪标签</span><a href="#wei-biao-qian" class="header-anchor"></a></h2><p>用训练过的模型在test data 上进行预测，对预测结果按0.5 为阈值计算置信度并进行排序，保留前30%的样本加入训练集。 这里没有单纯按置信度过滤样本，是因为模型预测结果大多数大于0.95或小于0.05，而过多的测试数据进入训练集，会导致模型最终的结果是在拟合训练集中的label，而无法带来提高（充分学习后的模型在训练数据上的预测结果自然是训练时的label）。</p><h2><span id="shi-yan-jie-guo">实验结果</span><a href="#shi-yan-jie-guo" class="header-anchor"></a></h2><ul><li>线上结果</li></ul><p>$$<br>\begin{array}{c|c}<br>\hline<br>\text{without DA} &amp; \text{with DA} \\<br>\hline<br>\text{0.802} &amp; \text{0.806} \\<br>\hline<br>\end{array}<br>$$</p><h1><span id="zi-zheng-liu">自蒸馏</span><a href="#zi-zheng-liu" class="header-anchor"></a></h1><p>借助知识蒸馏，我们尝试了自蒸馏方案：即Teacher 与 Student 为同一个模型，Teacher模型先学习一遍后，对训练样本打上soft labels，Student 同时学习true labels 与 soft labels.</p><ul><li><p>soft labels：<br>$$<br>q_i = \frac{exp(\frac{z_i}{T})}{\sum_j exp(\frac{z_j}{T})}<br>$$</p></li><li><p>线下测试结果：<br>$$<br>\begin{array}{c|c}<br>\hline<br>\text{without KD} &amp; \text{with KD} \\<br>\hline<br>\text{0.831} &amp; \text{0.84} \\<br>\hline<br>\end{array}<br>$$</p></li></ul><h1><span id="shuffle-jie-ma">shuffle 解码</span><a href="#shuffle-jie-ma" class="header-anchor"></a></h1><p>对于q a-list 的模型，可以在预测时，对answer list 进行全排列，然后将结果投票，一来可以将answer label之间的影响降低，二来可以在非常小的成本下融合，也算是一种trick。不过此次比赛的数据对顺序比较敏感，shuffle后大多数情况下会降低模型的性能，所以最终融合后结果没提升反而降低了。</p><h1><span id="mo-xing-rong-he">模型融合</span><a href="#mo-xing-rong-he" class="header-anchor"></a></h1><p>为了提高模型的稳定性与泛化能力，我们进行了模型融合。融合时，我们期望模型间能“和而不同”：每个单模型的性能之间差异小（都要接近最优单模型），且模型之间差异尽量大(架构或者优化方案上差异尽量大）。根据以上策略，对QA Pair 与 QA Point两种模型进行融合。</p><h1><span id="shi-yan-zong-jie">实验总结</span><a href="#shi-yan-zong-jie" class="header-anchor"></a></h1><ul><li><p>能work的方案<br>$$<br>\begin{array}{c|c}<br>\hline<br>\text{task-adaptive training} &amp; \text{+1.5%~3%} \\<br>\hline<br>\text{加入新词} &amp; \text{+0.5%~1%} \\<br>\hline<br>\text{加入sop/aop} &amp; \text{+0.1%~0.3%} \\<br>\hline<br>\text{model-adaptive} &amp; \text{+0.5%~0.7%} \\<br>\hline<br>\text{对抗训练} &amp; \text{+0.5%~0.9%} \\<br>\hline<br>\text{EDA} &amp; \text{+0.3%~0.5%} \\<br>\hline<br>\text{模型融合} &amp; \text{+0.5%~0.7%} \\<br>\hline<br>\end{array}<br>$$</p></li><li><p>不能work的方案<br>$$<br>\begin{array}{c|c}<br>\hline<br>\text{external-embedding bottom} &amp; \text{-0.2%~0%} \\<br>\hline<br>\text{external-embedding top} &amp; \text{-0.1%~0%} \\<br>\hline<br>\text{self-supervised contrastive learning} &amp; \text{-0.4%~-0.2%} \\<br>\hline<br>\text{supervised contrastive learning} &amp; \text{-0.1%~0%} \\<br>\hline<br>\text{focal loss} &amp; \text{0%} \\<br>\hline<br>\text{shuffle trick} &amp; \text{-0.15%~0} \\<br>\end{array}<br>$$</p></li><li><p>线下有效但未提交<br>$$<br>\begin{array}{c|c}<br>\hline<br>\text{自蒸馏} &amp; \text{+0.5%~1%} \\<br>\hline<br>\text{伪标签} &amp; \text{+0.1%~0.3%} \\<br>\hline<br>\end{array}<br>$$</p></li></ul><p>对于PET ，在post training后的效果并不是很好，不过由于没有时间了，所以没有继续优化。这里提一下可以优化的点：1.可以增加解码空间；2.增加多个pattern 进行融合的方式尝试优化。笔者本人是比较喜欢PET 这个思路的，统一了两个阶段，所以可做的事还有很多。</p><h1><span id="bi-sai-jie-guo">比赛结果</span><a href="#bi-sai-jie-guo" class="header-anchor"></a></h1><p>比赛最终的线上成绩在A/B 榜均是第一，答辩阶段也得到了第一。</p><ul><li>A榜得分：<br><img src="/2021/01/20/ccf-qa-2/a-result.png" alt></li><li>B榜得分：<br><img src="/2021/01/20/ccf-qa-2/b-result.png" alt></li><li>答辩得分：<br><img src="/2021/01/20/ccf-qa-2/last-result.jpg" alt></li></ul><h1><span id="dai-ma">代码</span><a href="#dai-ma" class="header-anchor"></a></h1><p>比赛相关思路的代码开源在github上：<br><a href="https://github.com/xv44586/ccf_2020_qa_match" target="_blank" rel="noopener">ccf_2020_qa_match</a><br>欢迎大家尝试使用，有问题或者想法可以提issue，一起讨论。</p><h1><span id="zui-hou">最后</span><a href="#zui-hou" class="header-anchor"></a></h1><p>本文主要总结了此次ccf 问答匹配中的实验思路，而其中提出的四种baseline ，可以横向推广至所有的文本分类相关的任务中，而优化相关的方案，则可以应用在所有bert-base 模型上。 从最初打算“白嫖”一份数据，到最终拿到第一，算起来这应该是笔者第一次参加NLP的比赛，所以很幸运也很惊喜。<br>Enjoy！</p><h1><span id="guan-yu-tou-tu">关于头图</span><a href="#guan-yu-tou-tu" class="header-anchor"></a></h1><p>答辩头图</p><div class="content-footer-sponsor"><h1><span id="sponsor">Buy me a coffee</span></h1><p>如果觉得这篇文章不错，对你有帮助，欢迎打赏一杯蜜雪冰城。</p><img src="/img/sponsor.JPG" alt="logo" title="sponsor"></div><div class="post__prevs"><div class="post__prev"><a href="/2021/01/12/matrix/" title="重新认识矩阵"><i class="iconfont icon-prev"></i>重新认识矩阵</a></div><div class="post__prev post__prev--right"><a href="/2021/02/19/happy-new-year/" title="辞旧迎新">辞旧迎新<i class="iconfont icon-next"></i></a></div></div></div></article><script src="https://giscus.app/client.js" data-repo="xv44586/giscus" data-repo-id="R_kgDOIC6Ipg" data-category="Announcements" data-category-id="DIC_kwDOIC6Ips4CRkmo" data-mapping="pathname" data-strict="0" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="bottom" data-theme="light" data-lang="zh-CN" crossorigin="anonymous" async></script></div><aside class="page__sidebar"><form id="page-search-from" class="page__search-from" action="/search/"><label class="search-form__item"><input class="input" type="text" name="search" placeholder="Search..."> <i class="iconfont icon-search"></i></label></form><div class="sidebar__block"><h3 class="block__title">简介</h3><p class="block__text">NLP | Machine Learning | Developer</p></div><div class="sidebar__block"><h3 class="block__title">文章分类</h3><ul class="block-list"><li class="block-list-item"><a class="block-list-link" href="/categories/Programming/">Programming</a><span class="block-list-count">4</span></li><li class="block-list-item"><a class="block-list-link" href="/categories/NLP/">NLP</a><span class="block-list-count">33</span></li><li class="block-list-item"><a class="block-list-link" href="/categories/Math/">Math</a><span class="block-list-count">5</span></li><li class="block-list-item"><a class="block-list-link" href="/categories/MachineLearning/">MachineLearning</a><span class="block-list-count">8</span></li><li class="block-list-item"><a class="block-list-link" href="/categories/Life/">Life</a><span class="block-list-count">6</span></li></ul></div><div class="sidebar__block"><h3 class="block__title">最新文章</h3><ul class="block-list latest-post-list"><li class="latest-post-item"><a href="/2023/03/25/gpt4/" title="GPT-4 yes!! but"><div class="item__cover"><img src="/2023/03/25/gpt4/bg.jpeg" alt="GPT-4 yes!! but"></div><div class="item__info"><h3 class="item__title">GPT-4 yes!! but</h3><span class="item__text">2023-03-25</span></div></a></li><li class="latest-post-item"><a href="/2023/03/10/llm-inf/" title="LLM Inference串讲"><div class="item__cover"><img src="/2023/03/10/llm-inf/sd.PNG" alt="LLM Inference串讲"></div><div class="item__info"><h3 class="item__title">LLM Inference串讲</h3><span class="item__text">2023-03-10</span></div></a></li><li class="latest-post-item"><a href="/2023/02/01/fine-tuning-at-few-shot/" title="few-shot视角下的fine-tuning"><div class="item__cover"><img src="/2023/02/01/fine-tuning-at-few-shot/himalayas.JPG" alt="few-shot视角下的fine-tuning"></div><div class="item__info"><h3 class="item__title">few-shot视角下的fine-tuning</h3><span class="item__text">2023-02-01</span></div></a></li><li class="latest-post-item"><a href="/2023/01/09/zero-to-chatgpt/" title="From zero to ChatGPT"><div class="item__cover"><img src="/2023/01/09/zero-to-chatgpt/chatgpt-bg.jpeg" alt="From zero to ChatGPT"></div><div class="item__info"><h3 class="item__title">From zero to ChatGPT</h3><span class="item__text">2023-01-09</span></div></a></li></ul></div><div class="sidebar__block"><h3 class="block__title">文章标签</h3><ul class="block-list tag-list clearfix"><li class="tag-item"><a class="tag-link" href="/tags/BERT/">BERT</a></li><li class="tag-item"><a class="tag-link" href="/tags/BPE/">BPE</a></li><li class="tag-item"><a class="tag-link" href="/tags/Bagging/">Bagging</a></li><li class="tag-item"><a class="tag-link" href="/tags/Boosting/">Boosting</a></li><li class="tag-item"><a class="tag-link" href="/tags/CCF/">CCF</a></li><li class="tag-item"><a class="tag-link" href="/tags/CRF/">CRF</a></li><li class="tag-item"><a class="tag-link" href="/tags/CUDA/">CUDA</a></li><li class="tag-item"><a class="tag-link" href="/tags/ChatGPT/">ChatGPT</a></li><li class="tag-item"><a class="tag-link" href="/tags/Classification/">Classification</a></li><li class="tag-item"><a class="tag-link" href="/tags/Competition/">Competition</a></li><li class="tag-item"><a class="tag-link" href="/tags/Deep-Learning/">Deep Learning</a></li><li class="tag-item"><a class="tag-link" href="/tags/Distillation/">Distillation</a></li><li class="tag-item"><a class="tag-link" href="/tags/EDA/">EDA</a></li><li class="tag-item"><a class="tag-link" href="/tags/FastBERT/">FastBERT</a></li><li class="tag-item"><a class="tag-link" href="/tags/Few-shot/">Few-shot</a></li><li class="tag-item"><a class="tag-link" href="/tags/GPT-3/">GPT-3</a></li><li class="tag-item"><a class="tag-link" href="/tags/GPT-4/">GPT-4</a></li><li class="tag-item"><a class="tag-link" href="/tags/GPU/">GPU</a></li><li class="tag-item"><a class="tag-link" href="/tags/Game/">Game</a></li><li class="tag-item"><a class="tag-link" href="/tags/Glove/">Glove</a></li><li class="tag-item"><a class="tag-link" href="/tags/Hexo/">Hexo</a></li><li class="tag-item"><a class="tag-link" href="/tags/In-context-learning/">In-context learning</a></li><li class="tag-item"><a class="tag-link" href="/tags/Inference/">Inference</a></li><li class="tag-item"><a class="tag-link" href="/tags/LLM/">LLM</a></li><li class="tag-item"><a class="tag-link" href="/tags/LR/">LR</a></li><li class="tag-item"><a class="tag-link" href="/tags/Language-Model/">Language Model</a></li><li class="tag-item"><a class="tag-link" href="/tags/Loss/">Loss</a></li><li class="tag-item"><a class="tag-link" href="/tags/MarkDown/">MarkDown</a></li><li class="tag-item"><a class="tag-link" href="/tags/Math/">Math</a></li><li class="tag-item"><a class="tag-link" href="/tags/Matrix/">Matrix</a></li><li class="tag-item"><a class="tag-link" href="/tags/NLG/">NLG</a></li><li class="tag-item"><a class="tag-link" href="/tags/Optimizer/">Optimizer</a></li><li class="tag-item"><a class="tag-link" href="/tags/Python/">Python</a></li><li class="tag-item"><a class="tag-link" href="/tags/QA/">QA</a></li><li class="tag-item"><a class="tag-link" href="/tags/R-Drop/">R-Drop</a></li><li class="tag-item"><a class="tag-link" href="/tags/Random-Forest/">Random Forest</a></li><li class="tag-item"><a class="tag-link" href="/tags/Segmentation/">Segmentation</a></li><li class="tag-item"><a class="tag-link" href="/tags/SimCSE/">SimCSE</a></li><li class="tag-item"><a class="tag-link" href="/tags/Statistics/">Statistics</a></li><li class="tag-item"><a class="tag-link" href="/tags/Survey/">Survey</a></li><li class="tag-item"><a class="tag-link" href="/tags/T5/">T5</a></li><li class="tag-item"><a class="tag-link" href="/tags/UniLM/">UniLM</a></li><li class="tag-item"><a class="tag-link" href="/tags/Unigram/">Unigram</a></li><li class="tag-item"><a class="tag-link" href="/tags/WordPiece/">WordPiece</a></li><li class="tag-item"><a class="tag-link" href="/tags/Words-Distance/">Words Distance</a></li><li class="tag-item"><a class="tag-link" href="/tags/Xgboost/">Xgboost</a></li><li class="tag-item"><a class="tag-link" href="/tags/debug/">debug</a></li><li class="tag-item"><a class="tag-link" href="/tags/faster-decoder/">faster decoder</a></li><li class="tag-item"><a class="tag-link" href="/tags/fine-tuning/">fine-tuning</a></li><li class="tag-item"><a class="tag-link" href="/tags/horovod/">horovod</a></li><li class="tag-item"><a class="tag-link" href="/tags/multi-task/">multi-task</a></li><li class="tag-item"><a class="tag-link" href="/tags/nohup/">nohup</a></li><li class="tag-item"><a class="tag-link" href="/tags/npm/">npm</a></li><li class="tag-item"><a class="tag-link" href="/tags/simbert/">simbert</a></li><li class="tag-item"><a class="tag-link" href="/tags/skipgram/">skipgram</a></li><li class="tag-item"><a class="tag-link" href="/tags/speed-up/">speed-up</a></li><li class="tag-item"><a class="tag-link" href="/tags/swift/">swift</a></li><li class="tag-item"><a class="tag-link" href="/tags/tensorflow-gpu/">tensorflow-gpu</a></li><li class="tag-item"><a class="tag-link" href="/tags/word2vec/">word2vec</a></li><li class="tag-item"><a class="tag-link" href="/tags/信息熵/">信息熵</a></li><li class="tag-item"><a class="tag-link" href="/tags/新词发现/">新词发现</a></li><li class="tag-item"><a class="tag-link" href="/tags/样本不均衡/">样本不均衡</a></li><li class="tag-item"><a class="tag-link" href="/tags/装机/">装机</a></li><li class="tag-item"><a class="tag-link" href="/tags/领域词挖掘/">领域词挖掘</a></li></ul></div></aside></main><footer class="page__footer"><section class="footer__top"><div class="page__container footer__container"><div class="footer-top__item footer-top__item--2"><h3 class="item__title">关于</h3><div class="item__content"><p class="item__text">本站是基于 Hexo 搭建的静态资源博客，主要用于分享日常学习、生活及工作的一些心得总结。</p><ul class="footer__contact-info"><li class="contact-info__item"><i class="iconfont icon-address"></i> <span>Beijing, China</span></li><li class="contact-info__item"><i class="iconfont icon-email2"></i> <span>xv44586@gmail.com</span></li></ul></div></div><div class="footer-top__item"><h3 class="item__title">友情链接</h3><div class="item__content"><ul class="footer-top__list"><li class="list-item"><a href="http://www.matrix67.com/" title="Matrix67" target="_blank">Matrix67</a></li><li class="list-item"><a href="https://spaces.ac.cn/" title="Spaces" target="_blank">科学空间</a></li></ul></div></div></div></section><section class="footer__bottom"><div class="page__container footer__container"><p class="footer__copyright">© <a href="https://github.com/Mrminfive/hexo-theme-skapp" target="_blank">Skapp</a> 2017 powered by <a href="http://hexo.io/" target="_blank">Hexo</a>, made by <a href="https://github.com/Mrminfive" target="_blank">minfive</a>. modified by <a href="https://github.com/xv44586" target="_blank">小蛋子</a></p><ul class="footer__social-network clearfix"><li class="social-network__item"><a href="https://github.com/xv44586" target="_blank" title="github"><i class="iconfont icon-github"></i></a></li><li class="social-network__item"><a href="xv44586@gmail.com" target="_blank" title="email"><i class="iconfont icon-email"></i></a></li></ul></div></section></footer><div id="back-top" class="back-top back-top--hidden js-hidden"><i class="iconfont icon-top"></i></div></div><script src="/js/common.js"></script><script src="/js/page/post.js"></script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
            tex2jax: {
                inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
                processEscapes: true,
                skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
            }
            });</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
            var all = MathJax.Hub.getAllJax(), i;
                for (i=0; i < all.length; i += 1) {
                all[i].SourceElement().parentNode.className += ' has-jax';
                }
            });</script><script type="text/javascript" src="//cdn.jsdelivr.net/npm/mathjax@2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script></body></html>