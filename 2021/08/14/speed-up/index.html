<!DOCTYPE html><html lang="zh-cn"><head><meta name="generator" content="Hexo 3.9.0"><meta charset="utf-8"><title>speed-up | 小蛋子</title><meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no"><meta name="format-detection" content="telephone=no"><meta name="author" content="[object Object]"><meta name="designer" content="minfive"><meta name="keywords" content="NLP, 机器学习, 深度学习, Python, Backend"><meta name="description" content="NLP | Machine Learning | Developer"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black"><meta name="format-detection" content="telephone=yes"><meta name="mobile-web-app-capable" content="yes"><meta name="robots" content="all"><link rel="canonical" href="https://xv44586.github.io/2021/08/14/speed-up/index.html"><link rel="icon" type="image/png" href="/img/favicon.ico" sizes="32x32"><meta name="google-site-verification" content="tbK2z0UTHcAWdqNCgEwykaDA9vvvXnN4ZSp_LFbAbDc"><meta name="baidu-site-verification" content="NBO0j1DAOy"><meta name="baidu-site-verification" content="ulZR80nUkv"><link rel="stylesheet" href="/scss/base/index.css"><link rel="alternate" href="/atom.xml" title="小蛋子"><script>var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?b1d2a1d2b250300950a8ffb5caa20818";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><link rel="stylesheet" href="/scss/views/page/post.css"><link rel="alternate" href="/atom.xml" title="小蛋子" type="application/atom+xml"></head><body ontouchstart><div id="page-loading" class="page page-loading" style="background-image:url(/other/loading.gif)"></div><div id="page" class="page js-hidden"><header class="page__small-header page__header--small"><nav class="page__navbar"><div class="page__container navbar-container"><a class="page__logo" href="/" title="小蛋子" alt="小蛋子"><img src="/img/lg.png" alt="小蛋子"></a><nav class="page__nav"><ul class="nav__list clearfix"><li class="nav__item"><a href="/" alt="首页" title="首页">首页</a></li><li class="nav__item"><a href="/archives" alt="归档" title="归档">归档</a></li><li class="nav__item"><a href="/about" alt="关于" title="关于">关于</a></li></ul></nav><button class="page__menu-btn" type="button"><i class="iconfont icon-menu"></i></button></div></nav></header><main class="page__container page__main"><div class="page__content"><article class="page__post"><div class="post__cover"><img src="/2021/08/14/speed-up/puppy.jpeg" alt="speed-up"></div><header class="post__info"><h1 class="post__title">speed-up</h1><div class="post__mark"><div class="mark__block"><i class="mark__icon iconfont icon-write"></i><ul class="mark__list clearfix"><li class="mark__item"><a href="https://github.com/xv44586">小蛋子</a></li></ul></div><div class="mark__block"><i class="mark__icon iconfont icon-time"></i><ul class="mark__list clearfix"><li class="mark__item"><span>2021-08-14</span></li></ul></div><div class="mark__block"><i class="mark__icon iconfont icon-tab"></i><ul class="mark__list clearfix"><li class="mark__item"><a href="/tags/speed-up/">Speed-Up</a></li></ul></div><div class="mark__block"><i class="mark__icon iconfont icon-eye"></i><ul class="mark__list clearfix"><li id="busuanzi_container_page_pv" class="mark__item"><span id="busuanzi_value_page_pv"></span>次</li></ul></div></div></header><div class="post__content"><div class="toc"><ul><li><a href="#xun-lian-jia-su">训练加速</a></li><li><a href="#hun-he-jing-du">混合精度</a><ul><li><a href="#dui-ying-de-ruan-ying-jian-yao-qiu">对应的软硬件要求</a></li><li><a href="#ru-he-kai-qi">如何开启</a></li><li><a href="#yi-xie-ce-shi-jie-guo">一些测试结果</a></li></ul></li><li><a href="#tui-li-jia-su">推理加速</a><ul><li><a href="#ce-shi">测试</a></li></ul></li><li><a href="#guan-yu-tou-tu">关于头图</a></li></ul></div><p>之前文章中介绍了通过模型压缩来加速其推理速度的主要思路，并就知识蒸馏总结了三篇内容，分别是：<a href="https://xv44586.github.io/2020/08/09/bert-of-theseus/">模型替换之bert-of-theseus</a> 、<a href="https://xv44586.github.io/2020/08/31/bert-01/">知识迁移</a> 和 <a href="https://xv44586.github.io/2020/09/25/fastbert/">看样本下菜的FastBERT</a>。本文总结两种与模型无关的加速方案。</p><h1><span id="xun-lian-jia-su">训练加速</span><a href="#xun-lian-jia-su" class="header-anchor"></a></h1><p>训练加速的主要方法包括pipeline 和混合精度，其中pipeline是指通过构造一个input pipeline将数据IO与GPU计算分开，从而避免GPU因IO而空闲，这个问题不是本篇重点，想进一步了解的可以参考<a href="https://zhuanlan.zhihu.com/p/27238630?utm_source=wechat_session&amp;utm_medium=social&amp;utm_oi=43831500210176" target="_blank" rel="noopener">tensorflow数据读取机制-何之源</a>和<a href="https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/data/Dataset" target="_blank" rel="noopener">Doc-tf-data-dataset</a></p><h1><span id="hun-he-jing-du">混合精度</span><a href="#hun-he-jing-du" class="header-anchor"></a></h1><p>混合精度是指训练时在模型中同时使用 16 位和32位浮点类型，从而加快运行速度，减少内存使用的一种训练方法。通过让模型的某些部分保持使用 32 位类型以保持数值稳定性，可以缩短模型的单步用时，而在评估指标（如准确率）方面仍可以获得同等的训练效果。（<a href="https://tensorflow.google.cn/guide/mixed_precision?hl=zh-cn" target="_blank" rel="noopener">tf doc</a>)简单说就是开启混合精度，既能更省显存又能加速训练，保证性能的前提下，偶尔还能提高性能，真是又省又快又好，了解更多混合精度相关知识，可以参考<a href="https://zhuanlan.zhihu.com/p/103685761" target="_blank" rel="noopener">浅谈混合精度训练</a>.<br>然而很早之前笔者就知道开启混合精度的好处了，在pytorch 下有<a href="https://github.com/NVIDIA/apex" target="_blank" rel="noopener">apex</a> 可以很方便的开启，但是在keras（tensorflow 1.x） 下尝试了多次，也没能找到正确的方法，最近笔者又一次尝试，终于找到了正确的姿势，这里也分享一下。</p><h2><span id="dui-ying-de-ruan-ying-jian-yao-qiu">对应的软硬件要求</span><a href="#dui-ying-de-ruan-ying-jian-yao-qiu" class="header-anchor"></a></h2><p>tensorflow要求版本在1.14+ ，对应的显卡需要算力（compute capability）在7及以上, 可以在<a href="https://developer.nvidia.com/cuda-gpus#compute" target="_blank" rel="noopener">cuda-gpus#compute</a>查看对应型号卡的算力</p><h2><span id="ru-he-kai-qi">如何开启</span><a href="#ru-he-kai-qi" class="header-anchor"></a></h2><p>对应代码中，只需要增加一行代码，修改一下optimizer即可。不过仍有两点非常需要注意：</p><ol><li>修改optimizer最好在build model前完成，否则某些情况下可能会报错。</li><li>optimizer需要是tf.train.Optimizer or tf.keras.optimizers.Optimizer继承来的，不支持keras 原生的optimizer。</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">...</span><br><span class="line">opt = ...</span><br><span class="line">opt = tf.train.experimental.enable_mixed_precision_graph_rewrite(opt) <span class="comment"># rewrite opt</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># build_model</span></span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>当在打印信息中看到 <code>tensorflow/core/grappler/optimizers/auto_mixed_precision.cc</code>相关信息，则说明已成功开启混合精度。<br></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">2021-08-04 07:36:24.231900: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1816] Running auto_mixed_precision graph optimizer</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p></p><h2><span id="yi-xie-ce-shi-jie-guo">一些测试结果</span><a href="#yi-xie-ce-shi-jie-guo" class="header-anchor"></a></h2><p>笔者在V100 下用bert-base 做了部分测试，测试结果如下：</p><p><strong>batch_size=32, maxlen=128</strong></p><table><thead><tr><th></th><th>epoch 1</th><th>epoch 2</th><th>epoch 3</th><th>epoch 4</th><th>epoch 5</th></tr></thead><tbody><tr><td>开启前：</td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td>277s</td><td>246s</td><td>244s</td><td>246s</td><td>244s</td></tr><tr><td></td><td>164ms/step</td><td>147ms/step</td><td>146ms/step</td><td>147ms/step</td><td>146ms/step</td></tr><tr><td></td><td>bset acc:</td><td><code>0.57</code></td></tr><tr><td>开启后：</td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td>235s</td><td>200s</td><td>201s</td><td>200s</td><td>201s</td></tr><tr><td></td><td>140ms/step</td><td>120ms/step</td><td>121ms/step</td><td>120ms/step</td><td>121ms/step</td></tr><tr><td></td><td>best acc:</td><td><code>0.576</code></td></tr></tbody></table><p><strong>batch_size=64, maxlen=128</strong></p><table><thead><tr><th style="text-align:center"></th><th style="text-align:center">epoch 1</th><th style="text-align:center">epoch 2</th><th style="text-align:center">epoch 3</th><th style="text-align:center">epoch 4</th><th style="text-align:center">epoch 5</th></tr></thead><tbody><tr><td style="text-align:center">开启前：</td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td></tr><tr><td style="text-align:center"></td><td style="text-align:center">234s</td><td style="text-align:center">202s</td><td style="text-align:center">201s</td><td style="text-align:center">203s</td><td style="text-align:center">203s</td></tr><tr><td style="text-align:center"></td><td style="text-align:center">281ms/step</td><td style="text-align:center">242ms/step</td><td style="text-align:center">241ms/step</td><td style="text-align:center">244ms/step</td><td style="text-align:center">244ms/step</td></tr><tr><td style="text-align:center"></td><td style="text-align:center">best acc:</td><td style="text-align:center"><code>0.567</code></td></tr><tr><td style="text-align:center">开启后:</td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td></tr><tr><td style="text-align:center"></td><td style="text-align:center">180s</td><td style="text-align:center">141s</td><td style="text-align:center">140s</td><td style="text-align:center">140s</td><td style="text-align:center">141s</td></tr><tr><td style="text-align:center"></td><td style="text-align:center">216ms/step</td><td style="text-align:center">169ms/step</td><td style="text-align:center">168ms/step</td><td style="text-align:center">168ms/step</td><td style="text-align:center">169ms/step</td></tr><tr><td style="text-align:center"></td><td style="text-align:center">best acc:</td><td style="text-align:center"><code>0.571</code></td></tr></tbody></table><p>可以看到，batch size越大，加速比越可观，约能节省1/3的训练时间，同时，性能不会出现明显下降甚至可能也会高一点点。<br>另外，测试使用的bert 是keras 代码，其中有一条日志是<code>converted 1265/17548 nodes to float16 precision</code>，所以约有不到10%的节点使用了半精度？所以猜测使用半精度的节点越多加速比越可观。</p><h1><span id="tui-li-jia-su">推理加速</span><a href="#tui-li-jia-su" class="header-anchor"></a></h1><p>推理时通常需要我们提供一个SDK或一个API 服务，这里我们只讨论API 服务的情况。<br>而API 服务通常有两种做法：</p><ol><li>在server 端load 模型，然后直接预测给出结果；</li><li>backend 调用tf-serving ，模型的预测由tf-serving 来提供，其余的（数据的预处理，结果的后处理等）则在backend 端进行。tf-serving 具有热更新，支持多模型多版本，异步调用，高可用等特性，所以也推荐使用tf-serving。使用了tf-serving后，完整的路线变为：<br><strong>client –&gt; backend –&gt; rpc/rest –&gt; tf-serving</strong><br>其中tf-serving 提供了两种形式的api：restful api 和 grpc<br>对应的demo 代码可以查看<a href="https://github.com/xv44586/toolkit4nlp/tree/master/serving" target="_blank" rel="noopener">serving</a></li></ol><h2><span id="ce-shi">测试</span><a href="#ce-shi" class="header-anchor"></a></h2><h1><span id="guan-yu-tou-tu">关于头图</span><a href="#guan-yu-tou-tu" class="header-anchor"></a></h1><p>可爱修狗</p><div class="content-footer-sponsor"><h1><span id="sponsor">Buy me a coffee</span></h1><p>如果觉得这篇文章不错，对你有帮助，欢迎打赏一杯蜜雪冰城。</p><img src="/img/sponsor.JPG" alt="logo" title="sponsor"></div><div class="post__prevs"><div class="post__prev"><a href="/2021/07/06/cl2rdrop/" title="对比学习心路历程"><i class="iconfont icon-prev"></i>对比学习心路历程</a></div><div class="post__prev post__prev--right"><a href="/2022/05/23/faster-decoder/" title="faster-decoder之 decoder解码加速">faster-decoder之 decoder解码加速<i class="iconfont icon-next"></i></a></div></div></div></article><script src="https://giscus.app/client.js" data-repo="xv44586/giscus" data-repo-id="R_kgDOIC6Ipg" data-category="Announcements" data-category-id="DIC_kwDOIC6Ips4CRkmo" data-mapping="pathname" data-strict="0" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="bottom" data-theme="light" data-lang="zh-CN" crossorigin="anonymous" async></script></div><aside class="page__sidebar"><form id="page-search-from" class="page__search-from" action="/search/"><label class="search-form__item"><input class="input" type="text" name="search" placeholder="Search..."> <i class="iconfont icon-search"></i></label></form><div class="sidebar__block"><h3 class="block__title">简介</h3><p class="block__text">NLP | Machine Learning | Developer</p></div><div class="sidebar__block"><h3 class="block__title">文章分类</h3><ul class="block-list"><li class="block-list-item"><a class="block-list-link" href="/categories/Programming/">Programming</a><span class="block-list-count">4</span></li><li class="block-list-item"><a class="block-list-link" href="/categories/NLP/">NLP</a><span class="block-list-count">32</span></li><li class="block-list-item"><a class="block-list-link" href="/categories/Math/">Math</a><span class="block-list-count">5</span></li><li class="block-list-item"><a class="block-list-link" href="/categories/MachineLearning/">MachineLearning</a><span class="block-list-count">8</span></li><li class="block-list-item"><a class="block-list-link" href="/categories/Life/">Life</a><span class="block-list-count">6</span></li></ul></div><div class="sidebar__block"><h3 class="block__title">最新文章</h3><ul class="block-list latest-post-list"><li class="latest-post-item"><a href="/2023/03/10/llm-inf/" title="LLM Inference串讲"><div class="item__cover"><img src="/2023/03/10/llm-inf/sd.PNG" alt="LLM Inference串讲"></div><div class="item__info"><h3 class="item__title">LLM Inference串讲</h3><span class="item__text">2023-03-10</span></div></a></li><li class="latest-post-item"><a href="/2023/02/01/fine-tuning-at-few-shot/" title="few-shot视角下的fine-tuning"><div class="item__cover"><img src="/2023/02/01/fine-tuning-at-few-shot/himalayas.JPG" alt="few-shot视角下的fine-tuning"></div><div class="item__info"><h3 class="item__title">few-shot视角下的fine-tuning</h3><span class="item__text">2023-02-01</span></div></a></li><li class="latest-post-item"><a href="/2023/01/09/zero-to-chatgpt/" title="From zero to ChatGPT"><div class="item__cover"><img src="/2023/01/09/zero-to-chatgpt/chatgpt-bg.jpeg" alt="From zero to ChatGPT"></div><div class="item__info"><h3 class="item__title">From zero to ChatGPT</h3><span class="item__text">2023-01-09</span></div></a></li><li class="latest-post-item"><a href="/2022/09/08/tokenizers/" title="tokenizers 总结"><div class="item__cover"><img src="/2022/09/08/tokenizers/cannot_code.PNG" alt="tokenizers 总结"></div><div class="item__info"><h3 class="item__title">tokenizers 总结</h3><span class="item__text">2022-09-08</span></div></a></li></ul></div><div class="sidebar__block"><h3 class="block__title">文章标签</h3><ul class="block-list tag-list clearfix"><li class="tag-item"><a class="tag-link" href="/tags/BERT/">BERT</a></li><li class="tag-item"><a class="tag-link" href="/tags/BPE/">BPE</a></li><li class="tag-item"><a class="tag-link" href="/tags/Bagging/">Bagging</a></li><li class="tag-item"><a class="tag-link" href="/tags/Boosting/">Boosting</a></li><li class="tag-item"><a class="tag-link" href="/tags/CCF/">CCF</a></li><li class="tag-item"><a class="tag-link" href="/tags/CRF/">CRF</a></li><li class="tag-item"><a class="tag-link" href="/tags/CUDA/">CUDA</a></li><li class="tag-item"><a class="tag-link" href="/tags/ChatGPT/">ChatGPT</a></li><li class="tag-item"><a class="tag-link" href="/tags/Classification/">Classification</a></li><li class="tag-item"><a class="tag-link" href="/tags/Competition/">Competition</a></li><li class="tag-item"><a class="tag-link" href="/tags/Deep-Learning/">Deep Learning</a></li><li class="tag-item"><a class="tag-link" href="/tags/Distillation/">Distillation</a></li><li class="tag-item"><a class="tag-link" href="/tags/EDA/">EDA</a></li><li class="tag-item"><a class="tag-link" href="/tags/FastBERT/">FastBERT</a></li><li class="tag-item"><a class="tag-link" href="/tags/Few-shot/">Few-shot</a></li><li class="tag-item"><a class="tag-link" href="/tags/GPT-3/">GPT-3</a></li><li class="tag-item"><a class="tag-link" href="/tags/GPU/">GPU</a></li><li class="tag-item"><a class="tag-link" href="/tags/Game/">Game</a></li><li class="tag-item"><a class="tag-link" href="/tags/Glove/">Glove</a></li><li class="tag-item"><a class="tag-link" href="/tags/Hexo/">Hexo</a></li><li class="tag-item"><a class="tag-link" href="/tags/In-context-learning/">In-context learning</a></li><li class="tag-item"><a class="tag-link" href="/tags/Inference/">Inference</a></li><li class="tag-item"><a class="tag-link" href="/tags/LLM/">LLM</a></li><li class="tag-item"><a class="tag-link" href="/tags/LR/">LR</a></li><li class="tag-item"><a class="tag-link" href="/tags/Language-Model/">Language Model</a></li><li class="tag-item"><a class="tag-link" href="/tags/Loss/">Loss</a></li><li class="tag-item"><a class="tag-link" href="/tags/MarkDown/">MarkDown</a></li><li class="tag-item"><a class="tag-link" href="/tags/Math/">Math</a></li><li class="tag-item"><a class="tag-link" href="/tags/Matrix/">Matrix</a></li><li class="tag-item"><a class="tag-link" href="/tags/NLG/">NLG</a></li><li class="tag-item"><a class="tag-link" href="/tags/Optimizer/">Optimizer</a></li><li class="tag-item"><a class="tag-link" href="/tags/Python/">Python</a></li><li class="tag-item"><a class="tag-link" href="/tags/QA/">QA</a></li><li class="tag-item"><a class="tag-link" href="/tags/R-Drop/">R-Drop</a></li><li class="tag-item"><a class="tag-link" href="/tags/Random-Forest/">Random Forest</a></li><li class="tag-item"><a class="tag-link" href="/tags/Segmentation/">Segmentation</a></li><li class="tag-item"><a class="tag-link" href="/tags/SimCSE/">SimCSE</a></li><li class="tag-item"><a class="tag-link" href="/tags/Statistics/">Statistics</a></li><li class="tag-item"><a class="tag-link" href="/tags/Survey/">Survey</a></li><li class="tag-item"><a class="tag-link" href="/tags/T5/">T5</a></li><li class="tag-item"><a class="tag-link" href="/tags/UniLM/">UniLM</a></li><li class="tag-item"><a class="tag-link" href="/tags/Unigram/">Unigram</a></li><li class="tag-item"><a class="tag-link" href="/tags/WordPiece/">WordPiece</a></li><li class="tag-item"><a class="tag-link" href="/tags/Words-Distance/">Words Distance</a></li><li class="tag-item"><a class="tag-link" href="/tags/Xgboost/">Xgboost</a></li><li class="tag-item"><a class="tag-link" href="/tags/debug/">debug</a></li><li class="tag-item"><a class="tag-link" href="/tags/faster-decoder/">faster decoder</a></li><li class="tag-item"><a class="tag-link" href="/tags/fine-tuning/">fine-tuning</a></li><li class="tag-item"><a class="tag-link" href="/tags/horovod/">horovod</a></li><li class="tag-item"><a class="tag-link" href="/tags/multi-task/">multi-task</a></li><li class="tag-item"><a class="tag-link" href="/tags/nohup/">nohup</a></li><li class="tag-item"><a class="tag-link" href="/tags/npm/">npm</a></li><li class="tag-item"><a class="tag-link" href="/tags/simbert/">simbert</a></li><li class="tag-item"><a class="tag-link" href="/tags/skipgram/">skipgram</a></li><li class="tag-item"><a class="tag-link" href="/tags/speed-up/">speed-up</a></li><li class="tag-item"><a class="tag-link" href="/tags/swift/">swift</a></li><li class="tag-item"><a class="tag-link" href="/tags/tensorflow-gpu/">tensorflow-gpu</a></li><li class="tag-item"><a class="tag-link" href="/tags/word2vec/">word2vec</a></li><li class="tag-item"><a class="tag-link" href="/tags/信息熵/">信息熵</a></li><li class="tag-item"><a class="tag-link" href="/tags/新词发现/">新词发现</a></li><li class="tag-item"><a class="tag-link" href="/tags/样本不均衡/">样本不均衡</a></li><li class="tag-item"><a class="tag-link" href="/tags/装机/">装机</a></li><li class="tag-item"><a class="tag-link" href="/tags/领域词挖掘/">领域词挖掘</a></li></ul></div></aside></main><footer class="page__footer"><section class="footer__top"><div class="page__container footer__container"><div class="footer-top__item footer-top__item--2"><h3 class="item__title">关于</h3><div class="item__content"><p class="item__text">本站是基于 Hexo 搭建的静态资源博客，主要用于分享日常学习、生活及工作的一些心得总结。</p><ul class="footer__contact-info"><li class="contact-info__item"><i class="iconfont icon-address"></i> <span>Beijing, China</span></li><li class="contact-info__item"><i class="iconfont icon-email2"></i> <span>xv44586@gmail.com</span></li></ul></div></div><div class="footer-top__item"><h3 class="item__title">友情链接</h3><div class="item__content"><ul class="footer-top__list"><li class="list-item"><a href="http://www.matrix67.com/" title="Matrix67" target="_blank">Matrix67</a></li><li class="list-item"><a href="https://spaces.ac.cn/" title="Spaces" target="_blank">科学空间</a></li></ul></div></div></div></section><section class="footer__bottom"><div class="page__container footer__container"><p class="footer__copyright">© <a href="https://github.com/Mrminfive/hexo-theme-skapp" target="_blank">Skapp</a> 2017 powered by <a href="http://hexo.io/" target="_blank">Hexo</a>, made by <a href="https://github.com/Mrminfive" target="_blank">minfive</a>. modified by <a href="https://github.com/xv44586" target="_blank">小蛋子</a></p><ul class="footer__social-network clearfix"><li class="social-network__item"><a href="https://github.com/xv44586" target="_blank" title="github"><i class="iconfont icon-github"></i></a></li><li class="social-network__item"><a href="xv44586@gmail.com" target="_blank" title="email"><i class="iconfont icon-email"></i></a></li></ul></div></section></footer><div id="back-top" class="back-top back-top--hidden js-hidden"><i class="iconfont icon-top"></i></div></div><script src="/js/common.js"></script><script src="/js/page/post.js"></script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
            tex2jax: {
                inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
                processEscapes: true,
                skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
            }
            });</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
            var all = MathJax.Hub.getAllJax(), i;
                for (i=0; i < all.length; i += 1) {
                all[i].SourceElement().parentNode.className += ' has-jax';
                }
            });</script><script type="text/javascript" src="//cdn.jsdelivr.net/npm/mathjax@2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script></body></html>