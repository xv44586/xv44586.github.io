<!DOCTYPE html><html lang="zh-cn"><head><meta name="generator" content="Hexo 3.9.0"><meta charset="utf-8"><title>ccf问答匹配比赛 | 小蛋子</title><meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no"><meta name="format-detection" content="telephone=no"><meta name="author" content="[object Object]"><meta name="designer" content="minfive"><meta name="keywords" content="NLP, 机器学习, 深度学习, Python, Backend"><meta name="description" content="NLP | Machine Learning | Developer"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black"><meta name="format-detection" content="telephone=yes"><meta name="mobile-web-app-capable" content="yes"><meta name="robots" content="all"><link rel="canonical" href="https://xv44586.github.io/2020/11/08/ccf-qa/index.html"><link rel="icon" type="image/png" href="/img/favicon.ico" sizes="32x32"><meta name="google-site-verification" content="tbK2z0UTHcAWdqNCgEwykaDA9vvvXnN4ZSp_LFbAbDc"><meta name="baidu-site-verification" content="NBO0j1DAOy"><meta name="baidu-site-verification" content="ulZR80nUkv"><link rel="stylesheet" href="/scss/base/index.css"><link rel="alternate" href="/atom.xml" title="小蛋子"><script>var _hmt=_hmt||[];!function(){var e=document.createElement("script"),t=(e.src="https://hm.baidu.com/hm.js?b1d2a1d2b250300950a8ffb5caa20818",document.getElementsByTagName("script")[0]);t.parentNode.insertBefore(e,t)}()</script><link rel="stylesheet" href="/scss/views/page/post.css"><link rel="alternate" href="/atom.xml" title="小蛋子" type="application/atom+xml"></head><body ontouchstart><div id="page-loading" class="page page-loading" style="background-image:url(/other/loading.gif)"></div><div id="page" class="page js-hidden"><header class="page__small-header page__header--small"><nav class="page__navbar"><div class="page__container navbar-container"><a class="page__logo" href="/" title="小蛋子" alt="小蛋子"><img src="/img/lg.png" alt="小蛋子"></a><nav class="page__nav"><ul class="nav__list clearfix"><li class="nav__item"><a href="/" alt="首页" title="首页">首页</a></li><li class="nav__item"><a href="/archives" alt="归档" title="归档">归档</a></li><li class="nav__item"><a href="/about" alt="关于" title="关于">关于</a></li></ul></nav><button class="page__menu-btn" type="button"><i class="iconfont icon-menu"></i></button></div></nav></header><main class="page__container page__main"><div class="page__content"><article class="page__post"><div class="post__cover"><img src="/2020/11/08/ccf-qa/pet.png" alt="ccf问答匹配比赛"></div><header class="post__info"><h1 class="post__title">ccf问答匹配比赛</h1><div class="post__mark"><div class="mark__block"><i class="mark__icon iconfont icon-write"></i><ul class="mark__list clearfix"><li class="mark__item"><a href="https://github.com/xv44586">小蛋子</a></li></ul></div><div class="mark__block"><i class="mark__icon iconfont icon-time"></i><ul class="mark__list clearfix"><li class="mark__item"><span>2020-11-08</span></li></ul></div><div class="mark__block"><i class="mark__icon iconfont icon-tab"></i><ul class="mark__list clearfix"><li class="mark__item"><a href="/tags/QA/">QA</a></li><li class="mark__item"><a href="/tags/CCF/">CCF</a></li><li class="mark__item"><a href="/tags/Competition/">Competition</a></li></ul></div><div class="mark__block"><i class="mark__icon iconfont icon-eye"></i><ul class="mark__list clearfix"><li id="busuanzi_container_page_pv" class="mark__item"><span id="busuanzi_value_page_pv"></span>次</li></ul></div></div></header><div class="post__content"><div class="toc"><ul><li><a href="#bi-sai-shuo-ming">比赛说明</a></li><li><a href="#baseline">baseline</a><ul><li><a href="#qa-pair">qa pair</a></li><li><a href="#point">point</a></li><li><a href="#pet">pet</a></li><li><a href="#update-concat">update: concat</a></li></ul></li><li><a href="#dui-bi">对比</a></li><li><a href="#chang-shi">尝试</a><ul><li><a href="#post-training">Post-training</a></li><li><a href="#focal-loss">focal loss</a></li><li><a href="#dui-kang-xun-lian-yu-ti-du-cheng-fa">对抗训练与梯度惩罚</a></li><li><a href="#tricks">tricks</a></li></ul></li><li><a href="#zong-jie">总结</a></li><li><a href="#guan-yu-tou-tu">关于头图</a></li></ul></div><p>这两周玩了一下ccf 2020 中的<a href="https://www.datafountain.cn/competitions/474" target="_blank" rel="noopener">房产聊天问答匹配</a>比赛，虽然还没完赛，但是先总结一下目前的收获。</p><h1><span id="bi-sai-shuo-ming">比赛说明</span><a href="#bi-sai-shuo-ming" class="header-anchor"></a></h1><p>首先，这个比赛的任务是在一系列回答中找到针对客户问题的回答。而客户提问前的对话及回答前的对话都是不可见的，即整个IM信息是不连续的，任务就是在不连续的回答中找到那些针对客户问题的答案。样本示例：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">query: 采荷一小是分校吧。</span><br><span class="line">reply:</span><br><span class="line">  是的  <span class="number">0</span></span><br><span class="line">  杭州市采荷第一小学钱江苑校区，杭州市钱江新城实验学校。  <span class="number">1</span></span><br><span class="line">  这是五楼  <span class="number">0</span></span><br></pre></td></tr></table></figure><p></p><p>可以看到，样本中所谓的针对问题的回答，不仅仅是直接回答问题的答案，而是更有针对性和说明的回答。</p><h1><span id="baseline">baseline</span><a href="#baseline" class="header-anchor"></a></h1><p>模型选择上，baseline全部使用bert，鉴于相对位置编码优于绝对位置编码，所以选择<a href="https://github.com/huawei-noah/Pretrained-Language-Model/tree/master/NEZHA-TensorFlow" target="_blank" rel="noopener">NEZHA</a>作为预训练权重。备选方案Roberta。</p><h2><span id="qa-pair">qa pair</span><a href="#qa-pair" class="header-anchor"></a></h2><p>由于回答是不连续的，所以可以将问题和答案一一对应，组成qa pair，然后分别判断是否是针对问题的回答。</p><p><img src="/2020/11/08/ccf-qa/pair.png" alt="pair"></p><h2><span id="point">point</span><a href="#point" class="header-anchor"></a></h2><p>虽然对话是不连续的，但是是同一个对话，所以不同的回答能相互支撑，提供部分信息，所以，第二种思路就是将同一个问题的所有回答都拼接在当前回答后面，然后同时对每一个回答进行判断。</p><p><img src="/2020/11/08/ccf-qa/point.png" alt="point"></p><h2><span id="pet">pet</span><a href="#pet" class="header-anchor"></a></h2><p>由于预训练模型使用的语料与当前任务所处领域有一定的gap，所以一个比较简单的想法是先在任务语料上进行Post-training，然后再进行fine-tuning。不过，上次我们介绍过<code>Pattern-Exploiting Training</code>,不了解的可以参考<a href="https://xv44586.github.io/2020/10/25/pet/">PET-文本分类的又一种妙解</a>。借鉴PET的方式，我们将posting-training与fine-tuning结合，即在label data上进行pattern exploiting training，在unlable data上进行mlm任务进行post-traing.</p><p><img src="/2020/11/08/ccf-qa/pet.png" alt="pet"></p><p>以上三种baseline的代码放在<a href="https://github.com/xv44586/ccf_2020_qa_match" target="_blank" rel="noopener">ccf_2020_qa_match</a>,感兴趣的可以查阅。</p><h2><span id="update-concat">update: concat</span><a href="#update-concat" class="header-anchor"></a></h2><p>由于bert 不同的transformer 层提取到的语义粒度不同，而不同粒度的信息对分类来说起到的作用也不同，所以可以concat所以粒度的语义信息，拼接后作为特征进行分类。<br><img src="/2020/11/08/ccf-qa/concat.png" alt="concat"></p><h1><span id="dui-bi">对比</span><a href="#dui-bi" class="header-anchor"></a></h1><p>第一种方案（pair-wise），由于缺少一定的上下文信息，加上很多回答都非常短，同时又可能会离提问”较远”，所以效果是最差的，不过线上提交单模型也有0.75左右了，所以bert确实强大！<br>第二种方案（point）中，将所有已知的上下文信息都整合到一起，所以相对上一种有所提升，不过由于这种上下文的可见性，所以也会带来一定的迷惑：即对某一个reply来说，假如其他的reply中有一个是针对性的回答，就有可能会干扰对当前reply的判断。<br>第三种方案（pet）中，通过mlm进行post-training，可以将领域间的gap缩小，同时，由于在训练时”看到”了测试数据，也在一定程度上减小了线上线下的差距，所以性能是最好的，单模型最好能达到0.765左右。</p><h1><span id="chang-shi">尝试</span><a href="#chang-shi" class="header-anchor"></a></h1><h2><span id="post-training">Post-training</span><a href="#post-training" class="header-anchor"></a></h2><p>第一个想法是尝试进行post-training，来提升所有方案的性能。由于问答之间是不连续的，所以在组织语料上进行了不同方式：</p><ol><li>query-reply pair</li><li>query-reply-list pair</li><li>cut-sentence to make pair</li></ol><p>以上文提到的样本为例；</p><ol><li>query-reply pair:</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">采荷一小是分校吧。</span><br><span class="line">是的</span><br><span class="line"></span><br><span class="line">采荷一小是分校吧。</span><br><span class="line">杭州市采荷第一小学钱江苑校区，杭州市钱江新城实验学校。</span><br><span class="line">...</span><br></pre></td></tr></table></figure><ol start="2"><li><p>query-reply-list pair</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">采荷一小是分校吧。</span><br><span class="line">是的 杭州市采荷第一小学钱江苑校区，杭州市钱江新城实验学校。  这是五楼</span><br><span class="line"></span><br><span class="line">...</span><br></pre></td></tr></table></figure></li><li><p>cut-sentence to make pair</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">采荷一小</span><br><span class="line">是分校吧。</span><br><span class="line"></span><br><span class="line">是</span><br><span class="line">的</span><br><span class="line"></span><br><span class="line">杭州市采荷第一小学钱江苑校区，</span><br><span class="line">杭州市钱江新城实验学校。</span><br><span class="line">...</span><br></pre></td></tr></table></figure></li></ol><p>第一种，将同一对话作为同一篇文档顺序排列；第二种，将问题作为单独文档，同一问题的所有回答作为单独文档，第三种，将问题和回答都作为单独文档，同时将其拆分为左右两个部分来做nsp任务。<br>在mask选择上，选择动态mask，即每个epoch都重新选择mask的token。</p><p>最终结果是如果直接使用<code>[CLS]</code>做最终特征，以上三种都不能带来pair-wise方案的提升，反而会带来不小的降低，猜测原因可能与以上三种方式的nsp任务与当前任务的模式不同，所以反而会引起降低。而在bert 后面接其他层（AttentionPooling1D，DGCNN）后能带来大约一个点左右提升。</p><h2><span id="focal-loss">focal loss</span><a href="#focal-loss" class="header-anchor"></a></h2><p>由于针对性回答与非针对性回答在数量上有不小差距，大约3:1，所以也想到尝试在loss上进行调节。<br>最终结果是没有多少提升，最后将普通loss训练后的模型在train data上进行了predict，并借鉴之前<a href="https://xv44586.github.io/2020/10/14/focal-loss/">focal loss</a>中的方式分析了一下，画出对应的难易样本分布。<br><img src="/2020/11/08/ccf-qa/focalloss.png" alt></p><p>上图中不难发现其难样本并不多也不聚集，所以focal loss并不能带来提升。</p><h2><span id="dui-kang-xun-lian-yu-ti-du-cheng-fa">对抗训练与梯度惩罚</span><a href="#dui-kang-xun-lian-yu-ti-du-cheng-fa" class="header-anchor"></a></h2><p>对抗训练与梯度惩罚也是两种比较有效的提升模型泛化性能的方法。其中对抗采用的FGM。<br>最终实验后发现两者都能带来线上线下的提升，尤其是对抗，最高能提升三个点，不过相同参数下结果也会差二个点左右，所以每个模型都要少不了调参的过程，所以适合后期提高时使用。</p><h2><span id="tricks">tricks</span><a href="#tricks" class="header-anchor"></a></h2><p>由于也是第一次做比赛，所以走了不少弯路，也学到了一些trick：</p><ol><li>对样本进行kfold然后训练，得到k个模型再进行ensemble。其中k从5增加到10，也会有提升。这种方式的好处是可以让更多的数据参与到训练，同时多个模型进行投票，也会带来或多或少的提升。</li><li>对数据进行post-training，虽然我的尝试暂时没有起到提升，但是交流时有其他组的同学通过这个方法就达到单模型0.77以上。而我三种方案对比，pet的方式也是最好的，所以也在一定程度上说明这种方式的有效性。</li><li>bert后接新的层，如cnn,dgcnn等。虽然bert的特征提取能力强大，但是在bert后面接一些新的层，总能带来一定的提升，尤其是DGCNN。这种方式可以看作是两种模型的stacking，即利用bert做特征提取，后面的模型在其上做下游任务。</li><li>不同模型进行ensemble，如将上述三种方案进行ensemble，由于不同模型关注点不同，融合后会带来一定提升。</li><li>更大的模型，如bert-xxlarge等。虽然我的显卡没法实验这种方案，但是交流后发现很多同学都是使用的大模型，baseline就可以达到0.77以上了，所以有时候还是需要一些”钞能力”.</li><li>数据清洗与增强。交流中有人提到用外部数据做增强，所以如果有能力，先做清洗与增强，结果也会提升很多。</li></ol><h1><span id="zong-jie">总结</span><a href="#zong-jie" class="header-anchor"></a></h1><p>以上就是对当前比赛的一些思考与总结，现在单模型最好的成绩为线上<code>0.7779</code>, 虽然只排到61名，不过鉴于我使用的是base模型，同时也是单模型，没有任何其他后续处理，所以结果感觉还行。后续完赛后如果有新的收获再更新一篇吧。最后，附上暂时排名截图。</p><p><img src="/2020/11/08/ccf-qa/leadboard.png" alt></p><h1><span id="guan-yu-tou-tu">关于头图</span><a href="#guan-yu-tou-tu" class="header-anchor"></a></h1><div class="post__prevs"><div class="post__prev"><a href="/2020/10/25/pet/" title="PET-文本分类的又一种妙解"><i class="iconfont icon-prev"></i>PET-文本分类的又一种妙解</a></div><div class="post__prev post__prev--right"><a href="/2020/11/10/eda/" title="NLP中的数据增强">NLP中的数据增强<i class="iconfont icon-next"></i></a></div></div></div></article></div><aside class="page__sidebar"><form id="page-search-from" class="page__search-from" action="/search/"><label class="search-form__item"><input class="input" type="text" name="search" placeholder="Search..."> <i class="iconfont icon-search"></i></label></form><div class="sidebar__block"><h3 class="block__title">简介</h3><p class="block__text">NLP | Machine Learning | Developer</p></div><div class="sidebar__block"><h3 class="block__title">文章分类</h3><ul class="block-list"><li class="block-list-item"><a class="block-list-link" href="/categories/Programming/">Programming</a><span class="block-list-count">3</span></li><li class="block-list-item"><a class="block-list-link" href="/categories/NLP/">NLP</a><span class="block-list-count">26</span></li><li class="block-list-item"><a class="block-list-link" href="/categories/Math/">Math</a><span class="block-list-count">5</span></li><li class="block-list-item"><a class="block-list-link" href="/categories/MachineLearning/">MachineLearning</a><span class="block-list-count">8</span></li><li class="block-list-item"><a class="block-list-link" href="/categories/Life/">Life</a><span class="block-list-count">6</span></li></ul></div><div class="sidebar__block"><h3 class="block__title">最新文章</h3><ul class="block-list latest-post-list"><li class="latest-post-item"><a href="/2022/05/23/faster-decoder/" title="faster-decoder之 decoder解码加速"><div class="item__cover"><img src="/2022/05/23/faster-decoder/Psyduck.jpeg" alt="faster-decoder之 decoder解码加速"></div><div class="item__info"><h3 class="item__title">faster-decoder之 decoder解码加速</h3><span class="item__text">2022-05-23</span></div></a></li><li class="latest-post-item"><a href="/2021/08/14/speed-up/" title="speed-up"><div class="item__cover"><img src="/2021/08/14/speed-up/puppy.jpeg" alt="speed-up"></div><div class="item__info"><h3 class="item__title">speed-up</h3><span class="item__text">2021-08-14</span></div></a></li><li class="latest-post-item"><a href="/2021/07/06/cl2rdrop/" title="对比学习心路历程"><div class="item__cover"><img src="/2021/07/06/cl2rdrop/ai.jpeg" alt="对比学习心路历程"></div><div class="item__info"><h3 class="item__title">对比学习心路历程</h3><span class="item__text">2021-07-06</span></div></a></li><li class="latest-post-item"><a href="/2021/03/28/multi-task/" title="多任务学习-以天池比赛为例的三种思路"><div class="item__cover"><img src="/2021/03/28/multi-task/bg.jpeg" alt="多任务学习-以天池比赛为例的三种思路"></div><div class="item__info"><h3 class="item__title">多任务学习-以天池比赛为例的三种思路</h3><span class="item__text">2021-03-28</span></div></a></li></ul></div><div class="sidebar__block"><h3 class="block__title">文章标签</h3><ul class="block-list tag-list clearfix"><li class="tag-item"><a class="tag-link" href="/tags/BERT/">BERT</a></li><li class="tag-item"><a class="tag-link" href="/tags/Bagging/">Bagging</a></li><li class="tag-item"><a class="tag-link" href="/tags/Boosting/">Boosting</a></li><li class="tag-item"><a class="tag-link" href="/tags/CCF/">CCF</a></li><li class="tag-item"><a class="tag-link" href="/tags/CRF/">CRF</a></li><li class="tag-item"><a class="tag-link" href="/tags/CUDA/">CUDA</a></li><li class="tag-item"><a class="tag-link" href="/tags/Classification/">Classification</a></li><li class="tag-item"><a class="tag-link" href="/tags/Competition/">Competition</a></li><li class="tag-item"><a class="tag-link" href="/tags/Contrastive-Learning/">Contrastive Learning</a></li><li class="tag-item"><a class="tag-link" href="/tags/Deep-Learning/">Deep Learning</a></li><li class="tag-item"><a class="tag-link" href="/tags/Distillation/">Distillation</a></li><li class="tag-item"><a class="tag-link" href="/tags/EDA/">EDA</a></li><li class="tag-item"><a class="tag-link" href="/tags/FastBERT/">FastBERT</a></li><li class="tag-item"><a class="tag-link" href="/tags/Few-shot/">Few-shot</a></li><li class="tag-item"><a class="tag-link" href="/tags/Game/">Game</a></li><li class="tag-item"><a class="tag-link" href="/tags/Glove/">Glove</a></li><li class="tag-item"><a class="tag-link" href="/tags/Hexo/">Hexo</a></li><li class="tag-item"><a class="tag-link" href="/tags/LR/">LR</a></li><li class="tag-item"><a class="tag-link" href="/tags/Language-Model/">Language Model</a></li><li class="tag-item"><a class="tag-link" href="/tags/Loss/">Loss</a></li><li class="tag-item"><a class="tag-link" href="/tags/MarkDown/">MarkDown</a></li><li class="tag-item"><a class="tag-link" href="/tags/Math/">Math</a></li><li class="tag-item"><a class="tag-link" href="/tags/Matrix/">Matrix</a></li><li class="tag-item"><a class="tag-link" href="/tags/NLG/">NLG</a></li><li class="tag-item"><a class="tag-link" href="/tags/Optimizer/">Optimizer</a></li><li class="tag-item"><a class="tag-link" href="/tags/Python/">Python</a></li><li class="tag-item"><a class="tag-link" href="/tags/QA/">QA</a></li><li class="tag-item"><a class="tag-link" href="/tags/R-Drop/">R-Drop</a></li><li class="tag-item"><a class="tag-link" href="/tags/Random-Forest/">Random Forest</a></li><li class="tag-item"><a class="tag-link" href="/tags/Segmentation/">Segmentation</a></li><li class="tag-item"><a class="tag-link" href="/tags/SimCSE/">SimCSE</a></li><li class="tag-item"><a class="tag-link" href="/tags/Statistics/">Statistics</a></li><li class="tag-item"><a class="tag-link" href="/tags/Survey/">Survey</a></li><li class="tag-item"><a class="tag-link" href="/tags/T5/">T5</a></li><li class="tag-item"><a class="tag-link" href="/tags/UniLM/">UniLM</a></li><li class="tag-item"><a class="tag-link" href="/tags/Words-Distance/">Words Distance</a></li><li class="tag-item"><a class="tag-link" href="/tags/Xgboost/">Xgboost</a></li><li class="tag-item"><a class="tag-link" href="/tags/faster-decoder/">faster decoder</a></li><li class="tag-item"><a class="tag-link" href="/tags/multi-task/">multi-task</a></li><li class="tag-item"><a class="tag-link" href="/tags/npm/">npm</a></li><li class="tag-item"><a class="tag-link" href="/tags/simbert/">simbert</a></li><li class="tag-item"><a class="tag-link" href="/tags/skipgram/">skipgram</a></li><li class="tag-item"><a class="tag-link" href="/tags/swift/">swift</a></li><li class="tag-item"><a class="tag-link" href="/tags/tensorflow-gpu/">tensorflow-gpu</a></li><li class="tag-item"><a class="tag-link" href="/tags/word2vec/">word2vec</a></li><li class="tag-item"><a class="tag-link" href="/tags/信息熵/">信息熵</a></li><li class="tag-item"><a class="tag-link" href="/tags/新词发现/">新词发现</a></li><li class="tag-item"><a class="tag-link" href="/tags/样本不均衡/">样本不均衡</a></li><li class="tag-item"><a class="tag-link" href="/tags/装机/">装机</a></li><li class="tag-item"><a class="tag-link" href="/tags/领域词挖掘/">领域词挖掘</a></li></ul></div></aside></main><footer class="page__footer"><section class="footer__top"><div class="page__container footer__container"><div class="footer-top__item footer-top__item--2"><h3 class="item__title">关于</h3><div class="item__content"><p class="item__text">本站是基于 Hexo 搭建的静态资源博客，主要用于分享日常学习、生活及工作的一些心得总结。</p><ul class="footer__contact-info"><li class="contact-info__item"><i class="iconfont icon-address"></i> <span>Beijing, China</span></li><li class="contact-info__item"><i class="iconfont icon-email2"></i> <span>xv44586@gmail.com</span></li></ul></div></div><div class="footer-top__item"><h3 class="item__title">友情链接</h3><div class="item__content"><ul class="footer-top__list"><li class="list-item"><a href="http://www.matrix67.com/" title="Matrix67" target="_blank">Matrix67</a></li><li class="list-item"><a href="https://spaces.ac.cn/" title="Spaces" target="_blank">科学空间</a></li></ul></div></div></div></section><section class="footer__bottom"><div class="page__container footer__container"><p class="footer__copyright">© <a href="https://github.com/Mrminfive/hexo-theme-skapp" target="_blank">Skapp</a> 2017 powered by <a href="http://hexo.io/" target="_blank">Hexo</a>, made by <a href="https://github.com/Mrminfive" target="_blank">minfive</a>. modified by <a href="https://github.com/xv44586" target="_blank">小蛋子</a></p><ul class="footer__social-network clearfix"><li class="social-network__item"><a href="https://github.com/xv44586" target="_blank" title="github"><i class="iconfont icon-github"></i></a></li><li class="social-network__item"><a href="xv44586@gmail.com" target="_blank" title="email"><i class="iconfont icon-email"></i></a></li></ul></div></section></footer><div id="back-top" class="back-top back-top--hidden js-hidden"><i class="iconfont icon-top"></i></div></div><script src="/js/common.js"></script><script src="/js/page/post.js"></script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
            tex2jax: {
                inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
                processEscapes: true,
                skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
            }
            });</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
            var all = MathJax.Hub.getAllJax(), i;
                for (i=0; i < all.length; i += 1) {
                all[i].SourceElement().parentNode.className += ' has-jax';
                }
            });</script><script type="text/javascript" src="//cdn.jsdelivr.net/npm/mathjax@2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script></body></html>