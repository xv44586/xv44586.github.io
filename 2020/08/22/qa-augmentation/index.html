<!DOCTYPE html><html lang="zh-cn"><head><meta name="generator" content="Hexo 3.9.0"><meta charset="utf-8"><title>模型增强（1）&#58; 利用NLG 增强QA 任务性能 | 小蛋子</title><meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no"><meta name="format-detection" content="telephone=no"><meta name="author" content="[object Object]"><meta name="designer" content="minfive"><meta name="keywords" content="NLP, 机器学习, 深度学习, Python, Backend"><meta name="description" content="NLP | Machine Learning | Developer"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black"><meta name="format-detection" content="telephone=yes"><meta name="mobile-web-app-capable" content="yes"><meta name="robots" content="all"><link rel="canonical" href="https://xv44586.github.io/2020/08/22/qa-augmentation/index.html"><link rel="icon" type="image/png" href="/img/favicon.ico" sizes="32x32"><meta name="google-site-verification" content="tbK2z0UTHcAWdqNCgEwykaDA9vvvXnN4ZSp_LFbAbDc"><meta name="baidu-site-verification" content="NBO0j1DAOy"><meta name="baidu-site-verification" content="ulZR80nUkv"><link rel="stylesheet" href="/scss/base/index.css"><link rel="alternate" href="/atom.xml" title="小蛋子"><script>var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?b1d2a1d2b250300950a8ffb5caa20818";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><link rel="stylesheet" href="/scss/views/page/post.css"><link rel="alternate" href="/atom.xml" title="小蛋子" type="application/atom+xml"></head><body ontouchstart><div id="page-loading" class="page page-loading" style="background-image:url(/other/loading.gif)"></div><div id="page" class="page js-hidden"><header class="page__small-header page__header--small"><nav class="page__navbar"><div class="page__container navbar-container"><a class="page__logo" href="/" title="小蛋子" alt="小蛋子"><img src="/img/lg.png" alt="小蛋子"></a><nav class="page__nav"><ul class="nav__list clearfix"><li class="nav__item"><a href="/" alt="首页" title="首页">首页</a></li><li class="nav__item"><a href="/archives" alt="归档" title="归档">归档</a></li><li class="nav__item"><a href="/about" alt="关于" title="关于">关于</a></li></ul></nav><button class="page__menu-btn" type="button"><i class="iconfont icon-menu"></i></button></div></nav></header><main class="page__container page__main"><div class="page__content"><article class="page__post"><div class="post__cover"><img src="/2020/08/22/qa-augmentation/cat.JPG" alt="模型增强（1）&#58; 利用NLG 增强QA 任务性能"></div><header class="post__info"><h1 class="post__title">模型增强（1）&#58; 利用NLG 增强QA 任务性能</h1><div class="post__mark"><div class="mark__block"><i class="mark__icon iconfont icon-write"></i><ul class="mark__list clearfix"><li class="mark__item"><a href="https://github.com/xv44586">小蛋子</a></li></ul></div><div class="mark__block"><i class="mark__icon iconfont icon-time"></i><ul class="mark__list clearfix"><li class="mark__item"><span>2020-08-22</span></li></ul></div><div class="mark__block"><i class="mark__icon iconfont icon-tab"></i><ul class="mark__list clearfix"><li class="mark__item"><a href="/tags/QA/">QA</a></li><li class="mark__item"><a href="/tags/NLG/">NLG</a></li><li class="mark__item"><a href="/tags/UniLM/">UniLM</a></li></ul></div><div class="mark__block"><i class="mark__icon iconfont icon-eye"></i><ul class="mark__list clearfix"><li id="busuanzi_container_page_pv" class="mark__item"><span id="busuanzi_value_page_pv"></span>次</li></ul></div></div></header><div class="post__content"><div class="toc"><ul><li><a href="#bei-jing">背景</a></li><li><a href="#unilm">UniLM</a></li><li><a href="#shu-ju-zeng-qiang">数据增强</a></li><li><a href="#shi-yan">实验</a><ul><li><a href="#wen-ti-sheng-cheng">问题生成</a></li><li><a href="#wen-ti-da-an-dui-sheng-cheng">问题答案对生成</a></li></ul></li><li><a href="#zong-jie">总结</a></li><li><a href="#guan-yu-tou-tu">关于头图</a></li></ul></div><h1><span id="bei-jing">背景</span><a href="#bei-jing" class="header-anchor"></a></h1><p>上周打算把UniLM在<a href="https://github.com/xv44586/toolkit4nlp" target="_blank" rel="noopener">toolkit4nlp</a>的基础上实现一下，又刷了一遍<a href="https://arxiv.org/pdf/1905.03197.pdf" target="_blank" rel="noopener">论文</a>,发现作者提到用UniLM做问题生成，来增强QA任务的性能，觉得很有意思，所以想尝试一下。</p><h1><span id="unilm">UniLM</span><a href="#unilm" class="header-anchor"></a></h1><p>因为这篇 UniLM 是主角，所以简单介绍一下该模型。该模型是通过灵活使用 attention mask ，将 NLG 与 NLU 任务统一在来一起，所以叫 unified LM，<br>他的做法是将 left-to-right/right-to-left/masked lm/seq2seq lm/放在一个框架里训练，从而让模型兼具 NLU 与 NLG 的能力。<br><img src="/2020/08/22/qa-augmentation/lm.png" alt><br>而为了达到这个训练，只需要在 bert 的基础上根据不同的 lm 调整 attention mask 即可。所以利用 bert 做 NLG 时，只需要调整 attention mask<br>为 seq2seq lm 对应mask即可。</p><h1><span id="shu-ju-zeng-qiang">数据增强</span><a href="#shu-ju-zeng-qiang" class="header-anchor"></a></h1><p>通常增强都是同义词/近义词替换，subsequence的随机删除/重复/互换等，我之前在做百度比赛时尝试过随机删除和随机两个片段互换位置，提升不是<br>非常大而论文里大问题生成带来大提升还是相当大的：<br><img src="/2020/08/22/qa-augmentation/table9.png" alt><br>仔细想一下，由于attention机制，互换只是改变了position embedding部分内容，而这部分的互换对模型的影响是很弱的；随机删除可能会破坏语义，<br>所以增加模型robust的同时可能会降低模型性能。而问题生成，则可以看作是同义词/近义词替换的句子级别替换，所以理论上能带来不错的提升。<br>从对抗的角度来看，生成的问题在语义上与原问题基本一致，这也正好符合<code>输入的微小改变</code>，从而让模型在这种带有微小扰动的前提下仍然能很好的预测。</p><h1><span id="shi-yan">实验</span><a href="#shi-yan" class="header-anchor"></a></h1><p>既然UniLM具有很强的NLG能力能力，那就有很多不同的玩法。首先，可以训练一个模型，来针对 context 和 answer 生成对应的问题，来对问题进行<br><code>“换个问法”</code>，其次，既然可以对问题<cdoe>“换个问法”,自然也可以<code>“换个问题”</code>,也就是根据 context 生成新的问题<br>和答案。另外，由于是扩增训练数据，所以有一个技巧是做生成是将 train data 与 dev data 互换，不过由于我用的是百度比赛数据，dev data 太少，<br>所以我是 train + dev。</cdoe></p><h2><span id="wen-ti-sheng-cheng">问题生成</span><a href="#wen-ti-sheng-cheng" class="header-anchor"></a></h2><p>问题生成时，就是将 context 与 answer 拼接，然后生成对应的question。具体样本形如：<code>[CLS] answer + context [SEP] question [SEP]</code> .<br>模型直接用bert base权重按UniLM的seq2seq方式来构建，可以看到效果还是很不错的，比如：</p><blockquote><br>context：报雅思或者托付培训班,一般情况下要900元左右。 雅思和托福考试可以自学: 一、基础知识准备:单词、基本语法、长难句分析; 二、板块训练:听说读写,四个板块; 三、合理备考计划,可以参见中国上别人经验结合自己的自身条件; 四、效果强化跟踪,使用合理的备考软件或者是自测题目随时跟踪自己的学习状态<br>question：雅思班价格<br>answer: [‘900元’, ‘900元左右’]<br>generate question: 雅思班报名多少钱<br></blockquote><blockquote>context：USB电压有5伏 USB一般4根线, 中间两根是数据线, 左右各为 +- 线 只要不短路是不会烧主板该插口的 ,我想你应该这样做,手机的线的一端直接插入手提电脑,另一头剪掉头子,从线中分离出四根线, 用万用表测出(红色+和其它色如黑-)剩下两根用胶布包扎(不用)然后 在这两根线上(正电极中最好串一50到100欧电阻)后接入一支高亮度发光二极管就成功了.<br>question：usb线电压<br>answer: [‘5伏’]<br>generate question: usb线电压</blockquote><p>解码时，有两种选择：随机抽样与 beam search 。随机抽样可以增加问题的多样性，并且可以生成多个问题；beam search近似最优，得到一个最优的<br>问题。由于我们是使用 train data 训练模型，在对 train data 生成新的问题时，beam search 将可能产生很多一摸一样的问题，这样将降低新增<br>数据的量；而随机抽样能产生很多新的问题，但可能新生成的问题与答案并不配套，还需要一些后处理之后才能真正拿来用。这里两种方式都拿来做实验，<br>并对生成的问题做一个简单的过滤：新生成的问题与原问题中有70%以上的字是重合的。<br>$$<br>\begin{array}{c|c|c}<br>\hline \\<br>\text{base line} &amp; \text{beam search} &amp; \text{random sample}\\<br>\hline \\<br>80.39\% &amp; 81.0\% &amp; 79.8\%<br>\end{array}<br>$$</p><p>random sample的样本经过了很多次过滤之后才能基本达到baseline的效果，所以生成的问题如果”问非所答”，对最终的效果反而是不好的，这也符合预期。</p><h2><span id="wen-ti-da-an-dui-sheng-cheng">问题答案对生成</span><a href="#wen-ti-da-an-dui-sheng-cheng" class="header-anchor"></a></h2><p>问题答案对生成时，由于答案是在 context 内的，相对问题生成简单一些，所以我们先生成答案，再根据 context 和生成的 answer 来生成对应的<br>question。不过为了让问题答案对更丰富多样，解码答案时我们采用随机抽样，而生成问题时，为了让问题尽量准确，我们采用 beam search。<br>样本形如 <code>[CLS]context[SEP]answer[SEP][question][SEP]</code>，生成的效果如下：</p><p></p><blockquote><br>context：您好，孕妇整个孕期体重增加12.5公斤左右，在增加的这12.5公斤中，胎儿的体重占3公斤左右，胎盘和羊水约是2公斤左右。在孕早期（怀孕3个月以内）增加2公斤，中期（怀孕3－6个月）以及末期（怀孕7－9个月）各增加5公斤左右。所以怀孕6个月体重增加7公斤左右比较正常。希望我的回答对你有所帮助。<br>question：孕妇6个月体重增加多少<br>answer: 7公斤左右<br>generate question: 孕妇6个月体重增加多少<br>generate answer: 12.5公斤左右<br></blockquote><br>不过也由于train data 参与训练，所以很多生成的问题答案对与原始问题答案对一致，如果有更多的外部数据，可以利用外部数据来训练。<br>$$<br>\begin{array}{c|c|c|c}<br>\hline \\<br>\text{base line} &amp; \text{beam search} &amp; \text{random sample} &amp; \text{question answer generation}\\<br>\hline \\<br>80.39\% &amp; 81.0\% &amp; 79.8\% &amp; 81.76\% \\<br>\hline<br>\end{array}<br>$$<p></p><h1><span id="zong-jie">总结</span><a href="#zong-jie" class="header-anchor"></a></h1><p>通过生成新的问题与新的问题答案对能在一定程度上提高qa 任务的性能，在生成问题时，用beam search 得到的新问题虽然量少但由于更准确，所以<br>能带来一定的提升；用随机采样生成的问题会有部分与答案无关的或者语义有点不通顺的问题，所以可能反而会导致性能降低；问题答案对的生成时，<br>先生成相对简单的回答再生成对应问题，能对性能带来不错的提升，在做qa相关任务时，可以尝试使用一下。<br>实验代码：<br><a href="https://github.com/xv44586/toolkit4nlp/blob/master/examples/qa_baseline.py" target="_blank" rel="noopener">qa_baseline</a><br><a href="https://github.com/xv44586/toolkit4nlp/blob/master/examples/qa_question_generation_seq2seq.py" target="_blank" rel="noopener">qa_question_generation_seq2seq</a><br><a href="https://github.com/xv44586/toolkit4nlp/blob/master/examples/qa_question_answer_generation_seq2seq.py" target="_blank" rel="noopener">qa_question_answer_generation_seq2seq</a></p><h1><span id="guan-yu-tou-tu">关于头图</span><a href="#guan-yu-tou-tu" class="header-anchor"></a></h1><p>看瓜的怒气小猫</p><div class="content-footer-sponsor"><h1><span id="sponsor">Buy me a coffee</span></h1><p>如果觉得这篇文章不错，对你有帮助，欢迎打赏一杯蜜雪冰城。</p><img src="/img/sponsor.JPG" alt="logo" title="sponsor"></div><div class="post__prevs"><div class="post__prev"><a href="/2020/08/19/bert-of-theseus-2/" title="Knowledge Distillation (1) &#58; 模块替换之bert-of-theseus-下篇"><i class="iconfont icon-prev"></i>Knowledge Distillation (1) &#58; 模块替换之bert-of-theseus-下篇</a></div><div class="post__prev post__prev--right"><a href="/2020/08/31/bert-01/" title="Knowledge Distillation (2) &#58; 知识迁移">Knowledge Distillation (2) &#58; 知识迁移<i class="iconfont icon-next"></i></a></div></div></div></article><script src="https://giscus.app/client.js" data-repo="xv44586/giscus" data-repo-id="R_kgDOIC6Ipg" data-category="Announcements" data-category-id="DIC_kwDOIC6Ips4CRkmo" data-mapping="pathname" data-strict="0" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="bottom" data-theme="light" data-lang="zh-CN" crossorigin="anonymous" async></script></div><aside class="page__sidebar"><form id="page-search-from" class="page__search-from" action="/search/"><label class="search-form__item"><input class="input" type="text" name="search" placeholder="Search..."> <i class="iconfont icon-search"></i></label></form><div class="sidebar__block"><h3 class="block__title">简介</h3><p class="block__text">NLP | Machine Learning | Developer</p></div><div class="sidebar__block"><h3 class="block__title">文章分类</h3><ul class="block-list"><li class="block-list-item"><a class="block-list-link" href="/categories/Programming/">Programming</a><span class="block-list-count">4</span></li><li class="block-list-item"><a class="block-list-link" href="/categories/NLP/">NLP</a><span class="block-list-count">33</span></li><li class="block-list-item"><a class="block-list-link" href="/categories/Math/">Math</a><span class="block-list-count">5</span></li><li class="block-list-item"><a class="block-list-link" href="/categories/MachineLearning/">MachineLearning</a><span class="block-list-count">8</span></li><li class="block-list-item"><a class="block-list-link" href="/categories/Life/">Life</a><span class="block-list-count">6</span></li></ul></div><div class="sidebar__block"><h3 class="block__title">最新文章</h3><ul class="block-list latest-post-list"><li class="latest-post-item"><a href="/2023/03/25/gpt4/" title="GPT-4 yes!! but"><div class="item__cover"><img src="/2023/03/25/gpt4/bg.jpeg" alt="GPT-4 yes!! but"></div><div class="item__info"><h3 class="item__title">GPT-4 yes!! but</h3><span class="item__text">2023-03-25</span></div></a></li><li class="latest-post-item"><a href="/2023/03/10/llm-inf/" title="LLM Inference串讲"><div class="item__cover"><img src="/2023/03/10/llm-inf/sd.PNG" alt="LLM Inference串讲"></div><div class="item__info"><h3 class="item__title">LLM Inference串讲</h3><span class="item__text">2023-03-10</span></div></a></li><li class="latest-post-item"><a href="/2023/02/01/fine-tuning-at-few-shot/" title="few-shot视角下的fine-tuning"><div class="item__cover"><img src="/2023/02/01/fine-tuning-at-few-shot/himalayas.JPG" alt="few-shot视角下的fine-tuning"></div><div class="item__info"><h3 class="item__title">few-shot视角下的fine-tuning</h3><span class="item__text">2023-02-01</span></div></a></li><li class="latest-post-item"><a href="/2023/01/09/zero-to-chatgpt/" title="From zero to ChatGPT"><div class="item__cover"><img src="/2023/01/09/zero-to-chatgpt/chatgpt-bg.jpeg" alt="From zero to ChatGPT"></div><div class="item__info"><h3 class="item__title">From zero to ChatGPT</h3><span class="item__text">2023-01-09</span></div></a></li></ul></div><div class="sidebar__block"><h3 class="block__title">文章标签</h3><ul class="block-list tag-list clearfix"><li class="tag-item"><a class="tag-link" href="/tags/BERT/">BERT</a></li><li class="tag-item"><a class="tag-link" href="/tags/BPE/">BPE</a></li><li class="tag-item"><a class="tag-link" href="/tags/Bagging/">Bagging</a></li><li class="tag-item"><a class="tag-link" href="/tags/Boosting/">Boosting</a></li><li class="tag-item"><a class="tag-link" href="/tags/CCF/">CCF</a></li><li class="tag-item"><a class="tag-link" href="/tags/CRF/">CRF</a></li><li class="tag-item"><a class="tag-link" href="/tags/CUDA/">CUDA</a></li><li class="tag-item"><a class="tag-link" href="/tags/ChatGPT/">ChatGPT</a></li><li class="tag-item"><a class="tag-link" href="/tags/Classification/">Classification</a></li><li class="tag-item"><a class="tag-link" href="/tags/Competition/">Competition</a></li><li class="tag-item"><a class="tag-link" href="/tags/Deep-Learning/">Deep Learning</a></li><li class="tag-item"><a class="tag-link" href="/tags/Distillation/">Distillation</a></li><li class="tag-item"><a class="tag-link" href="/tags/EDA/">EDA</a></li><li class="tag-item"><a class="tag-link" href="/tags/FastBERT/">FastBERT</a></li><li class="tag-item"><a class="tag-link" href="/tags/Few-shot/">Few-shot</a></li><li class="tag-item"><a class="tag-link" href="/tags/GPT-3/">GPT-3</a></li><li class="tag-item"><a class="tag-link" href="/tags/GPT-4/">GPT-4</a></li><li class="tag-item"><a class="tag-link" href="/tags/GPU/">GPU</a></li><li class="tag-item"><a class="tag-link" href="/tags/Game/">Game</a></li><li class="tag-item"><a class="tag-link" href="/tags/Glove/">Glove</a></li><li class="tag-item"><a class="tag-link" href="/tags/Hexo/">Hexo</a></li><li class="tag-item"><a class="tag-link" href="/tags/In-context-learning/">In-context learning</a></li><li class="tag-item"><a class="tag-link" href="/tags/Inference/">Inference</a></li><li class="tag-item"><a class="tag-link" href="/tags/LLM/">LLM</a></li><li class="tag-item"><a class="tag-link" href="/tags/LR/">LR</a></li><li class="tag-item"><a class="tag-link" href="/tags/Language-Model/">Language Model</a></li><li class="tag-item"><a class="tag-link" href="/tags/Loss/">Loss</a></li><li class="tag-item"><a class="tag-link" href="/tags/MarkDown/">MarkDown</a></li><li class="tag-item"><a class="tag-link" href="/tags/Math/">Math</a></li><li class="tag-item"><a class="tag-link" href="/tags/Matrix/">Matrix</a></li><li class="tag-item"><a class="tag-link" href="/tags/NLG/">NLG</a></li><li class="tag-item"><a class="tag-link" href="/tags/Optimizer/">Optimizer</a></li><li class="tag-item"><a class="tag-link" href="/tags/Python/">Python</a></li><li class="tag-item"><a class="tag-link" href="/tags/QA/">QA</a></li><li class="tag-item"><a class="tag-link" href="/tags/R-Drop/">R-Drop</a></li><li class="tag-item"><a class="tag-link" href="/tags/Random-Forest/">Random Forest</a></li><li class="tag-item"><a class="tag-link" href="/tags/Segmentation/">Segmentation</a></li><li class="tag-item"><a class="tag-link" href="/tags/SimCSE/">SimCSE</a></li><li class="tag-item"><a class="tag-link" href="/tags/Statistics/">Statistics</a></li><li class="tag-item"><a class="tag-link" href="/tags/Survey/">Survey</a></li><li class="tag-item"><a class="tag-link" href="/tags/T5/">T5</a></li><li class="tag-item"><a class="tag-link" href="/tags/UniLM/">UniLM</a></li><li class="tag-item"><a class="tag-link" href="/tags/Unigram/">Unigram</a></li><li class="tag-item"><a class="tag-link" href="/tags/WordPiece/">WordPiece</a></li><li class="tag-item"><a class="tag-link" href="/tags/Words-Distance/">Words Distance</a></li><li class="tag-item"><a class="tag-link" href="/tags/Xgboost/">Xgboost</a></li><li class="tag-item"><a class="tag-link" href="/tags/debug/">debug</a></li><li class="tag-item"><a class="tag-link" href="/tags/faster-decoder/">faster decoder</a></li><li class="tag-item"><a class="tag-link" href="/tags/fine-tuning/">fine-tuning</a></li><li class="tag-item"><a class="tag-link" href="/tags/horovod/">horovod</a></li><li class="tag-item"><a class="tag-link" href="/tags/multi-task/">multi-task</a></li><li class="tag-item"><a class="tag-link" href="/tags/nohup/">nohup</a></li><li class="tag-item"><a class="tag-link" href="/tags/npm/">npm</a></li><li class="tag-item"><a class="tag-link" href="/tags/simbert/">simbert</a></li><li class="tag-item"><a class="tag-link" href="/tags/skipgram/">skipgram</a></li><li class="tag-item"><a class="tag-link" href="/tags/speed-up/">speed-up</a></li><li class="tag-item"><a class="tag-link" href="/tags/swift/">swift</a></li><li class="tag-item"><a class="tag-link" href="/tags/tensorflow-gpu/">tensorflow-gpu</a></li><li class="tag-item"><a class="tag-link" href="/tags/word2vec/">word2vec</a></li><li class="tag-item"><a class="tag-link" href="/tags/信息熵/">信息熵</a></li><li class="tag-item"><a class="tag-link" href="/tags/新词发现/">新词发现</a></li><li class="tag-item"><a class="tag-link" href="/tags/样本不均衡/">样本不均衡</a></li><li class="tag-item"><a class="tag-link" href="/tags/装机/">装机</a></li><li class="tag-item"><a class="tag-link" href="/tags/领域词挖掘/">领域词挖掘</a></li></ul></div></aside></main><footer class="page__footer"><section class="footer__top"><div class="page__container footer__container"><div class="footer-top__item footer-top__item--2"><h3 class="item__title">关于</h3><div class="item__content"><p class="item__text">本站是基于 Hexo 搭建的静态资源博客，主要用于分享日常学习、生活及工作的一些心得总结。</p><ul class="footer__contact-info"><li class="contact-info__item"><i class="iconfont icon-address"></i> <span>Beijing, China</span></li><li class="contact-info__item"><i class="iconfont icon-email2"></i> <span>xv44586@gmail.com</span></li></ul></div></div><div class="footer-top__item"><h3 class="item__title">友情链接</h3><div class="item__content"><ul class="footer-top__list"><li class="list-item"><a href="http://www.matrix67.com/" title="Matrix67" target="_blank">Matrix67</a></li><li class="list-item"><a href="https://spaces.ac.cn/" title="Spaces" target="_blank">科学空间</a></li></ul></div></div></div></section><section class="footer__bottom"><div class="page__container footer__container"><p class="footer__copyright">© <a href="https://github.com/Mrminfive/hexo-theme-skapp" target="_blank">Skapp</a> 2017 powered by <a href="http://hexo.io/" target="_blank">Hexo</a>, made by <a href="https://github.com/Mrminfive" target="_blank">minfive</a>. modified by <a href="https://github.com/xv44586" target="_blank">小蛋子</a></p><ul class="footer__social-network clearfix"><li class="social-network__item"><a href="https://github.com/xv44586" target="_blank" title="github"><i class="iconfont icon-github"></i></a></li><li class="social-network__item"><a href="xv44586@gmail.com" target="_blank" title="email"><i class="iconfont icon-email"></i></a></li></ul></div></section></footer><div id="back-top" class="back-top back-top--hidden js-hidden"><i class="iconfont icon-top"></i></div></div><script src="/js/common.js"></script><script src="/js/page/post.js"></script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
            tex2jax: {
                inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
                processEscapes: true,
                skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
            }
            });</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
            var all = MathJax.Hub.getAllJax(), i;
                for (i=0; i < all.length; i += 1) {
                all[i].SourceElement().parentNode.className += ' has-jax';
                }
            });</script><script type="text/javascript" src="//cdn.jsdelivr.net/npm/mathjax@2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script></body></html>