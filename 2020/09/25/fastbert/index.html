<!DOCTYPE html><html lang="zh-cn"><head><meta name="generator" content="Hexo 3.9.0"><meta charset="utf-8"><title>Knowledge Distillation (3) &#58; 看样本下菜的FastBERT | 小蛋子</title><meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no"><meta name="format-detection" content="telephone=no"><meta name="author" content="[object Object]"><meta name="designer" content="minfive"><meta name="keywords" content="NLP, 机器学习, 深度学习, Python, Backend"><meta name="description" content="NLP | Machine Learning | Developer"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black"><meta name="format-detection" content="telephone=yes"><meta name="mobile-web-app-capable" content="yes"><meta name="robots" content="all"><link rel="canonical" href="https://xv44586.github.io/2020/09/25/fastbert/index.html"><link rel="icon" type="image/png" href="/img/favicon.ico" sizes="32x32"><meta name="google-site-verification" content="tbK2z0UTHcAWdqNCgEwykaDA9vvvXnN4ZSp_LFbAbDc"><meta name="baidu-site-verification" content="NBO0j1DAOy"><meta name="baidu-site-verification" content="ulZR80nUkv"><link rel="stylesheet" href="/scss/base/index.css"><link rel="alternate" href="/atom.xml" title="小蛋子"><script>var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?b1d2a1d2b250300950a8ffb5caa20818";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><link rel="stylesheet" href="/scss/views/page/post.css"><link rel="alternate" href="/atom.xml" title="小蛋子" type="application/atom+xml"></head><body ontouchstart><div id="page-loading" class="page page-loading" style="background-image:url(/other/loading.gif)"></div><div id="page" class="page js-hidden"><header class="page__small-header page__header--small"><nav class="page__navbar"><div class="page__container navbar-container"><a class="page__logo" href="/" title="小蛋子" alt="小蛋子"><img src="/img/lg.png" alt="小蛋子"></a><nav class="page__nav"><ul class="nav__list clearfix"><li class="nav__item"><a href="/" alt="首页" title="首页">首页</a></li><li class="nav__item"><a href="/archives" alt="归档" title="归档">归档</a></li><li class="nav__item"><a href="/about" alt="关于" title="关于">关于</a></li></ul></nav><button class="page__menu-btn" type="button"><i class="iconfont icon-menu"></i></button></div></nav></header><main class="page__container page__main"><div class="page__content"><article class="page__post"><div class="post__cover"><img src="/2020/08/31/bert-01/bert.jpg" alt="Knowledge Distillation (3) &#58; 看样本下菜的FastBERT"></div><header class="post__info"><h1 class="post__title">Knowledge Distillation (3) &#58; 看样本下菜的FastBERT</h1><div class="post__mark"><div class="mark__block"><i class="mark__icon iconfont icon-write"></i><ul class="mark__list clearfix"><li class="mark__item"><a href="https://github.com/xv44586">小蛋子</a></li></ul></div><div class="mark__block"><i class="mark__icon iconfont icon-time"></i><ul class="mark__list clearfix"><li class="mark__item"><span>2020-09-25</span></li></ul></div><div class="mark__block"><i class="mark__icon iconfont icon-tab"></i><ul class="mark__list clearfix"><li class="mark__item"><a href="/tags/Distillation/">Distillation</a></li><li class="mark__item"><a href="/tags/FastBERT/">FastBERT</a></li></ul></div><div class="mark__block"><i class="mark__icon iconfont icon-eye"></i><ul class="mark__list clearfix"><li id="busuanzi_container_page_pv" class="mark__item"><span id="busuanzi_value_page_pv"></span>次</li></ul></div></div></header><div class="post__content"><div class="toc"><ul><li><a href="#knowledge-distillation-mu-de">Knowledge Distillation 目的</a></li><li><a href="#zen-me-zuo">怎么做</a><ul><li><a href="#qu-fen-yang-ben">区分样本</a></li><li><a href="#mo-xing-can-shu-gong-xiang">模型参数共享</a></li><li><a href="#zheng-ti-jia-gou">整体架构</a></li></ul></li><li><a href="#fu-xian">复现</a></li><li><a href="#zong-jie">总结</a></li><li><a href="#guan-yu-tou-tu">关于头图</a></li></ul></div><p>之前Knowledge Distillation 相关的两篇分别介绍了两种知识蒸馏的方式：<a href="https://xv44586.github.io/2020/08/09/bert-of-theseus/">模型替换之bert-of-theseus</a> 和<a href="https://xv44586.github.io/2020/08/31/bert-01/">知识迁移</a>,本篇介绍一种从样本入手的知识蒸馏方法。</p><h1><span id="knowledge-distillation-mu-de">Knowledge Distillation 目的</span><a href="#knowledge-distillation-mu-de" class="header-anchor"></a></h1><p>再来看看我们做knowledge distillation 的目的是什么：我们是想要模型即性能好又推理快，那要推理快，我们直接使用一个更小的模型，比如3层的bert就比12层的bert快，那为什么不这么做呢？这是因为直接用3层bert来fine-tuning的结果往往不那么“性能好”，所以他只能满足推理快这一半。<br>所以我们要通过一个teacher 来引导这个小模型，来把“性能好”这个特性补上。</p><h1><span id="zen-me-zuo">怎么做</span><a href="#zen-me-zuo" class="header-anchor"></a></h1><p>而一般做KD ，我们往往关注怎么去让student 更好的学习teacher，但是好像没人关注过student 直接fine-tuning 的时候到底有多差？拿文本分类来说，我们用bert-3 在IFLYTEK数据上进行fine-tuning，最终的accuracy 大概在57.9%，而bert-12 大概在60.7%((结果)[<a href="https://github.com/xv44586/toolkit4nlp/blob/master/examples/classification_ifytek_bert_of_theseus.py])，3层是不如12层，但是差距只有不到3个点，换句不严谨的话说，只有不到3%的数据需要12层的bert才能达到当前最优性能，而大部分样本在前3层就已经能确定了。" target="_blank" rel="noopener">https://github.com/xv44586/toolkit4nlp/blob/master/examples/classification_ifytek_bert_of_theseus.py])，3层是不如12层，但是差距只有不到3个点，换句不严谨的话说，只有不到3%的数据需要12层的bert才能达到当前最优性能，而大部分样本在前3层就已经能确定了。</a><br>换成一句我们都能理解的事实描述就是：样本有难易之分，有的样本容易区分，有的样本不容易区分。这时候，如果全部样本都当不容易区分看待，对这部分容易区分的样本来说就是“杀鸡用牛刀”了，那一个简单直观的办法就是，我们“杀鸡时用杀鸡刀，杀牛时用杀牛刀”，即我们按样本难易程度，分别为他们指定不同的模型来分类，简单的样本只需要用小模型，因为他就能得到与大模型一致的结果，而难的样本再用大模型，这样就能“性能好”的同时推理又快了，因为大部分模型只需要小模型推理即可。</p><h2><span id="qu-fen-yang-ben">区分样本</span><a href="#qu-fen-yang-ben" class="header-anchor"></a></h2><p>接下来的问题就是我们怎么区分样本是简单样本还是难样本了。这里我们将其换个思路：假如小模型对自己的结果非常有信心（确定），那我们就相信小模型的结果，反之，我们就将样本送进大模型，让大模型来进一步判断。注意，这里如果小模型非常“确定”的将样本给了错误结果，那这个结果也将认为是最终结果，即使这个结果送进大模型有被改正确的可能。那如何判断一个结果的不确定性呢？通常我们用熵来判断一个分布的不确定性，这里也一样。</p><h2><span id="mo-xing-can-shu-gong-xiang">模型参数共享</span><a href="#mo-xing-can-shu-gong-xiang" class="header-anchor"></a></h2><p>到了这一步，我们取得了“性能好”又“推理快”的目标了吗？其实还没有，因为此时我们会有多个模型，每个模型对应不同难易程度的样本，这样无疑是将推理从一次变成了多次，那怎么解决呢？我们可以利用上一个小模型的结果而不用再从头算，这样最终的模型就由一系列模型变为一个带有多个分支的大模型，只是每个分支的部分会进行一次判断，如果其结果的不确定性非常低，则直接返回结果而不再往后继续计算。而由于利用了上一层的结果，所以整体的时间上只增加了多个分类器与判断结果置信度的时间，而这个时间相对于其他计算要小的多。</p><h2><span id="zheng-ti-jia-gou">整体架构</span><a href="#zheng-ti-jia-gou" class="header-anchor"></a></h2><p>模型整体架构示意图：<br><img src="/2020/09/25/fastbert/fastbert.png" alt></p><p>以上就是fastbert 模型的整体思路了。对于fastbert 来说，越靠前的层的性能越好，其推理速度提升的就越大，所以有必要尽量提高前面层的性能。这里就是Knowledge Distillation 的任务了：由于fastbert 本身就是一个12层bert，所以将最后一个分类器作为Teacher Model，然后生成对应的soft labels，然后迁移到fastbert 的每一个分支model上。之前的<a href="https://xv44586.github.io/2020/08/31/bert-01/">实验</a>我们也提到过这种self-distillation 能提高性能，作者这里也是一样的思路。</p><h1><span id="fu-xian">复现</span><a href="#fu-xian" class="header-anchor"></a></h1><p>实验代码在<a href="https://github.com/xv44586/Knowledge-Distillation-NLP/blob/master/knowledge_distillation_fastbert.py" target="_blank" rel="noopener">fastbert</a>感兴趣的同学可以看看.不过由于我只会keras(tensorflow)，而tf 这种静态图不好实现这种分支结构，所以我的实验代码其实并没有真的提前终止计算返回结果，暂时没找到更好的实现方式，如果有知道的同学也欢迎告知。</p><h1><span id="zong-jie">总结</span><a href="#zong-jie" class="header-anchor"></a></h1><p>fastbert从思路上来说，通过对样本进行难易程度进行划分，对样本进行adaptive predict ，但是缺点也比较明显：1. 用确定性来代替难易，中间有不对等会导致较难样本在初期被错分后没有修正对机会；2.其基本假设是易分样本远多于难分样本，否则会使推理速度不降反增。</p><h1><span id="guan-yu-tou-tu">关于头图</span><a href="#guan-yu-tou-tu" class="header-anchor"></a></h1><p>芝麻街</p><div class="post__prevs"><div class="post__prev"><a href="/2020/09/13/classification-label-augment/" title="模型增强（2）&#58; 从label下手"><i class="iconfont icon-prev"></i>模型增强（2）&#58; 从label下手</a></div><div class="post__prev post__prev--right"><a href="/2020/09/30/location/" title="年轻人的第一个swift：ios 模拟定位打卡">年轻人的第一个swift：ios 模拟定位打卡<i class="iconfont icon-next"></i></a></div></div></div></article></div><aside class="page__sidebar"><form id="page-search-from" class="page__search-from" action="/search/"><label class="search-form__item"><input class="input" type="text" name="search" placeholder="Search..."> <i class="iconfont icon-search"></i></label></form><div class="sidebar__block"><h3 class="block__title">简介</h3><p class="block__text">NLP | Machine Learning | Developer</p></div><div class="sidebar__block"><h3 class="block__title">文章分类</h3><ul class="block-list"><li class="block-list-item"><a class="block-list-link" href="/categories/Programming/">Programming</a><span class="block-list-count">3</span></li><li class="block-list-item"><a class="block-list-link" href="/categories/NLP/">NLP</a><span class="block-list-count">21</span></li><li class="block-list-item"><a class="block-list-link" href="/categories/Math/">Math</a><span class="block-list-count">5</span></li><li class="block-list-item"><a class="block-list-link" href="/categories/MachineLearning/">MachineLearning</a><span class="block-list-count">8</span></li><li class="block-list-item"><a class="block-list-link" href="/categories/Life/">Life</a><span class="block-list-count">5</span></li></ul></div><div class="sidebar__block"><h3 class="block__title">最新文章</h3><ul class="block-list latest-post-list"><li class="latest-post-item"><a href="/2021/01/12/matrix/" title="重新认识矩阵"><div class="item__cover"><img src="/2021/01/12/matrix/det.png" alt="重新认识矩阵"></div><div class="item__info"><h3 class="item__title">重新认识矩阵</h3><span class="item__text">2021-01-12</span></div></a></li><li class="latest-post-item"><a href="/2020/11/24/fine-tune/" title="如何提升bert在下游任务中的性能"><div class="item__cover"><img src="/2020/08/31/bert-01/bert.jpg" alt="如何提升bert在下游任务中的性能"></div><div class="item__info"><h3 class="item__title">如何提升bert在下游任务中的性能</h3><span class="item__text">2020-11-24</span></div></a></li><li class="latest-post-item"><a href="/2020/11/23/scl/" title="Contrastive Learning"><div class="item__cover"><img src="/img/default_cover.jpeg" alt="Contrastive Learning"></div><div class="item__info"><h3 class="item__title">Contrastive Learning</h3><span class="item__text">2020-11-23</span></div></a></li><li class="latest-post-item"><a href="/2020/11/21/ad-dti/" title="跨界之阿尔滋海默病的分类竞赛"><div class="item__cover"><img src="/2020/11/21/ad-dti/cat.jpeg" alt="跨界之阿尔滋海默病的分类竞赛"></div><div class="item__info"><h3 class="item__title">跨界之阿尔滋海默病的分类竞赛</h3><span class="item__text">2020-11-21</span></div></a></li></ul></div><div class="sidebar__block"><h3 class="block__title">文章标签</h3><ul class="block-list tag-list clearfix"><li class="tag-item"><a class="tag-link" href="/tags/BERT/">BERT</a></li><li class="tag-item"><a class="tag-link" href="/tags/Bagging/">Bagging</a></li><li class="tag-item"><a class="tag-link" href="/tags/Boosting/">Boosting</a></li><li class="tag-item"><a class="tag-link" href="/tags/CCF/">CCF</a></li><li class="tag-item"><a class="tag-link" href="/tags/CRF/">CRF</a></li><li class="tag-item"><a class="tag-link" href="/tags/CUDA/">CUDA</a></li><li class="tag-item"><a class="tag-link" href="/tags/Classification/">Classification</a></li><li class="tag-item"><a class="tag-link" href="/tags/Competition/">Competition</a></li><li class="tag-item"><a class="tag-link" href="/tags/Deep-Learning/">Deep Learning</a></li><li class="tag-item"><a class="tag-link" href="/tags/Distillation/">Distillation</a></li><li class="tag-item"><a class="tag-link" href="/tags/EDA/">EDA</a></li><li class="tag-item"><a class="tag-link" href="/tags/FastBERT/">FastBERT</a></li><li class="tag-item"><a class="tag-link" href="/tags/Few-shot/">Few-shot</a></li><li class="tag-item"><a class="tag-link" href="/tags/Game/">Game</a></li><li class="tag-item"><a class="tag-link" href="/tags/Glove/">Glove</a></li><li class="tag-item"><a class="tag-link" href="/tags/Hexo/">Hexo</a></li><li class="tag-item"><a class="tag-link" href="/tags/LR/">LR</a></li><li class="tag-item"><a class="tag-link" href="/tags/Language-Model/">Language Model</a></li><li class="tag-item"><a class="tag-link" href="/tags/Loss/">Loss</a></li><li class="tag-item"><a class="tag-link" href="/tags/MarkDown/">MarkDown</a></li><li class="tag-item"><a class="tag-link" href="/tags/Math/">Math</a></li><li class="tag-item"><a class="tag-link" href="/tags/Matrix/">Matrix</a></li><li class="tag-item"><a class="tag-link" href="/tags/NLG/">NLG</a></li><li class="tag-item"><a class="tag-link" href="/tags/Optimizer/">Optimizer</a></li><li class="tag-item"><a class="tag-link" href="/tags/Python/">Python</a></li><li class="tag-item"><a class="tag-link" href="/tags/QA/">QA</a></li><li class="tag-item"><a class="tag-link" href="/tags/Random-Forest/">Random Forest</a></li><li class="tag-item"><a class="tag-link" href="/tags/Segmentation/">Segmentation</a></li><li class="tag-item"><a class="tag-link" href="/tags/Statistics/">Statistics</a></li><li class="tag-item"><a class="tag-link" href="/tags/Survey/">Survey</a></li><li class="tag-item"><a class="tag-link" href="/tags/UniLM/">UniLM</a></li><li class="tag-item"><a class="tag-link" href="/tags/Words-Distance/">Words Distance</a></li><li class="tag-item"><a class="tag-link" href="/tags/Xgboost/">Xgboost</a></li><li class="tag-item"><a class="tag-link" href="/tags/npm/">npm</a></li><li class="tag-item"><a class="tag-link" href="/tags/skipgram/">skipgram</a></li><li class="tag-item"><a class="tag-link" href="/tags/swift/">swift</a></li><li class="tag-item"><a class="tag-link" href="/tags/tensorflow-gpu/">tensorflow-gpu</a></li><li class="tag-item"><a class="tag-link" href="/tags/word2vec/">word2vec</a></li><li class="tag-item"><a class="tag-link" href="/tags/信息熵/">信息熵</a></li><li class="tag-item"><a class="tag-link" href="/tags/新词发现/">新词发现</a></li><li class="tag-item"><a class="tag-link" href="/tags/样本不均衡/">样本不均衡</a></li><li class="tag-item"><a class="tag-link" href="/tags/装机/">装机</a></li><li class="tag-item"><a class="tag-link" href="/tags/领域词挖掘/">领域词挖掘</a></li></ul></div></aside></main><footer class="page__footer"><section class="footer__top"><div class="page__container footer__container"><div class="footer-top__item footer-top__item--2"><h3 class="item__title">关于</h3><div class="item__content"><p class="item__text">本站是基于 Hexo 搭建的静态资源博客，主要用于分享日常学习、生活及工作的一些心得总结。</p><ul class="footer__contact-info"><li class="contact-info__item"><i class="iconfont icon-address"></i> <span>Beijing, China</span></li><li class="contact-info__item"><i class="iconfont icon-email2"></i> <span>xv44586@gmail.com</span></li></ul></div></div><div class="footer-top__item"><h3 class="item__title">友情链接</h3><div class="item__content"><ul class="footer-top__list"><li class="list-item"><a href="http://www.matrix67.com/" title="Matrix67" target="_blank">Matrix67</a></li><li class="list-item"><a href="https://spaces.ac.cn/" title="Spaces" target="_blank">科学空间</a></li></ul></div></div></div></section><section class="footer__bottom"><div class="page__container footer__container"><p class="footer__copyright">© <a href="https://github.com/Mrminfive/hexo-theme-skapp" target="_blank">Skapp</a> 2017 powered by <a href="http://hexo.io/" target="_blank">Hexo</a>, made by <a href="https://github.com/Mrminfive" target="_blank">minfive</a>. modified by <a href="https://github.com/xv44586" target="_blank">小蛋子</a></p><ul class="footer__social-network clearfix"><li class="social-network__item"><a href="https://github.com/xv44586" target="_blank" title="github"><i class="iconfont icon-github"></i></a></li><li class="social-network__item"><a href="xv44586@gmail.com" target="_blank" title="email"><i class="iconfont icon-email"></i></a></li></ul></div></section></footer><div id="back-top" class="back-top back-top--hidden js-hidden"><i class="iconfont icon-top"></i></div></div><script src="/js/common.js"></script><script src="/js/page/post.js"></script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
            tex2jax: {
                inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
                processEscapes: true,
                skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
            }
            });</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
            var all = MathJax.Hub.getAllJax(), i;
                for (i=0; i < all.length; i += 1) {
                all[i].SourceElement().parentNode.className += ' has-jax';
                }
            });</script><script type="text/javascript" src="//cdn.jsdelivr.net/npm/mathjax@2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script></body></html>